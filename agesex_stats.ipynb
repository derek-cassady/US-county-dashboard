{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age & Sex Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import workbook, load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import numpy as np\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading file to dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of dataframes and their proper order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating ordered list of DFs to name each sheet coming in from workbook\n",
    "df_names = ['DF_total_all','DF_male_all','DF_female_all','DF_total_whi',\n",
    "            'DF_total_male_whi','DF_total_female_whi','DF_total_baa',\n",
    "            'DF_total_male_baa','DF_total_female_baa','DF_total_aian',\n",
    "            'DF_total_male_aian','DF_total_female_aian','DF_total_aa',\n",
    "            'DF_total_male_aa','DF_total_female_aa','DF_total_nhop',\n",
    "            'DF_total_male_nhop','DF_total_female_nhop','DF_total_sor',\n",
    "            'DF_total_male_sor','DF_total_female_sor','DF_total_tom',\n",
    "            'DF_total_male_tom','DF_total_female_tom','DF_total_hol',\n",
    "            'DF_total_male_hol','DF_total_female_hol'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables for column names and type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_int = ['Under 1 Year','1 Year','2 Years','3 Years','4 Years','5 Years',\n",
    "            '6 Years','7 Years','8 Years','9 Years','10 Years','11 Years',\n",
    "            '12 Years','13 Years','14 Years','15 Years','16 Years','17 Years',\n",
    "            '18 Years','19 Years','20 Years','21 Years','22 Years','23 Years',\n",
    "            '24 Years','25 Years','26 Years','27 Years','28 Years','29 Years',\n",
    "            '30 Years','31 Years','32 Years','33 Years','34 Years','35 Years',\n",
    "            '36 Years','37 Years','38 Years','39 Years','40 Years','41 Years',\n",
    "            '42 Years','43 Years','44 Years','45 Years','46 Years','47 Years',\n",
    "            '48 Years','49 Years','50 Years','51 Years','52 Years','53 Years',\n",
    "            '54 Years','55 Years','56 Years','57 Years','58 Years','59 Years',\n",
    "            '60 Years','61 Years','62 Years','63 Years','64 Years','65 Years',\n",
    "            '66 Years','67 Years','68 Years','69 Years','70 Years','71 Years',\n",
    "            '72 Years','73 Years','74 Years','75 Years','76 Years','77 Years',\n",
    "            '78 Years','79 Years','80 Years','81 Years','82 Years','83 Years',\n",
    "            '84 Years','85 Years','86 Years','87 Years','88 Years','89 Years',\n",
    "            '90 Years','91 Years','92 Years','93 Years','94 Years','95 Years',\n",
    "            '96 Years','97  Years','98  Years','99  Years','100 to 104  Years',\n",
    "            '105 to 109  Years','110  Years and Over'\n",
    "            ]\n",
    "\n",
    "cols_str = ['Location', 'State', 'County', 'FIPS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the dataframes\n",
    "dfs = {}\n",
    "\n",
    "# Get the path of the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Construct the full path to the .xlsx file\n",
    "file_path = os.path.join(cwd, '2020_agesex_data.xlsx')\n",
    "\n",
    "# Load each sheet of the .xlsx file into a named dataframe\n",
    "for name in df_names:\n",
    "    df = pd.read_excel(file_path, sheet_name=name, header=None)  # Specify header=None to treat the first row as data\n",
    "    df.columns = df.iloc[0]  # Set the first row as the column headers\n",
    "    df = df[1:]  # Exclude the first row from the data\n",
    "    df.reset_index(drop=True, inplace=True)  # Reset the index\n",
    "    \n",
    "    # Change column types based on column names\n",
    "    for column in cols_int:\n",
    "        if column in df.columns:\n",
    "            df[column] = df[column].astype(int)\n",
    "    \n",
    "    for column in cols_str:\n",
    "        if column in df.columns:\n",
    "            df[column] = df[column].astype(str)\n",
    "    \n",
    "    dfs[name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where the hell are my dataframes stored currently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27\n",
    "dfs {'DF_total_all','DF_male_all','DF_female_all','DF_total_whi',\n",
    "'DF_total_male_whi','DF_total_female_whi','DF_total_baa',\n",
    "'DF_total_male_baa','DF_total_female_baa','DF_total_aian',\n",
    "'DF_total_male_aian','DF_total_female_aian','DF_total_aa',\n",
    "'DF_total_male_aa','DF_total_female_aa','DF_total_nhop',\n",
    "'DF_total_male_nhop','DF_total_female_nhop','DF_total_sor',\n",
    "'DF_total_male_sor','DF_total_female_sor','DF_total_tom',\n",
    "'DF_total_male_tom','DF_total_female_tom','DF_total_hol',\n",
    "'DF_total_male_hol','DF_total_female_hol'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all the names, shapes, and dtypes of the dataframes loaded in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the names, shapes, and dtypes of the dataframes in 'dfs'\n",
    "# print(\"Data Frames in 'dfs':\")\n",
    "# for name, df in dfs.items():\n",
    "#     print(name)\n",
    "#     print(\"Shape:\", df.shape)\n",
    "#     print(\"Dtypes:\")\n",
    "#     for column, dtype in df.dtypes.items():\n",
    "#         print(f\"{column}: {dtype}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Percent to Total column\n",
    "Percent to total for male & female age groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping Dataframes with like structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_df = ['DF_male_all','DF_female_all','DF_total_male_whi',\n",
    "             'DF_total_female_whi','DF_total_male_baa','DF_total_female_baa',\n",
    "             'DF_total_male_aian','DF_total_female_aian','DF_total_male_aa',\n",
    "             'DF_total_female_aa','DF_total_male_nhop','DF_total_female_nhop',\n",
    "             'DF_total_male_sor','DF_total_female_sor','DF_total_male_tom',\n",
    "             'DF_total_female_tom','DF_total_male_hol','DF_total_female_hol'\n",
    "             ]\n",
    "\n",
    "perc_df_2 = ['DF_total_all','DF_total_whi','DF_total_baa','DF_total_aian',\n",
    "             'DF_total_aa','DF_total_nhop','DF_total_sor','DF_total_tom',\n",
    "             'DF_total_hol'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent to total process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the dictionary of dataframes\n",
    "for df_name, df in dfs.items():\n",
    "    if df_name in perc_df:\n",
    "        # Get the list of columns in the dataframe that match cols_int\n",
    "        columns = [col for col in df.columns if col in cols_int]\n",
    "        updated_columns = []\n",
    "\n",
    "        # Reset the index to consolidate memory layout\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Calculate the percentage values for the new column\n",
    "        for col in columns:\n",
    "            new_col_name = f'{col}_perc'\n",
    "            updated_columns.extend([col, new_col_name])\n",
    "\n",
    "            df[new_col_name] = [0 if total == 0 else (value / total)\n",
    "                                for value, total in zip(df[col], df['Total'])]\n",
    "        # Append ['Location', 'State', 'County', 'FIPS'] to updated_columns\n",
    "        updated_columns.extend(['Total','Location', 'State', 'County', 'FIPS'])\n",
    "        # Reorder the columns in the dataframe\n",
    "        df = df[updated_columns]\n",
    "\n",
    "        # Update the dataframe in the 'dfs' dictionary\n",
    "        dfs[df_name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all the name,shape,# of cols, col names of the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the shape of the dataframes in 'dfs'\n",
    "# print(\"Data Frames in 'perc_df':\")\n",
    "# for df_name, df in dfs.items():\n",
    "#     if df_name in perc_df:\n",
    "#         print(\"Dataframe Name:\", df_name)\n",
    "#         print(\"Shape:\", df.shape)\n",
    "#         print(f\"Number of Columns: {len(df.columns)}\")\n",
    "#         print(\"Columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Weighted Average Column for 'perc_df' listed dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing modified dataframes from dict dfs for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the new dictionary 'dfs_perc'\n",
    "dfs_perc = {}\n",
    "\n",
    "# Iterate over the dataframe names in 'perc_df' list\n",
    "for df_name in perc_df:\n",
    "    # Check if the dataframe name exists in 'dfs' dictionary\n",
    "    if df_name in dfs:\n",
    "        # Move the matching dataframe from 'dfs' to 'dfs_perc'\n",
    "        dfs_perc[df_name] = dfs.pop(df_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where the hell are my dataframes stored currently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27\n",
    "dfs {'DF_total_all','DF_male_all','DF_female_all','DF_total_whi',\n",
    "'DF_total_male_whi','DF_total_female_whi','DF_total_baa',\n",
    "'DF_total_male_baa','DF_total_female_baa','DF_total_aian',\n",
    "'DF_total_male_aian','DF_total_female_aian','DF_total_aa',\n",
    "'DF_total_male_aa','DF_total_female_aa','DF_total_nhop',\n",
    "'DF_total_male_nhop','DF_total_female_nhop','DF_total_sor',\n",
    "'DF_total_male_sor','DF_total_female_sor','DF_total_tom',\n",
    "'DF_total_male_tom','DF_total_female_tom','DF_total_hol',\n",
    "'DF_total_male_hol','DF_total_female_hol'}\n",
    "\n",
    "18\n",
    "dfs_perc {DF_male_all,DF_female_all,DF_total_male_whi,DF_total_female_whi\n",
    "DF_total_male_baa,DF_total_female_baa,DF_total_male_aian,DF_total_female_aian\n",
    "DF_total_male_aa,DF_total_female_aa,DF_total_male_nhop,DF_total_female_nhop\n",
    "DF_total_male_sor,DF_total_female_sor,DF_total_male_tom,DF_total_female_tom\n",
    "DF_total_male_hol,DF_total_female_hol}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary 'dfs':\n",
      "9\n",
      "['DF_total_all', 'DF_total_whi', 'DF_total_baa', 'DF_total_aian', 'DF_total_aa', 'DF_total_nhop', 'DF_total_sor', 'DF_total_tom', 'DF_total_hol']\n",
      "\n",
      "Dictionary 'perc_df':\n",
      "18\n",
      "['DF_male_all', 'DF_female_all', 'DF_total_male_whi', 'DF_total_female_whi', 'DF_total_male_baa', 'DF_total_female_baa', 'DF_total_male_aian', 'DF_total_female_aian', 'DF_total_male_aa', 'DF_total_female_aa', 'DF_total_male_nhop', 'DF_total_female_nhop', 'DF_total_male_sor', 'DF_total_female_sor', 'DF_total_male_tom', 'DF_total_female_tom', 'DF_total_male_hol', 'DF_total_female_hol']\n"
     ]
    }
   ],
   "source": [
    "# # Printing list of both dataframe dictionaries to verify last step\n",
    "\n",
    "# # We should have 9 in dict 'dfs' and 18 in new dict 'perc_df'\n",
    "\n",
    "# print(\"Dictionary 'dfs':\")\n",
    "# print(len(dfs.keys()))\n",
    "# print(list(dfs.keys()))\n",
    "\n",
    "# print(\"\\nDictionary 'perc_df':\")\n",
    "# print(len(dfs_perc.keys()))\n",
    "# print(list(dfs_perc.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables for columns to drop to new dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Under 1 Year_perc','1 Year_perc','2 Years_perc',\n",
    "                  '3 Years_perc','4 Years_perc','5 Years_perc','6 Years_perc',\n",
    "                  '7 Years_perc','8 Years_perc','9 Years_perc','10 Years_perc',\n",
    "                  '11 Years_perc','12 Years_perc','13 Years_perc',\n",
    "                  '14 Years_perc','15 Years_perc','16 Years_perc',\n",
    "                  '17 Years_perc','18 Years_perc','19 Years_perc',\n",
    "                  '20 Years_perc','21 Years_perc','22 Years_perc',\n",
    "                  '23 Years_perc','24 Years_perc','25 Years_perc',\n",
    "                  '26 Years_perc','27 Years_perc','28 Years_perc',\n",
    "                  '29 Years_perc','30 Years_perc','31 Years_perc',\n",
    "                  '32 Years_perc','33 Years_perc','34 Years_perc',\n",
    "                  '35 Years_perc','36 Years_perc','37 Years_perc',\n",
    "                  '38 Years_perc','39 Years_perc','40 Years_perc',\n",
    "                  '41 Years_perc','42 Years_perc','43 Years_perc',\n",
    "                  '44 Years_perc','45 Years_perc','46 Years_perc',\n",
    "                  '47 Years_perc','48 Years_perc','49 Years_perc',\n",
    "                  '50 Years_perc','51 Years_perc','52 Years_perc',\n",
    "                  '53 Years_perc','54 Years_perc','55 Years_perc',\n",
    "                  '56 Years_perc','57 Years_perc','58 Years_perc',\n",
    "                  '59 Years_perc','60 Years_perc','61 Years_perc',\n",
    "                  '62 Years_perc','63 Years_perc','64 Years_perc',\n",
    "                  '65 Years_perc','66 Years_perc','67 Years_perc',\n",
    "                  '68 Years_perc','69 Years_perc','70 Years_perc',\n",
    "                  '71 Years_perc','72 Years_perc','73 Years_perc',\n",
    "                  '74 Years_perc','75 Years_perc','76 Years_perc',\n",
    "                  '77 Years_perc','78 Years_perc','79 Years_perc',\n",
    "                  '80 Years_perc','81 Years_perc','82 Years_perc',\n",
    "                  '83 Years_perc','84 Years_perc','85 Years_perc',\n",
    "                  '86 Years_perc','87 Years_perc','88 Years_perc',\n",
    "                  '89 Years_perc','90 Years_perc','91 Years_perc',\n",
    "                  '92 Years_perc','93 Years_perc','94 Years_perc',\n",
    "                  '95 Years_perc','96 Years_perc','97  Years_perc',\n",
    "                  '98  Years_perc','99  Years_perc','100 to 104  Years_perc',\n",
    "                  '105 to 109  Years_perc','110  Years and Over_perc','Total',\n",
    "                  'Location','State','County','FIPS'\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_columns = {}\n",
    "\n",
    "# Iterate over the dataframes in 'dfs_perc'\n",
    "for df_name, df in dfs_perc.items():\n",
    "    # Store the dropped columns' data\n",
    "    dropped_columns[df_name] = df[columns_to_drop]\n",
    "\n",
    "    # Drop the specified columns from each dataframe\n",
    "    dfs_perc[df_name] = df.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where the hell are my dataframes stored currently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\n",
    "dfs {DF_total_all,DF_total_whi,DF_total_baa,DF_total_aian,DF_total_aa,\n",
    "DF_total_nhop,DF_total_sor,DF_total_tom,DF_total_hol}\n",
    "\n",
    "18\n",
    "dfs_perc {DF_male_all,DF_female_all,DF_total_male_whi,DF_total_female_whi\n",
    "DF_total_male_baa,DF_total_female_baa,DF_total_male_aian,DF_total_female_aian\n",
    "DF_total_male_aa,DF_total_female_aa,DF_total_male_nhop,DF_total_female_nhop\n",
    "DF_total_male_sor,DF_total_female_sor,DF_total_male_tom,DF_total_female_tom\n",
    "DF_total_male_hol,DF_total_female_hol}\n",
    "\n",
    "18\n",
    "dropped_columns {DF_male_all,DF_female_all,DF_total_male_whi,DF_total_female_whi\n",
    "DF_total_male_baa,DF_total_female_baa,DF_total_male_aian,DF_total_female_aian\n",
    "DF_total_male_aa,DF_total_female_aa,DF_total_male_nhop,DF_total_female_nhop\n",
    "DF_total_male_sor,DF_total_female_sor,DF_total_male_tom,DF_total_female_tom\n",
    "DF_total_male_hol,DF_total_female_hol}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Dictionary 'dfs_perc':\")\n",
    "# for df_name, df in dfs_perc.items():\n",
    "#     print(f\"DataFrame '{df_name}' column names:\")\n",
    "#     print(list(df.columns))\n",
    "\n",
    "# print(\"\\nDictionary 'dropped_columns':\")\n",
    "# for df_name, df in dropped_columns.items():\n",
    "#     print(f\"DataFrame '{df_name}' column names:\")\n",
    "#     print(list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables for columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_int = ['Under 1 Year','1 Year','2 Years','3 Years','4 Years','5 Years',\n",
    "            '6 Years','7 Years','8 Years','9 Years','10 Years','11 Years',\n",
    "            '12 Years','13 Years','14 Years','15 Years','16 Years','17 Years',\n",
    "            '18 Years','19 Years','20 Years','21 Years','22 Years','23 Years',\n",
    "            '24 Years','25 Years','26 Years','27 Years','28 Years','29 Years',\n",
    "            '30 Years','31 Years','32 Years','33 Years','34 Years','35 Years',\n",
    "            '36 Years','37 Years','38 Years','39 Years','40 Years','41 Years',\n",
    "            '42 Years','43 Years','44 Years','45 Years','46 Years','47 Years',\n",
    "            '48 Years','49 Years','50 Years','51 Years','52 Years','53 Years',\n",
    "            '54 Years','55 Years','56 Years','57 Years','58 Years','59 Years',\n",
    "            '60 Years','61 Years','62 Years','63 Years','64 Years','65 Years',\n",
    "            '66 Years','67 Years','68 Years','69 Years','70 Years','71 Years',\n",
    "            '72 Years','73 Years','74 Years','75 Years','76 Years','77 Years',\n",
    "            '78 Years','79 Years','80 Years','81 Years','82 Years','83 Years',\n",
    "            '84 Years','85 Years','86 Years','87 Years','88 Years','89 Years',\n",
    "            '90 Years','91 Years','92 Years','93 Years','94 Years','95 Years',\n",
    "            '96 Years','97 Years','98 Years','99 Years','100 to 104 Years',\n",
    "            '105 to 109 Years','110 Years and Over'\n",
    "            ]\n",
    "cols_mod = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,\n",
    "            25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,\n",
    "            47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,\n",
    "            69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,\n",
    "            91,92,93,94,95,96,97,98,99,102,107,110\n",
    "            ] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column change process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the dataframes in 'dfs_perc'\n",
    "for df_name, df in dfs_perc.items():\n",
    "    # Change the column names to the list of integers\n",
    "    df.columns = cols_mod\n",
    "    \n",
    "    # Convert the column type to integer\n",
    "    df[cols_mod] = df[cols_mod].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where the hell are my dataframes stored currently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\n",
    "dfs{DF_total_all,DF_total_whi,DF_total_baa,DF_total_aian,DF_total_aa,\n",
    "DF_total_nhop,DF_total_sor,DF_total_tom,DF_total_hol}\n",
    "\n",
    "18\n",
    "dfs_perc{DF_male_all,DF_female_all,DF_total_male_whi,DF_total_female_whi,\n",
    "DF_total_male_baa,DF_total_female_baa,DF_total_male_aian,DF_total_female_aian,\n",
    "DF_total_male_aa,DF_total_female_aa,DF_total_male_nhop,DF_total_female_nhop,\n",
    "DF_total_male_sor,DF_total_female_sor,DF_total_male_tom,DF_total_female_tom,\n",
    "DF_total_male_hol,DF_total_female_hol}\n",
    "\n",
    "18\n",
    "dropped_columns{DF_male_all,DF_female_all,DF_total_male_whi,DF_total_female_whi,\n",
    "DF_total_male_baa,DF_total_female_baa,DF_total_male_aian,DF_total_female_aian,\n",
    "DF_total_male_aa,DF_total_female_aa,DF_total_male_nhop,DF_total_female_nhop,\n",
    "DF_total_male_sor,DF_total_female_sor,DF_total_male_tom,DF_total_female_tom,\n",
    "DF_total_male_hol,DF_total_female_hol}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate over the dataframes in 'dfs_perc'\n",
    "# for df_name, df in dfs_perc.items():\n",
    "#     print(f\"DataFrame '{df_name}' column names:\")\n",
    "#     print(list(df.columns))\n",
    "#     print(f\"DataFrame '{df_name}' column types:\")\n",
    "#     print(df.dtypes)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding weighted Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each key-value pair in dfs_perc\n",
    "for df_name, df in dfs_perc.items():\n",
    "    # Get the column names as an array of integers\n",
    "    values = np.array(df.columns, dtype=int)\n",
    "\n",
    "    # Initialize an empty list to store the results\n",
    "    results = []\n",
    "\n",
    "    # Iterate over each row in the dataframe\n",
    "    for _, row in df.iterrows():\n",
    "        # Get the row entries as an array of integers\n",
    "        weights = np.array(row.values, dtype=int)\n",
    "\n",
    "        # Perform element-wise multiplication of values and weights\n",
    "        weighted_values = values * weights\n",
    "\n",
    "        # Sum the products of the multiplications\n",
    "        weighted_sum = np.sum(weighted_values)\n",
    "\n",
    "        # Sum all items in the weights array\n",
    "        weights_sum = np.sum(weights)\n",
    "\n",
    "        # Calculate the weighted average\n",
    "        weighted_average = weighted_sum / weights_sum\n",
    "\n",
    "        # Append the weighted average to the results list\n",
    "        results.append(weighted_average)\n",
    "\n",
    "    # Add the 'Average_Age' column to the dataframe\n",
    "    df['Average_Age'] = results\n",
    "\n",
    "    # Reset the index of the dataframe\n",
    "    df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate over the dictionaries in 'dropped_string_columns'\n",
    "# for df_name, df_dict in dfs_perc.items():\n",
    "#     print(f\"DataFrame '{df_name}' column names:\")\n",
    "#     print(list(df_dict.keys()))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verifying values in column of specific dataframe in 'dfs_perc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if 'DF_male_all' exists in 'dfs_perc' dictionary\n",
    "# if 'DF_male_all' in dfs_perc:\n",
    "#     print(\"DataFrame 'DF_male_all':\")\n",
    "#     print(dfs_perc['DF_male_all'])\n",
    "# else:\n",
    "#     print(\"DataFrame 'DF_male_all' does not exist in 'dfs_perc' dictionary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where the hell are my dataframes stored currently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\n",
    "dfs{DF_total_all,DF_total_whi,DF_total_baa,DF_total_aian,DF_total_aa,\n",
    "DF_total_nhop,DF_total_sor,DF_total_tom,DF_total_hol}\n",
    "\n",
    "18\n",
    "dfs_perc{DF_male_all,DF_female_all,DF_total_male_whi,DF_total_female_whi,\n",
    "DF_total_male_baa,DF_total_female_baa,DF_total_male_aian,DF_total_female_aian,\n",
    "DF_total_male_aa,DF_total_female_aa,DF_total_male_nhop,DF_total_female_nhop,\n",
    "DF_total_male_sor,DF_total_female_sor,DF_total_male_tom,DF_total_female_tom,\n",
    "DF_total_male_hol,DF_total_female_hol}\n",
    "\n",
    "18\n",
    "dropped_columns{DF_male_all,DF_female_all,DF_total_male_whi,DF_total_female_whi,\n",
    "DF_total_male_baa,DF_total_female_baa,DF_total_male_aian,DF_total_female_aian,\n",
    "DF_total_male_aa,DF_total_female_aa,DF_total_male_nhop,DF_total_female_nhop,\n",
    "DF_total_male_sor,DF_total_female_sor,DF_total_male_tom,DF_total_female_tom,\n",
    "DF_total_male_hol,DF_total_female_hol}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the dataframes in 'dfs_perc'\n",
    "for df_name, df_perc in dfs_perc.items():\n",
    "    # Get the corresponding dataframe from 'dropped_columns'\n",
    "    df_dropped = dropped_columns[df_name]\n",
    "\n",
    "    # Concatenate the dataframes width-wise\n",
    "    joined_df = pd.concat([df_perc, df_dropped], axis=1)\n",
    "\n",
    "    # Update the 'dfs_perc' dataframe in place with the joined dataframe\n",
    "    dfs_perc[df_name] = joined_df\n",
    "\n",
    "    # Reset the index of the dataframe\n",
    "    dfs_perc[df_name].reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Delete the 'dropped_columns' dictionary to free up memory\n",
    "del dropped_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where the hell are my dataframes stored currently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\n",
    "dfs {DF_total_all,DF_total_whi,DF_total_baa,DF_total_aian,DF_total_aa,\n",
    "DF_total_nhop,DF_total_sor,DF_total_tom,DF_total_hol}\n",
    "\n",
    "18\n",
    "dfs_perc{DF_male_all,DF_female_all,DF_total_male_whi,DF_total_female_whi,\n",
    "DF_total_male_baa,DF_total_female_baa,DF_total_male_aian,DF_total_female_aian,\n",
    "DF_total_male_aa,DF_total_female_aa,DF_total_male_nhop,DF_total_female_nhop,\n",
    "DF_total_male_sor,DF_total_female_sor,DF_total_male_tom,DF_total_female_tom,\n",
    "DF_total_male_hol,DF_total_female_hol}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the names, shapes, and dtypes of the dataframes in 'dfs_perc'\n",
    "# print(\"Data Frames in 'dfs_perc':\")\n",
    "# for name, df in dfs_perc.items():\n",
    "#     print(name)\n",
    "#     print(\"Shape:\", df.shape)\n",
    "#     print(\"Dtypes:\")\n",
    "#     for column, dtype in df.dtypes.items():\n",
    "#         print(f\"{column}: {dtype}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting a specific dataframe to verify information has migrated correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Temp option to see all columns\n",
    "# with pd.option_context('display.max_columns', None):\n",
    "#     print(dfs_perc['DF_male_all'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dictionaries 'dfs' and 'dfs_perc' into 'dfs' in the order of 'df_names'\n",
    "for df_name in df_names:\n",
    "    if df_name in dfs_perc:\n",
    "        if df_name in dfs:\n",
    "            df_merged = pd.concat([dfs[df_name], dfs_perc[df_name]], axis=1)\n",
    "            dfs[df_name] = df_merged\n",
    "        else:\n",
    "            dfs[df_name] = dfs_perc[df_name]\n",
    "# Delete the 'dfs_perc' dictionary to free up memory\n",
    "del dfs_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where the hell are my dataframes stored currently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27\n",
    "dfs{DF_total_all,DF_total_whi,DF_total_baa,DF_total_aian,DF_total_aa,\n",
    "DF_total_nhop,DF_total_sor,DF_total_tom,DF_total_hol,DF_male_all,DF_female_all,\n",
    "DF_total_male_whi,DF_total_female_whi,DF_total_male_baa,DF_total_female_baa,\n",
    "DF_total_male_aian,DF_total_female_aian,DF_total_male_aa,DF_total_female_aa,\n",
    "DF_total_male_nhop,DF_total_female_nhop,DF_total_male_sor,DF_total_female_sor,\n",
    "DF_total_male_tom,DF_total_female_tom,DF_total_male_hol,DF_total_female_hol}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all the count,name,shape,# of cols, col names of the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the number of dataframes in the 'dfs' dictionary\n",
    "# print(\"Number of Dataframes in 'dfs':\", len(dfs))\n",
    "\n",
    "# # Print the shape of the dataframes in 'dfs'\n",
    "# print(\"Data Frames in 'dfs':\")\n",
    "# for df_name, df in dfs.items():\n",
    "#     print(\"Dataframe Name:\", df_name)\n",
    "#     print(\"Shape:\", df.shape)\n",
    "#     print(f\"Number of Columns: {len(df.columns)}\")\n",
    "#     print(\"Columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy needed cols from sex dfs to race df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map the column prefixes to the corresponding dataframes\n",
    "column_map = {\n",
    "    'DF_total_all': ['DF_male_all', 'DF_female_all'],\n",
    "    'DF_total_whi': ['DF_total_male_whi', 'DF_total_female_whi'],\n",
    "    'DF_total_baa': ['DF_total_male_baa', 'DF_total_female_baa'],\n",
    "    'DF_total_aian': ['DF_total_male_aian', 'DF_total_female_aian'],\n",
    "    'DF_total_aa': ['DF_total_male_aa', 'DF_total_female_aa'],\n",
    "    'DF_total_nhop': ['DF_total_male_nhop', 'DF_total_female_nhop'],\n",
    "    'DF_total_sor': ['DF_total_male_sor', 'DF_total_female_sor'],\n",
    "    'DF_total_tom': ['DF_total_male_tom', 'DF_total_female_tom'],\n",
    "    'DF_total_hol': ['DF_total_male_hol', 'DF_total_female_hol']\n",
    "}\n",
    "\n",
    "# Copy 'Total' column to the correct dataframes\n",
    "for key, value in column_map.items():\n",
    "    # Slicing exclude the first three characters\n",
    "    dfs[key][f'{value[0][3:]}'] = dfs[value[0]]['Total'].copy()\n",
    "    dfs[key][f'{value[1][3:]}'] = dfs[value[1]]['Total'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Verify the outcome\n",
    "# for key, df in dfs.items():\n",
    "#     print(f\"DataFrame '{key}' column names:\")\n",
    "#     print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy needed cols from race df to total df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map the column prefixes to the corresponding dataframes\n",
    "column_map = {\n",
    "    'DF_total_all': ['DF_total_whi', 'DF_total_baa', 'DF_total_aian',\n",
    "                     'DF_total_aa', 'DF_total_nhop', 'DF_total_sor',\n",
    "                     'DF_total_tom', 'DF_total_hol'\n",
    "                     ]\n",
    "                }\n",
    "\n",
    "# Copy 'Total' column to the correct dataframes\n",
    "for key, value in column_map.items():\n",
    "    for df_name in value:\n",
    "        dfs[key][df_name[3:]] = dfs[df_name]['Total'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Verify the outcome\n",
    "# print(f\"DataFrame 'DF_total_all' column names:\")\n",
    "# print(dfs['DF_total_all'].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Age totals for races from age DF to race DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map the column prefixes to the corresponding dataframes\n",
    "column_map = {\n",
    "    'DF_total_all': ['DF_male_all', 'DF_female_all'],\n",
    "    'DF_total_whi': ['DF_total_male_whi', 'DF_total_female_whi'],\n",
    "    'DF_total_baa': ['DF_total_male_baa', 'DF_total_female_baa'],\n",
    "    'DF_total_aian': ['DF_total_male_aian', 'DF_total_female_aian'],\n",
    "    'DF_total_aa': ['DF_total_male_aa', 'DF_total_female_aa'],\n",
    "    'DF_total_nhop': ['DF_total_male_nhop', 'DF_total_female_nhop'],\n",
    "    'DF_total_sor': ['DF_total_male_sor', 'DF_total_female_sor'],\n",
    "    'DF_total_tom': ['DF_total_male_tom', 'DF_total_female_tom'],\n",
    "    'DF_total_hol': ['DF_total_male_hol', 'DF_total_female_hol']\n",
    "}\n",
    "\n",
    "# Iterate through the columns and update the 'DF_total_all' dataframe using the column_map\n",
    "for column in cols_mod:\n",
    "    dfs['DF_total_all'][column] = dfs['DF_male_all'][column] + dfs['DF_female_all'][column]\n",
    "\n",
    "# Iterate through the column_map to update other dataframes\n",
    "for key, value in column_map.items():\n",
    "    for column in cols_mod:\n",
    "        dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, df in dfs.items():\n",
    "#     print(f\"DataFrame '{key}' after modification:\")\n",
    "#     print(df)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Weighted Average Column for 'perc_df_2' listed dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing dataframes from dict 'dfs' for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the new dictionary 'dfs_perc'\n",
    "dfs_perc_2 = {}\n",
    "\n",
    "# Iterate over the dataframe names in 'perc_df_2' list\n",
    "for df_name in perc_df_2:\n",
    "    # Check if the dataframe name exists in 'dfs' dictionary\n",
    "    if df_name in dfs:\n",
    "        # Move the matching dataframe from 'dfs' to 'dfs_perc_2'\n",
    "        dfs_perc_2[df_name] = dfs.pop(df_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should have 9 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(dfs_perc_2))\n",
    "# for key, df in dfs_perc_2.items():\n",
    "#     print(f\"DataFrame '{key}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''Dropping columns in list'cols_mod' to new dictionary.  Running weighted\n",
    "# average arrays in new dict 'dropped_columns' then rejoining dictionaries to the\n",
    "# affected dataframes from list 'perc_df_2'. I know, imagine how I feel, I'm the\n",
    "# one writing the things.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_columns = {}\n",
    "\n",
    "# Iterate over the dataframes in 'dfs_perc_2'\n",
    "    # Dataframe's name to 'df_name' and the dataframe itself to 'df'\n",
    "for df_name, df in dfs_perc_2.items():\n",
    "    # Store the dropped columns' data\n",
    "    dropped_columns[df_name] = df[cols_mod]\n",
    "\n",
    "    # Drop the specified columns from each dataframe\n",
    "    dfs_perc_2[df_name] = df.drop(cols_mod, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df_name, df in dropped_columns.items():\n",
    "#     # Print the name of the dataframe\n",
    "#     print(f\"DataFrame Name: {df_name}\")\n",
    "\n",
    "#     # Print the list of column names for the dataframe\n",
    "#     print(\"Column Names:\")\n",
    "#     column_names = df.columns.tolist()\n",
    "#     print(column_names)\n",
    "\n",
    "#     # Print the list of column types for the dataframe\n",
    "#     print(\"Column Types:\")\n",
    "#     column_types = df.dtypes.tolist()\n",
    "#     print(column_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding weighted Average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For DFs in dict 'dropped_columns'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dataframes in 'dropped_columns' whose name is in 'perc_df_2'\n",
    "for df_name, df in dropped_columns.items():\n",
    "    if df_name in perc_df_2:\n",
    "        # Get the column names as an array of integers from 'cols_mod'\n",
    "        values = np.array(cols_mod, dtype=int)\n",
    "\n",
    "        # Initialize an empty list to store the results\n",
    "        results = []\n",
    "\n",
    "        # Iterate over each row in the dataframe\n",
    "        for _, row in df.iterrows():\n",
    "            # Get the row entries as an array of integers\n",
    "            weights = np.array(row.values, dtype=int)\n",
    "\n",
    "            # Perform element-wise multiplication of values and weights\n",
    "            weighted_values = values * weights\n",
    "\n",
    "            # Sum the products of the multiplications\n",
    "            weighted_sum = np.sum(weighted_values)\n",
    "\n",
    "            # Sum all items in the weights array\n",
    "            weights_sum = np.sum(weights)\n",
    "\n",
    "            # Calculate the weighted average, handle division by zero\n",
    "            if weights_sum != 0:\n",
    "                weighted_average = weighted_sum / weights_sum\n",
    "            else:\n",
    "                weighted_average = np.nan\n",
    "\n",
    "            # Append the weighted average to the results list\n",
    "            results.append(weighted_average)\n",
    "\n",
    "        # Convert the results list to a float array explicitly\n",
    "        results = np.array(results, dtype=float)\n",
    "\n",
    "        # Add the 'Average_Age' column to the dataframe\n",
    "        df['Average_Age'] = results\n",
    "\n",
    "        # Reset the index of the dataframe\n",
    "        df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"DataFrame 'DF_total_all' with 'Average_Age' column:\")\n",
    "# print(dropped_columns['DF_total_all'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the dataframes in 'dfs_perc_2'\n",
    "for df_name, df_perc in dfs_perc_2.items():\n",
    "    # Get the corresponding dataframe from 'dropped_columns'\n",
    "    df_dropped = dropped_columns[df_name]\n",
    "\n",
    "    # Concatenate the dataframes width-wise\n",
    "    joined_df = pd.concat([df_perc, df_dropped], axis=1)\n",
    "\n",
    "    # Update the 'dfs_perc_2' dataframe in place with the joined dataframe\n",
    "    dfs_perc_2[df_name] = joined_df\n",
    "\n",
    "    # Reset the index of the dataframe\n",
    "    dfs_perc_2[df_name].reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dfs_perc_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the number of dataframes in the 'dfs_perc_2' dictionary\n",
    "# print(\"Number of Dataframes in 'dfs_perc_2':\", len(dfs_perc_2))\n",
    "\n",
    "# # Print the shape of the dataframes in 'dfs_perc_2'\n",
    "# print(\"Data Frames in 'dfs_perc_2':\")\n",
    "# for df_name, df in dfs_perc_2.items():\n",
    "#     print(\"Dataframe Name:\", df_name)\n",
    "#     print(\"Shape:\", df.shape)\n",
    "#     print(f\"Number of Columns: {len(df.columns)}\")\n",
    "#     print(\"Columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dfs_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the number of dataframes in the 'dfs_perc' dictionary\n",
    "# print(\"Number of Dataframes in 'dfs_perc':\", len(dfs_perc))\n",
    "\n",
    "# # Print the shape of the dataframes in 'dfs_perc'\n",
    "# print(\"Data Frames in 'dfs_perc':\")\n",
    "# for df_name, df in dfs_perc.items():\n",
    "#     print(\"Dataframe Name:\", df_name)\n",
    "#     print(\"Shape:\", df.shape)\n",
    "#     print(f\"Number of Columns: {len(df.columns)}\")\n",
    "#     print(\"Columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dropped_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the number of dataframes in the 'dropped_columns' dictionary\n",
    "# print(\"Number of Dataframes in 'dropped_columns':\", len(dropped_columns))\n",
    "\n",
    "# # Print the shape of the dataframes in 'dropped_columns'\n",
    "# print(\"Data Frames in 'dropped_columns':\")\n",
    "# for df_name, df in dropped_columns.items():\n",
    "#     print(\"Dataframe Name:\", df_name)\n",
    "#     print(\"Shape:\", df.shape)\n",
    "#     print(f\"Number of Columns: {len(df.columns)}\")\n",
    "#     print(\"Columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all the count,name,shape,# of cols, col names of the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the number of dataframes in the 'dfs' dictionary\n",
    "# print(\"Number of Dataframes in 'dfs':\", len(dfs))\n",
    "\n",
    "# # Print the shape of the dataframes in 'dfs'\n",
    "# print(\"Data Frames in 'dfs':\")\n",
    "# for df_name, df in dfs.items():\n",
    "#     print(\"Dataframe Name:\", df_name)\n",
    "#     print(\"Shape:\", df.shape)\n",
    "#     print(f\"Number of Columns: {len(df.columns)}\")\n",
    "#     print(\"Columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Percent to Total columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percent to total for ages in dfs of dict 'dfs_perc_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each dataframe in the dictionary\n",
    "for df_name, df in dfs_perc_2.items():\n",
    "    # Get the list of columns in the dataframe that match cols_mod\n",
    "    columns = [col for col in df.columns if col in cols_mod]\n",
    "    updated_columns = []\n",
    "\n",
    "    # Reset the index to consolidate memory layout\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Calculate the percentage values for the new column\n",
    "    for col in columns:\n",
    "        new_col_name = f'{col}_perc'\n",
    "        updated_columns.extend([col, new_col_name])\n",
    "\n",
    "        df[new_col_name] = [0 if total == 0 else (value / total)\n",
    "                            for value, total in zip(df[col], df['Total'])]\n",
    "\n",
    "    # Reorder the columns in the dataframe\n",
    "    df = df[updated_columns]\n",
    "\n",
    "    # Update the dataframe in the 'dfs_perc_2' dictionary\n",
    "    dfs_perc_2[df_name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"DataFrame 'DF_total_all' after modification:\")\n",
    "# print(dfs['DF_total_all'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dictionaries 'dfs' and 'dfs_perc_2' into 'dfs' in the order of 'df_names'\n",
    "for df_name in df_names:\n",
    "    if df_name in dfs_perc_2:\n",
    "        if df_name in dfs:\n",
    "            df_merged = pd.concat([dfs[df_name], dfs_perc_2[df_name]], axis=1)\n",
    "            dfs[df_name] = df_merged\n",
    "        else:\n",
    "            dfs[df_name] = dfs_perc_2[df_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file name\n",
    "file_name = '2020_agesex_statistics.xlsx'\n",
    "\n",
    "# Get the file path in the current working directory\n",
    "file_path = os.path.join(os.getcwd(), file_name)\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    # Load the existing Excel file\n",
    "    excel_file = pd.read_excel(file_path, engine='openpyxl')\n",
    "\n",
    "    # Create a new ExcelWriter object using the existing file\n",
    "    writer = pd.ExcelWriter(file_path, engine='openpyxl', if_sheet_exists='replace', mode='a')\n",
    "\n",
    "    # Iterate through the dataframes in dfs\n",
    "    for df_name, df in dfs.items():  # Use 'dfs.items()' to get the name (key) and dataframe (value)\n",
    "        # Get the name of the dataframe\n",
    "        name = df_name\n",
    "\n",
    "        # Write each dataframe to a separate sheet in the Excel file\n",
    "        df.to_excel(writer, sheet_name=name, index=False)\n",
    "\n",
    "    # Close the writer\n",
    "    writer.close()\n",
    "\n",
    "else:\n",
    "    # Create a new workbook\n",
    "    writer = pd.ExcelWriter(file_path, engine='openpyxl')\n",
    "\n",
    "    # Iterate through the dataframes in dfs\n",
    "    for df_name, df in dfs.items():  # Use 'dfs.items()' to get the name (key) and dataframe (value)\n",
    "        # Get the name of the dataframe\n",
    "        name = df_name\n",
    "\n",
    "        # Write each dataframe to a separate sheet in the Excel file\n",
    "        df.to_excel(writer, sheet_name=name, index=False)\n",
    "\n",
    "    # Close the writer\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Error Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['total_whi', 'total_baa', 'total_aian', 'total_aa', 'total_nhop',\\n       'total_sor', 'total_tom', 'total_hol'],\\n      dtype='object', name=0)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[304], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Assuming you have already loaded the 'DF_total_all' DataFrame\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[39m# Step 1: Calculate the expected total by summing the individual racial category columns\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m expected_total \u001b[39m=\u001b[39m dfs[\u001b[39m'\u001b[39;49m\u001b[39mDF_total_all\u001b[39;49m\u001b[39m'\u001b[39;49m][[\u001b[39m'\u001b[39;49m\u001b[39mtotal_whi\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtotal_baa\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtotal_aian\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtotal_aa\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtotal_nhop\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtotal_sor\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtotal_tom\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtotal_hol\u001b[39;49m\u001b[39m'\u001b[39;49m]]\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[39m# Step 2: Find the absolute error by subtracting the 'Total' column from the expected total\u001b[39;00m\n\u001b[0;32m      7\u001b[0m absolute_error \u001b[39m=\u001b[39m expected_total \u001b[39m-\u001b[39m dfs[\u001b[39m'\u001b[39m\u001b[39mDF_total_all\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mTotal\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Derek\\Desktop\\Code_Louisville\\DA_2_Project\\US-county-dashboard\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Derek\\Desktop\\Code_Louisville\\DA_2_Project\\US-county-dashboard\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5876\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5873\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5874\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5876\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5878\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   5879\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5880\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Derek\\Desktop\\Code_Louisville\\DA_2_Project\\US-county-dashboard\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5935\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5933\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5934\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 5935\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5937\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m   5938\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['total_whi', 'total_baa', 'total_aian', 'total_aa', 'total_nhop',\\n       'total_sor', 'total_tom', 'total_hol'],\\n      dtype='object', name=0)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Step 1: Calculate the expected total by summing the individual racial category columns\n",
    "expected_total = dfs['DF_total_all'][['total_whi', 'total_baa', 'total_aian', 'total_aa', 'total_nhop', 'total_sor', 'total_tom', 'total_hol']].sum(axis=1)\n",
    "\n",
    "# Step 2: Find the absolute error by subtracting the 'Total' column from the expected total\n",
    "absolute_error = expected_total - dfs['DF_total_all']['Total']\n",
    "\n",
    "# Step 3: Calculate the error rate as the absolute error divided by the expected total, multiplied by 100\n",
    "error_rate = (absolute_error / expected_total) * 100\n",
    "\n",
    "# Add the 'expected_total', 'absolute_error', and 'error_rate' columns to the DataFrame\n",
    "dfs['DF_total_all']['Expected Total'] = expected_total\n",
    "dfs['DF_total_all']['Absolute Error'] = absolute_error\n",
    "dfs['DF_total_all']['Error Rate'] = error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display the DataFrame with the added columns\n",
    "# print(dfs['DF_total_all'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating column order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the variables for column order for DF_total_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total all DF is unique and needs to be done seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_loc_tot_all = [0,'0_perc',1,'1_perc',2,'2_perc',3,'3_perc',4,'4_perc',5,\n",
    "                   '5_perc',6,'6_perc',7,'7_perc',8,'8_perc',9,'9_perc',10,\n",
    "                   '10_perc',11,'11_perc',12,'12_perc',13,'13_perc',14,\n",
    "                   '14_perc',15,'15_perc',16,'16_perc',17,'17_perc',18,\n",
    "                   '18_perc',19,'19_perc',20,'20_perc',21,'21_perc',22,\n",
    "                   '22_perc',23,'23_perc',24,'24_perc',25,'25_perc',26,\n",
    "                   '26_perc',27,'27_perc',28,'28_perc',29,'29_perc',30,\n",
    "                   '30_perc',31,'31_perc',32,'32_perc',33,'33_perc',34,\n",
    "                   '34_perc',35,'35_perc',36,'36_perc',37,'37_perc',38,\n",
    "                   '38_perc',39,'39_perc',40,'40_perc',41,'41_perc',42,\n",
    "                   '42_perc',43,'43_perc',44,'44_perc',45,'45_perc',46,\n",
    "                   '46_perc',47,'47_perc',48,'48_perc',49,'49_perc',50,\n",
    "                   '50_perc',51,'51_perc',52,'52_perc',53,'53_perc',54,\n",
    "                   '54_perc',55,'55_perc',56,'56_perc',57,'57_perc',58,\n",
    "                   '58_perc',59,'59_perc',60,'60_perc',61,'61_perc',62,\n",
    "                   '62_perc',63,'63_perc',64,'64_perc',65,'65_perc',66,\n",
    "                   '66_perc',67,'67_perc',68,'68_perc',69,'69_perc',70,\n",
    "                   '70_perc',71,'71_perc',72,'72_perc',73,'73_perc',74,\n",
    "                   '74_perc',75,'75_perc',76,'76_perc',77,'77_perc',78,\n",
    "                   '78_perc',79,'79_perc',80,'80_perc',81,'81_perc',82,\n",
    "                   '82_perc',83,'83_perc',84,'84_perc',85,'85_perc',86,\n",
    "                   '86_perc',87,'87_perc',88,'88_perc',89,'89_perc',90,\n",
    "                   '90_perc',91,'91_perc',92,'92_perc',93,'93_perc',94,\n",
    "                   '94_perc',95,'95_perc',96,'96_perc',97,'97_perc',98,\n",
    "                   '98_perc',99,'99_perc',102,'102_perc',107,'107_perc',\n",
    "                   110,'110_perc','Average_Age','male_all','female_all',\n",
    "                   'total_whi','total_baa','total_aian','total_aa',\n",
    "                   'total_nhop','total_sor','total_tom','total_hol',\n",
    "                   'Expected Total','Total','Absolute Error','Error Rate',\n",
    "                   'Location','State','County','FIPS'\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordering process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify only the 'DF_total_all' dataframe\n",
    "df = dfs['DF_total_all']\n",
    "\n",
    "# Reorder the columns in the dataframe based on 'col_loc_tot_all'\n",
    "df = df[col_loc_tot_all]\n",
    "\n",
    "# Update the dataframe in the 'dfs' dictionary\n",
    "dfs['DF_total_all'] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the variables for column order for total race dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perc_8 = ['DF_total_whi','DF_total_baa','DF_total_aian','DF_total_aa',\n",
    "             'DF_total_nhop','DF_total_sor','DF_total_tom','DF_total_hol'\n",
    "             ]\n",
    "\n",
    "col_loc = [0,'0_perc',1,'1_perc',2,'2_perc',3,'3_perc',4,'4_perc',5,'5_perc',6,\n",
    "           '6_perc',7,'7_perc',8,'8_perc',9,'9_perc',10,'10_perc',11,'11_perc',\n",
    "           12,'12_perc',13,'13_perc',14,'14_perc',15,'15_perc',16,'16_perc',17,\n",
    "           '17_perc',18,'18_perc',19,'19_perc',20,'20_perc',21,'21_perc',22,\n",
    "           '22_perc',23,'23_perc',24,'24_perc',25,'25_perc',26,'26_perc',27,\n",
    "           '27_perc',28,'28_perc',29,'29_perc',30,'30_perc',31,'31_perc',32,\n",
    "           '32_perc',33,'33_perc',34,'34_perc',35,'35_perc',36,'36_perc',37,\n",
    "           '37_perc',38,'38_perc',39,'39_perc',40,'40_perc',41,'41_perc',42,\n",
    "           '42_perc',43,'43_perc',44,'44_perc',45,'45_perc',46,'46_perc',47,\n",
    "           '47_perc',48,'48_perc',49,'49_perc',50,'50_perc',51,'51_perc',52,\n",
    "           '52_perc',53,'53_perc',54,'54_perc',55,'55_perc',56,'56_perc',57,\n",
    "           '57_perc',58,'58_perc',59,'59_perc',60,'60_perc',61,'61_perc',62,\n",
    "           '62_perc',63,'63_perc',64,'64_perc',65,'65_perc',66,'66_perc',67,\n",
    "           '67_perc',68,'68_perc',69,'69_perc',70,'70_perc',71,'71_perc',72,\n",
    "           '72_perc',73,'73_perc',74,'74_perc',75,'75_perc',76,'76_perc',77,\n",
    "           '77_perc',78,'78_perc',79,'79_perc',80,'80_perc',81,'81_perc',82,\n",
    "           '82_perc',83,'83_perc',84,'84_perc',85,'85_perc',86,'86_perc',87,\n",
    "           '87_perc',88,'88_perc',89,'89_perc',90,'90_perc',91,'91_perc',92,\n",
    "           '92_perc',93,'93_perc',94,'94_perc',95,'95_perc',96,'96_perc',97,\n",
    "           '97_perc',98,'98_perc',99,'99_perc',102,'102_perc',107,'107_perc',\n",
    "           110,'110_perc','Average_Age','Total','Location','State','County',\n",
    "           'FIPS']\n",
    "\n",
    "spec_col_dict = {\n",
    "        'DF_total_whi': ['total_male_whi','total_female_whi'],\n",
    "        'DF_total_baa': ['total_male_baa','total_female_baa'],\n",
    "        'DF_total_aian': ['total_male_aian','total_female_aian'],\n",
    "        'DF_total_aa': ['total_male_aa','total_female_aa'],\n",
    "        'DF_total_nhop': ['total_male_nhop','total_female_nhop'],\n",
    "        'DF_total_sor': ['total_male_sor','total_female_sor'],\n",
    "        'DF_total_tom': ['total_male_tom','total_female_tom'],\n",
    "        'DF_total_hol': ['total_male_hol','total_female_hol'],\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordering process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the index where you want to insert the specific columns\n",
    "insert_index = 207  \n",
    "\n",
    "# Iterate through the list of dataframe names\n",
    "for df_name in df_perc_8:\n",
    "    # Get the dataframe from the 'dfs' dictionary\n",
    "    df = dfs[df_name]\n",
    "\n",
    "    # Get the specific column names for the current dataframe\n",
    "    df_spec_col_dict = spec_col_dict[df_name]\n",
    "\n",
    "    # Separate the columns into two groups: common columns and specific columns\n",
    "    common_columns = [col for col in col_loc if col not in df_spec_col_dict]\n",
    "    specific_columns = df_spec_col_dict\n",
    "\n",
    "    # Reorder the common columns in the dataframe\n",
    "    df_common_reordered = df[common_columns]\n",
    "\n",
    "    # Reindex the dataframe with the updated column order\n",
    "    updated_columns = common_columns[:insert_index] + specific_columns + common_columns[insert_index:]\n",
    "    df = df_common_reordered.reindex(columns=updated_columns)\n",
    "\n",
    "    # Update the dataframe in the 'dfs' dictionary\n",
    "    dfs[df_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create workbook and export wanted dataframes to excel as individual sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file name\n",
    "file_name = '2020_agesex_statistics.xlsx'\n",
    "\n",
    "# Get the file path in the current working directory\n",
    "file_path = os.path.join(os.getcwd(), file_name)\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    # Load the existing Excel file\n",
    "    excel_file = pd.read_excel(file_path, engine='openpyxl')\n",
    "\n",
    "    # Create a new ExcelWriter object using the existing file\n",
    "    writer = pd.ExcelWriter(file_path, engine='openpyxl', if_sheet_exists='replace', mode='a')\n",
    "\n",
    "    # Iterate through the dataframes in dfs\n",
    "    for df_name, df in dfs.items():  # Use 'dfs.items()' to get the name (key) and dataframe (value)\n",
    "        # Get the name of the dataframe\n",
    "        name = df_name\n",
    "\n",
    "        # Write each dataframe to a separate sheet in the Excel file\n",
    "        df.to_excel(writer, sheet_name=name, index=False)\n",
    "\n",
    "    # Close the writer\n",
    "    writer.close()\n",
    "\n",
    "else:\n",
    "    # Create a new workbook\n",
    "    writer = pd.ExcelWriter(file_path, engine='openpyxl')\n",
    "\n",
    "    # Iterate through the dataframes in dfs\n",
    "    for df_name, df in dfs.items():  # Use 'dfs.items()' to get the name (key) and dataframe (value)\n",
    "        # Get the name of the dataframe\n",
    "        name = df_name\n",
    "\n",
    "        # Write each dataframe to a separate sheet in the Excel file\n",
    "        df.to_excel(writer, sheet_name=name, index=False)\n",
    "\n",
    "    # Close the writer\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
