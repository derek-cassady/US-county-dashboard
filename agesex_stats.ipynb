{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age & Sex Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import workbook, load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import numpy as np\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading file to dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of dataframes and their proper order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating ordered list of DFs to name each sheet coming in from workbook\n",
    "df_names = ['DF_total_all','DF_male_all','DF_female_all','DF_total_whi',\n",
    "            'DF_total_male_whi','DF_total_female_whi','DF_total_baa',\n",
    "            'DF_total_male_baa','DF_total_female_baa','DF_total_aian',\n",
    "            'DF_total_male_aian','DF_total_female_aian','DF_total_aa',\n",
    "            'DF_total_male_aa','DF_total_female_aa','DF_total_nhop',\n",
    "            'DF_total_male_nhop','DF_total_female_nhop','DF_total_sor',\n",
    "            'DF_total_male_sor','DF_total_female_sor','DF_total_tom',\n",
    "            'DF_total_male_tom','DF_total_female_tom','DF_total_hol',\n",
    "            'DF_total_male_hol','DF_total_female_hol'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables for column names and type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_int = ['Under 1 Year','1 Year','2 Years','3 Years','4 Years','5 Years',\n",
    "            '6 Years','7 Years','8 Years','9 Years','10 Years','11 Years',\n",
    "            '12 Years','13 Years','14 Years','15 Years','16 Years','17 Years',\n",
    "            '18 Years','19 Years','20 Years','21 Years','22 Years','23 Years',\n",
    "            '24 Years','25 Years','26 Years','27 Years','28 Years','29 Years',\n",
    "            '30 Years','31 Years','32 Years','33 Years','34 Years','35 Years',\n",
    "            '36 Years','37 Years','38 Years','39 Years','40 Years','41 Years',\n",
    "            '42 Years','43 Years','44 Years','45 Years','46 Years','47 Years',\n",
    "            '48 Years','49 Years','50 Years','51 Years','52 Years','53 Years',\n",
    "            '54 Years','55 Years','56 Years','57 Years','58 Years','59 Years',\n",
    "            '60 Years','61 Years','62 Years','63 Years','64 Years','65 Years',\n",
    "            '66 Years','67 Years','68 Years','69 Years','70 Years','71 Years',\n",
    "            '72 Years','73 Years','74 Years','75 Years','76 Years','77 Years',\n",
    "            '78 Years','79 Years','80 Years','81 Years','82 Years','83 Years',\n",
    "            '84 Years','85 Years','86 Years','87 Years','88 Years','89 Years',\n",
    "            '90 Years','91 Years','92 Years','93 Years','94 Years','95 Years',\n",
    "            '96 Years','97  Years','98  Years','99  Years','100 to 104  Years',\n",
    "            '105 to 109  Years','110  Years and Over'\n",
    "            ]\n",
    "\n",
    "cols_str = ['Location', 'State', 'County', 'FIPS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the dataframes\n",
    "dfs = {}\n",
    "\n",
    "# Get the path of the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Construct the full path to the .xlsx file\n",
    "file_path = os.path.join(cwd, '2020_agesex_data.xlsx')\n",
    "\n",
    "# Load each sheet of the .xlsx file into a named dataframe\n",
    "for name in df_names:\n",
    "    df = pd.read_excel(file_path, sheet_name=name, header=None)  # Specify header=None to treat the first row as data\n",
    "    df.columns = df.iloc[0]  # Set the first row as the column headers\n",
    "    df = df[1:]  # Exclude the first row from the data\n",
    "    df.reset_index(drop=True, inplace=True)  # Reset the index\n",
    "    \n",
    "    # Change column types based on column names\n",
    "    for column in cols_int:\n",
    "        if column in df.columns:\n",
    "            df[column] = df[column].astype(int)\n",
    "    \n",
    "    for column in cols_str:\n",
    "        if column in df.columns:\n",
    "            df[column] = df[column].astype(str)\n",
    "    \n",
    "    dfs[name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all the names, shapes, and dtypes of the dataframes loaded in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frames in 'dfs':\n",
      "DF_total_all\n",
      "Shape: (3221, 5)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_male_all\n",
      "Shape: (3221, 108)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Under 1 Year: int32\n",
      "1 Year: int32\n",
      "2 Years: int32\n",
      "3 Years: int32\n",
      "4 Years: int32\n",
      "5 Years: int32\n",
      "6 Years: int32\n",
      "7 Years: int32\n",
      "8 Years: int32\n",
      "9 Years: int32\n",
      "10 Years: int32\n",
      "11 Years: int32\n",
      "12 Years: int32\n",
      "13 Years: int32\n",
      "14 Years: int32\n",
      "15 Years: int32\n",
      "16 Years: int32\n",
      "17 Years: int32\n",
      "18 Years: int32\n",
      "19 Years: int32\n",
      "20 Years: int32\n",
      "21 Years: int32\n",
      "22 Years: int32\n",
      "23 Years: int32\n",
      "24 Years: int32\n",
      "25 Years: int32\n",
      "26 Years: int32\n",
      "27 Years: int32\n",
      "28 Years: int32\n",
      "29 Years: int32\n",
      "30 Years: int32\n",
      "31 Years: int32\n",
      "32 Years: int32\n",
      "33 Years: int32\n",
      "34 Years: int32\n",
      "35 Years: int32\n",
      "36 Years: int32\n",
      "37 Years: int32\n",
      "38 Years: int32\n",
      "39 Years: int32\n",
      "40 Years: int32\n",
      "41 Years: int32\n",
      "42 Years: int32\n",
      "43 Years: int32\n",
      "44 Years: int32\n",
      "45 Years: int32\n",
      "46 Years: int32\n",
      "47 Years: int32\n",
      "48 Years: int32\n",
      "49 Years: int32\n",
      "50 Years: int32\n",
      "51 Years: int32\n",
      "52 Years: int32\n",
      "53 Years: int32\n",
      "54 Years: int32\n",
      "55 Years: int32\n",
      "56 Years: int32\n",
      "57 Years: int32\n",
      "58 Years: int32\n",
      "59 Years: int32\n",
      "60 Years: int32\n",
      "61 Years: int32\n",
      "62 Years: int32\n",
      "63 Years: int32\n",
      "64 Years: int32\n",
      "65 Years: int32\n",
      "66 Years: int32\n",
      "67 Years: int32\n",
      "68 Years: int32\n",
      "69 Years: int32\n",
      "70 Years: int32\n",
      "71 Years: int32\n",
      "72 Years: int32\n",
      "73 Years: int32\n",
      "74 Years: int32\n",
      "75 Years: int32\n",
      "76 Years: int32\n",
      "77 Years: int32\n",
      "78 Years: int32\n",
      "79 Years: int32\n",
      "80 Years: int32\n",
      "81 Years: int32\n",
      "82 Years: int32\n",
      "83 Years: int32\n",
      "84 Years: int32\n",
      "85 Years: int32\n",
      "86 Years: int32\n",
      "87 Years: int32\n",
      "88 Years: int32\n",
      "89 Years: int32\n",
      "90 Years: int32\n",
      "91 Years: int32\n",
      "92 Years: int32\n",
      "93 Years: int32\n",
      "94 Years: int32\n",
      "95 Years: int32\n",
      "96 Years: int32\n",
      "97  Years: int32\n",
      "98  Years: int32\n",
      "99  Years: int32\n",
      "100 to 104  Years: int32\n",
      "105 to 109  Years: int32\n",
      "110  Years and Over: int32\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_female_all\n",
      "Shape: (3221, 108)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Under 1 Year: int32\n",
      "1 Year: int32\n",
      "2 Years: int32\n",
      "3 Years: int32\n",
      "4 Years: int32\n",
      "5 Years: int32\n",
      "6 Years: int32\n",
      "7 Years: int32\n",
      "8 Years: int32\n",
      "9 Years: int32\n",
      "10 Years: int32\n",
      "11 Years: int32\n",
      "12 Years: int32\n",
      "13 Years: int32\n",
      "14 Years: int32\n",
      "15 Years: int32\n",
      "16 Years: int32\n",
      "17 Years: int32\n",
      "18 Years: int32\n",
      "19 Years: int32\n",
      "20 Years: int32\n",
      "21 Years: int32\n",
      "22 Years: int32\n",
      "23 Years: int32\n",
      "24 Years: int32\n",
      "25 Years: int32\n",
      "26 Years: int32\n",
      "27 Years: int32\n",
      "28 Years: int32\n",
      "29 Years: int32\n",
      "30 Years: int32\n",
      "31 Years: int32\n",
      "32 Years: int32\n",
      "33 Years: int32\n",
      "34 Years: int32\n",
      "35 Years: int32\n",
      "36 Years: int32\n",
      "37 Years: int32\n",
      "38 Years: int32\n",
      "39 Years: int32\n",
      "40 Years: int32\n",
      "41 Years: int32\n",
      "42 Years: int32\n",
      "43 Years: int32\n",
      "44 Years: int32\n",
      "45 Years: int32\n",
      "46 Years: int32\n",
      "47 Years: int32\n",
      "48 Years: int32\n",
      "49 Years: int32\n",
      "50 Years: int32\n",
      "51 Years: int32\n",
      "52 Years: int32\n",
      "53 Years: int32\n",
      "54 Years: int32\n",
      "55 Years: int32\n",
      "56 Years: int32\n",
      "57 Years: int32\n",
      "58 Years: int32\n",
      "59 Years: int32\n",
      "60 Years: int32\n",
      "61 Years: int32\n",
      "62 Years: int32\n",
      "63 Years: int32\n",
      "64 Years: int32\n",
      "65 Years: int32\n",
      "66 Years: int32\n",
      "67 Years: int32\n",
      "68 Years: int32\n",
      "69 Years: int32\n",
      "70 Years: int32\n",
      "71 Years: int32\n",
      "72 Years: int32\n",
      "73 Years: int32\n",
      "74 Years: int32\n",
      "75 Years: int32\n",
      "76 Years: int32\n",
      "77 Years: int32\n",
      "78 Years: int32\n",
      "79 Years: int32\n",
      "80 Years: int32\n",
      "81 Years: int32\n",
      "82 Years: int32\n",
      "83 Years: int32\n",
      "84 Years: int32\n",
      "85 Years: int32\n",
      "86 Years: int32\n",
      "87 Years: int32\n",
      "88 Years: int32\n",
      "89 Years: int32\n",
      "90 Years: int32\n",
      "91 Years: int32\n",
      "92 Years: int32\n",
      "93 Years: int32\n",
      "94 Years: int32\n",
      "95 Years: int32\n",
      "96 Years: int32\n",
      "97  Years: int32\n",
      "98  Years: int32\n",
      "99  Years: int32\n",
      "100 to 104  Years: int32\n",
      "105 to 109  Years: int32\n",
      "110  Years and Over: int32\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_whi\n",
      "Shape: (3221, 5)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_male_whi\n",
      "Shape: (3221, 108)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Under 1 Year: int32\n",
      "1 Year: int32\n",
      "2 Years: int32\n",
      "3 Years: int32\n",
      "4 Years: int32\n",
      "5 Years: int32\n",
      "6 Years: int32\n",
      "7 Years: int32\n",
      "8 Years: int32\n",
      "9 Years: int32\n",
      "10 Years: int32\n",
      "11 Years: int32\n",
      "12 Years: int32\n",
      "13 Years: int32\n",
      "14 Years: int32\n",
      "15 Years: int32\n",
      "16 Years: int32\n",
      "17 Years: int32\n",
      "18 Years: int32\n",
      "19 Years: int32\n",
      "20 Years: int32\n",
      "21 Years: int32\n",
      "22 Years: int32\n",
      "23 Years: int32\n",
      "24 Years: int32\n",
      "25 Years: int32\n",
      "26 Years: int32\n",
      "27 Years: int32\n",
      "28 Years: int32\n",
      "29 Years: int32\n",
      "30 Years: int32\n",
      "31 Years: int32\n",
      "32 Years: int32\n",
      "33 Years: int32\n",
      "34 Years: int32\n",
      "35 Years: int32\n",
      "36 Years: int32\n",
      "37 Years: int32\n",
      "38 Years: int32\n",
      "39 Years: int32\n",
      "40 Years: int32\n",
      "41 Years: int32\n",
      "42 Years: int32\n",
      "43 Years: int32\n",
      "44 Years: int32\n",
      "45 Years: int32\n",
      "46 Years: int32\n",
      "47 Years: int32\n",
      "48 Years: int32\n",
      "49 Years: int32\n",
      "50 Years: int32\n",
      "51 Years: int32\n",
      "52 Years: int32\n",
      "53 Years: int32\n",
      "54 Years: int32\n",
      "55 Years: int32\n",
      "56 Years: int32\n",
      "57 Years: int32\n",
      "58 Years: int32\n",
      "59 Years: int32\n",
      "60 Years: int32\n",
      "61 Years: int32\n",
      "62 Years: int32\n",
      "63 Years: int32\n",
      "64 Years: int32\n",
      "65 Years: int32\n",
      "66 Years: int32\n",
      "67 Years: int32\n",
      "68 Years: int32\n",
      "69 Years: int32\n",
      "70 Years: int32\n",
      "71 Years: int32\n",
      "72 Years: int32\n",
      "73 Years: int32\n",
      "74 Years: int32\n",
      "75 Years: int32\n",
      "76 Years: int32\n",
      "77 Years: int32\n",
      "78 Years: int32\n",
      "79 Years: int32\n",
      "80 Years: int32\n",
      "81 Years: int32\n",
      "82 Years: int32\n",
      "83 Years: int32\n",
      "84 Years: int32\n",
      "85 Years: int32\n",
      "86 Years: int32\n",
      "87 Years: int32\n",
      "88 Years: int32\n",
      "89 Years: int32\n",
      "90 Years: int32\n",
      "91 Years: int32\n",
      "92 Years: int32\n",
      "93 Years: int32\n",
      "94 Years: int32\n",
      "95 Years: int32\n",
      "96 Years: int32\n",
      "97  Years: int32\n",
      "98  Years: int32\n",
      "99  Years: int32\n",
      "100 to 104  Years: int32\n",
      "105 to 109  Years: int32\n",
      "110  Years and Over: int32\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_female_whi\n",
      "Shape: (3221, 108)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Under 1 Year: int32\n",
      "1 Year: int32\n",
      "2 Years: int32\n",
      "3 Years: int32\n",
      "4 Years: int32\n",
      "5 Years: int32\n",
      "6 Years: int32\n",
      "7 Years: int32\n",
      "8 Years: int32\n",
      "9 Years: int32\n",
      "10 Years: int32\n",
      "11 Years: int32\n",
      "12 Years: int32\n",
      "13 Years: int32\n",
      "14 Years: int32\n",
      "15 Years: int32\n",
      "16 Years: int32\n",
      "17 Years: int32\n",
      "18 Years: int32\n",
      "19 Years: int32\n",
      "20 Years: int32\n",
      "21 Years: int32\n",
      "22 Years: int32\n",
      "23 Years: int32\n",
      "24 Years: int32\n",
      "25 Years: int32\n",
      "26 Years: int32\n",
      "27 Years: int32\n",
      "28 Years: int32\n",
      "29 Years: int32\n",
      "30 Years: int32\n",
      "31 Years: int32\n",
      "32 Years: int32\n",
      "33 Years: int32\n",
      "34 Years: int32\n",
      "35 Years: int32\n",
      "36 Years: int32\n",
      "37 Years: int32\n",
      "38 Years: int32\n",
      "39 Years: int32\n",
      "40 Years: int32\n",
      "41 Years: int32\n",
      "42 Years: int32\n",
      "43 Years: int32\n",
      "44 Years: int32\n",
      "45 Years: int32\n",
      "46 Years: int32\n",
      "47 Years: int32\n",
      "48 Years: int32\n",
      "49 Years: int32\n",
      "50 Years: int32\n",
      "51 Years: int32\n",
      "52 Years: int32\n",
      "53 Years: int32\n",
      "54 Years: int32\n",
      "55 Years: int32\n",
      "56 Years: int32\n",
      "57 Years: int32\n",
      "58 Years: int32\n",
      "59 Years: int32\n",
      "60 Years: int32\n",
      "61 Years: int32\n",
      "62 Years: int32\n",
      "63 Years: int32\n",
      "64 Years: int32\n",
      "65 Years: int32\n",
      "66 Years: int32\n",
      "67 Years: int32\n",
      "68 Years: int32\n",
      "69 Years: int32\n",
      "70 Years: int32\n",
      "71 Years: int32\n",
      "72 Years: int32\n",
      "73 Years: int32\n",
      "74 Years: int32\n",
      "75 Years: int32\n",
      "76 Years: int32\n",
      "77 Years: int32\n",
      "78 Years: int32\n",
      "79 Years: int32\n",
      "80 Years: int32\n",
      "81 Years: int32\n",
      "82 Years: int32\n",
      "83 Years: int32\n",
      "84 Years: int32\n",
      "85 Years: int32\n",
      "86 Years: int32\n",
      "87 Years: int32\n",
      "88 Years: int32\n",
      "89 Years: int32\n",
      "90 Years: int32\n",
      "91 Years: int32\n",
      "92 Years: int32\n",
      "93 Years: int32\n",
      "94 Years: int32\n",
      "95 Years: int32\n",
      "96 Years: int32\n",
      "97  Years: int32\n",
      "98  Years: int32\n",
      "99  Years: int32\n",
      "100 to 104  Years: int32\n",
      "105 to 109  Years: int32\n",
      "110  Years and Over: int32\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_baa\n",
      "Shape: (3221, 5)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_male_baa\n",
      "Shape: (3221, 108)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Under 1 Year: int32\n",
      "1 Year: int32\n",
      "2 Years: int32\n",
      "3 Years: int32\n",
      "4 Years: int32\n",
      "5 Years: int32\n",
      "6 Years: int32\n",
      "7 Years: int32\n",
      "8 Years: int32\n",
      "9 Years: int32\n",
      "10 Years: int32\n",
      "11 Years: int32\n",
      "12 Years: int32\n",
      "13 Years: int32\n",
      "14 Years: int32\n",
      "15 Years: int32\n",
      "16 Years: int32\n",
      "17 Years: int32\n",
      "18 Years: int32\n",
      "19 Years: int32\n",
      "20 Years: int32\n",
      "21 Years: int32\n",
      "22 Years: int32\n",
      "23 Years: int32\n",
      "24 Years: int32\n",
      "25 Years: int32\n",
      "26 Years: int32\n",
      "27 Years: int32\n",
      "28 Years: int32\n",
      "29 Years: int32\n",
      "30 Years: int32\n",
      "31 Years: int32\n",
      "32 Years: int32\n",
      "33 Years: int32\n",
      "34 Years: int32\n",
      "35 Years: int32\n",
      "36 Years: int32\n",
      "37 Years: int32\n",
      "38 Years: int32\n",
      "39 Years: int32\n",
      "40 Years: int32\n",
      "41 Years: int32\n",
      "42 Years: int32\n",
      "43 Years: int32\n",
      "44 Years: int32\n",
      "45 Years: int32\n",
      "46 Years: int32\n",
      "47 Years: int32\n",
      "48 Years: int32\n",
      "49 Years: int32\n",
      "50 Years: int32\n",
      "51 Years: int32\n",
      "52 Years: int32\n",
      "53 Years: int32\n",
      "54 Years: int32\n",
      "55 Years: int32\n",
      "56 Years: int32\n",
      "57 Years: int32\n",
      "58 Years: int32\n",
      "59 Years: int32\n",
      "60 Years: int32\n",
      "61 Years: int32\n",
      "62 Years: int32\n",
      "63 Years: int32\n",
      "64 Years: int32\n",
      "65 Years: int32\n",
      "66 Years: int32\n",
      "67 Years: int32\n",
      "68 Years: int32\n",
      "69 Years: int32\n",
      "70 Years: int32\n",
      "71 Years: int32\n",
      "72 Years: int32\n",
      "73 Years: int32\n",
      "74 Years: int32\n",
      "75 Years: int32\n",
      "76 Years: int32\n",
      "77 Years: int32\n",
      "78 Years: int32\n",
      "79 Years: int32\n",
      "80 Years: int32\n",
      "81 Years: int32\n",
      "82 Years: int32\n",
      "83 Years: int32\n",
      "84 Years: int32\n",
      "85 Years: int32\n",
      "86 Years: int32\n",
      "87 Years: int32\n",
      "88 Years: int32\n",
      "89 Years: int32\n",
      "90 Years: int32\n",
      "91 Years: int32\n",
      "92 Years: int32\n",
      "93 Years: int32\n",
      "94 Years: int32\n",
      "95 Years: int32\n",
      "96 Years: int32\n",
      "97  Years: int32\n",
      "98  Years: int32\n",
      "99  Years: int32\n",
      "100 to 104  Years: int32\n",
      "105 to 109  Years: int32\n",
      "110  Years and Over: int32\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_female_baa\n",
      "Shape: (3221, 108)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Under 1 Year: int32\n",
      "1 Year: int32\n",
      "2 Years: int32\n",
      "3 Years: int32\n",
      "4 Years: int32\n",
      "5 Years: int32\n",
      "6 Years: int32\n",
      "7 Years: int32\n",
      "8 Years: int32\n",
      "9 Years: int32\n",
      "10 Years: int32\n",
      "11 Years: int32\n",
      "12 Years: int32\n",
      "13 Years: int32\n",
      "14 Years: int32\n",
      "15 Years: int32\n",
      "16 Years: int32\n",
      "17 Years: int32\n",
      "18 Years: int32\n",
      "19 Years: int32\n",
      "20 Years: int32\n",
      "21 Years: int32\n",
      "22 Years: int32\n",
      "23 Years: int32\n",
      "24 Years: int32\n",
      "25 Years: int32\n",
      "26 Years: int32\n",
      "27 Years: int32\n",
      "28 Years: int32\n",
      "29 Years: int32\n",
      "30 Years: int32\n",
      "31 Years: int32\n",
      "32 Years: int32\n",
      "33 Years: int32\n",
      "34 Years: int32\n",
      "35 Years: int32\n",
      "36 Years: int32\n",
      "37 Years: int32\n",
      "38 Years: int32\n",
      "39 Years: int32\n",
      "40 Years: int32\n",
      "41 Years: int32\n",
      "42 Years: int32\n",
      "43 Years: int32\n",
      "44 Years: int32\n",
      "45 Years: int32\n",
      "46 Years: int32\n",
      "47 Years: int32\n",
      "48 Years: int32\n",
      "49 Years: int32\n",
      "50 Years: int32\n",
      "51 Years: int32\n",
      "52 Years: int32\n",
      "53 Years: int32\n",
      "54 Years: int32\n",
      "55 Years: int32\n",
      "56 Years: int32\n",
      "57 Years: int32\n",
      "58 Years: int32\n",
      "59 Years: int32\n",
      "60 Years: int32\n",
      "61 Years: int32\n",
      "62 Years: int32\n",
      "63 Years: int32\n",
      "64 Years: int32\n",
      "65 Years: int32\n",
      "66 Years: int32\n",
      "67 Years: int32\n",
      "68 Years: int32\n",
      "69 Years: int32\n",
      "70 Years: int32\n",
      "71 Years: int32\n",
      "72 Years: int32\n",
      "73 Years: int32\n",
      "74 Years: int32\n",
      "75 Years: int32\n",
      "76 Years: int32\n",
      "77 Years: int32\n",
      "78 Years: int32\n",
      "79 Years: int32\n",
      "80 Years: int32\n",
      "81 Years: int32\n",
      "82 Years: int32\n",
      "83 Years: int32\n",
      "84 Years: int32\n",
      "85 Years: int32\n",
      "86 Years: int32\n",
      "87 Years: int32\n",
      "88 Years: int32\n",
      "89 Years: int32\n",
      "90 Years: int32\n",
      "91 Years: int32\n",
      "92 Years: int32\n",
      "93 Years: int32\n",
      "94 Years: int32\n",
      "95 Years: int32\n",
      "96 Years: int32\n",
      "97  Years: int32\n",
      "98  Years: int32\n",
      "99  Years: int32\n",
      "100 to 104  Years: int32\n",
      "105 to 109  Years: int32\n",
      "110  Years and Over: int32\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_aian\n",
      "Shape: (3221, 5)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_male_aian\n",
      "Shape: (3221, 108)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Under 1 Year: int32\n",
      "1 Year: int32\n",
      "2 Years: int32\n",
      "3 Years: int32\n",
      "4 Years: int32\n",
      "5 Years: int32\n",
      "6 Years: int32\n",
      "7 Years: int32\n",
      "8 Years: int32\n",
      "9 Years: int32\n",
      "10 Years: int32\n",
      "11 Years: int32\n",
      "12 Years: int32\n",
      "13 Years: int32\n",
      "14 Years: int32\n",
      "15 Years: int32\n",
      "16 Years: int32\n",
      "17 Years: int32\n",
      "18 Years: int32\n",
      "19 Years: int32\n",
      "20 Years: int32\n",
      "21 Years: int32\n",
      "22 Years: int32\n",
      "23 Years: int32\n",
      "24 Years: int32\n",
      "25 Years: int32\n",
      "26 Years: int32\n",
      "27 Years: int32\n",
      "28 Years: int32\n",
      "29 Years: int32\n",
      "30 Years: int32\n",
      "31 Years: int32\n",
      "32 Years: int32\n",
      "33 Years: int32\n",
      "34 Years: int32\n",
      "35 Years: int32\n",
      "36 Years: int32\n",
      "37 Years: int32\n",
      "38 Years: int32\n",
      "39 Years: int32\n",
      "40 Years: int32\n",
      "41 Years: int32\n",
      "42 Years: int32\n",
      "43 Years: int32\n",
      "44 Years: int32\n",
      "45 Years: int32\n",
      "46 Years: int32\n",
      "47 Years: int32\n",
      "48 Years: int32\n",
      "49 Years: int32\n",
      "50 Years: int32\n",
      "51 Years: int32\n",
      "52 Years: int32\n",
      "53 Years: int32\n",
      "54 Years: int32\n",
      "55 Years: int32\n",
      "56 Years: int32\n",
      "57 Years: int32\n",
      "58 Years: int32\n",
      "59 Years: int32\n",
      "60 Years: int32\n",
      "61 Years: int32\n",
      "62 Years: int32\n",
      "63 Years: int32\n",
      "64 Years: int32\n",
      "65 Years: int32\n",
      "66 Years: int32\n",
      "67 Years: int32\n",
      "68 Years: int32\n",
      "69 Years: int32\n",
      "70 Years: int32\n",
      "71 Years: int32\n",
      "72 Years: int32\n",
      "73 Years: int32\n",
      "74 Years: int32\n",
      "75 Years: int32\n",
      "76 Years: int32\n",
      "77 Years: int32\n",
      "78 Years: int32\n",
      "79 Years: int32\n",
      "80 Years: int32\n",
      "81 Years: int32\n",
      "82 Years: int32\n",
      "83 Years: int32\n",
      "84 Years: int32\n",
      "85 Years: int32\n",
      "86 Years: int32\n",
      "87 Years: int32\n",
      "88 Years: int32\n",
      "89 Years: int32\n",
      "90 Years: int32\n",
      "91 Years: int32\n",
      "92 Years: int32\n",
      "93 Years: int32\n",
      "94 Years: int32\n",
      "95 Years: int32\n",
      "96 Years: int32\n",
      "97  Years: int32\n",
      "98  Years: int32\n",
      "99  Years: int32\n",
      "100 to 104  Years: int32\n",
      "105 to 109  Years: int32\n",
      "110  Years and Over: int32\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_female_aian\n",
      "Shape: (3221, 108)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Under 1 Year: int32\n",
      "1 Year: int32\n",
      "2 Years: int32\n",
      "3 Years: int32\n",
      "4 Years: int32\n",
      "5 Years: int32\n",
      "6 Years: int32\n",
      "7 Years: int32\n",
      "8 Years: int32\n",
      "9 Years: int32\n",
      "10 Years: int32\n",
      "11 Years: int32\n",
      "12 Years: int32\n",
      "13 Years: int32\n",
      "14 Years: int32\n",
      "15 Years: int32\n",
      "16 Years: int32\n",
      "17 Years: int32\n",
      "18 Years: int32\n",
      "19 Years: int32\n",
      "20 Years: int32\n",
      "21 Years: int32\n",
      "22 Years: int32\n",
      "23 Years: int32\n",
      "24 Years: int32\n",
      "25 Years: int32\n",
      "26 Years: int32\n",
      "27 Years: int32\n",
      "28 Years: int32\n",
      "29 Years: int32\n",
      "30 Years: int32\n",
      "31 Years: int32\n",
      "32 Years: int32\n",
      "33 Years: int32\n",
      "34 Years: int32\n",
      "35 Years: int32\n",
      "36 Years: int32\n",
      "37 Years: int32\n",
      "38 Years: int32\n",
      "39 Years: int32\n",
      "40 Years: int32\n",
      "41 Years: int32\n",
      "42 Years: int32\n",
      "43 Years: int32\n",
      "44 Years: int32\n",
      "45 Years: int32\n",
      "46 Years: int32\n",
      "47 Years: int32\n",
      "48 Years: int32\n",
      "49 Years: int32\n",
      "50 Years: int32\n",
      "51 Years: int32\n",
      "52 Years: int32\n",
      "53 Years: int32\n",
      "54 Years: int32\n",
      "55 Years: int32\n",
      "56 Years: int32\n",
      "57 Years: int32\n",
      "58 Years: int32\n",
      "59 Years: int32\n",
      "60 Years: int32\n",
      "61 Years: int32\n",
      "62 Years: int32\n",
      "63 Years: int32\n",
      "64 Years: int32\n",
      "65 Years: int32\n",
      "66 Years: int32\n",
      "67 Years: int32\n",
      "68 Years: int32\n",
      "69 Years: int32\n",
      "70 Years: int32\n",
      "71 Years: int32\n",
      "72 Years: int32\n",
      "73 Years: int32\n",
      "74 Years: int32\n",
      "75 Years: int32\n",
      "76 Years: int32\n",
      "77 Years: int32\n",
      "78 Years: int32\n",
      "79 Years: int32\n",
      "80 Years: int32\n",
      "81 Years: int32\n",
      "82 Years: int32\n",
      "83 Years: int32\n",
      "84 Years: int32\n",
      "85 Years: int32\n",
      "86 Years: int32\n",
      "87 Years: int32\n",
      "88 Years: int32\n",
      "89 Years: int32\n",
      "90 Years: int32\n",
      "91 Years: int32\n",
      "92 Years: int32\n",
      "93 Years: int32\n",
      "94 Years: int32\n",
      "95 Years: int32\n",
      "96 Years: int32\n",
      "97  Years: int32\n",
      "98  Years: int32\n",
      "99  Years: int32\n",
      "100 to 104  Years: int32\n",
      "105 to 109  Years: int32\n",
      "110  Years and Over: int32\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_aa\n",
      "Shape: (3221, 5)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_male_aa\n",
      "Shape: (3221, 108)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Under 1 Year: int32\n",
      "1 Year: int32\n",
      "2 Years: int32\n",
      "3 Years: int32\n",
      "4 Years: int32\n",
      "5 Years: int32\n",
      "6 Years: int32\n",
      "7 Years: int32\n",
      "8 Years: int32\n",
      "9 Years: int32\n",
      "10 Years: int32\n",
      "11 Years: int32\n",
      "12 Years: int32\n",
      "13 Years: int32\n",
      "14 Years: int32\n",
      "15 Years: int32\n",
      "16 Years: int32\n",
      "17 Years: int32\n",
      "18 Years: int32\n",
      "19 Years: int32\n",
      "20 Years: int32\n",
      "21 Years: int32\n",
      "22 Years: int32\n",
      "23 Years: int32\n",
      "24 Years: int32\n",
      "25 Years: int32\n",
      "26 Years: int32\n",
      "27 Years: int32\n",
      "28 Years: int32\n",
      "29 Years: int32\n",
      "30 Years: int32\n",
      "31 Years: int32\n",
      "32 Years: int32\n",
      "33 Years: int32\n",
      "34 Years: int32\n",
      "35 Years: int32\n",
      "36 Years: int32\n",
      "37 Years: int32\n",
      "38 Years: int32\n",
      "39 Years: int32\n",
      "40 Years: int32\n",
      "41 Years: int32\n",
      "42 Years: int32\n",
      "43 Years: int32\n",
      "44 Years: int32\n",
      "45 Years: int32\n",
      "46 Years: int32\n",
      "47 Years: int32\n",
      "48 Years: int32\n",
      "49 Years: int32\n",
      "50 Years: int32\n",
      "51 Years: int32\n",
      "52 Years: int32\n",
      "53 Years: int32\n",
      "54 Years: int32\n",
      "55 Years: int32\n",
      "56 Years: int32\n",
      "57 Years: int32\n",
      "58 Years: int32\n",
      "59 Years: int32\n",
      "60 Years: int32\n",
      "61 Years: int32\n",
      "62 Years: int32\n",
      "63 Years: int32\n",
      "64 Years: int32\n",
      "65 Years: int32\n",
      "66 Years: int32\n",
      "67 Years: int32\n",
      "68 Years: int32\n",
      "69 Years: int32\n",
      "70 Years: int32\n",
      "71 Years: int32\n",
      "72 Years: int32\n",
      "73 Years: int32\n",
      "74 Years: int32\n",
      "75 Years: int32\n",
      "76 Years: int32\n",
      "77 Years: int32\n",
      "78 Years: int32\n",
      "79 Years: int32\n",
      "80 Years: int32\n",
      "81 Years: int32\n",
      "82 Years: int32\n",
      "83 Years: int32\n",
      "84 Years: int32\n",
      "85 Years: int32\n",
      "86 Years: int32\n",
      "87 Years: int32\n",
      "88 Years: int32\n",
      "89 Years: int32\n",
      "90 Years: int32\n",
      "91 Years: int32\n",
      "92 Years: int32\n",
      "93 Years: int32\n",
      "94 Years: int32\n",
      "95 Years: int32\n",
      "96 Years: int32\n",
      "97  Years: int32\n",
      "98  Years: int32\n",
      "99  Years: int32\n",
      "100 to 104  Years: int32\n",
      "105 to 109  Years: int32\n",
      "110  Years and Over: int32\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_female_aa\n",
      "Shape: (3221, 108)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Under 1 Year: int32\n",
      "1 Year: int32\n",
      "2 Years: int32\n",
      "3 Years: int32\n",
      "4 Years: int32\n",
      "5 Years: int32\n",
      "6 Years: int32\n",
      "7 Years: int32\n",
      "8 Years: int32\n",
      "9 Years: int32\n",
      "10 Years: int32\n",
      "11 Years: int32\n",
      "12 Years: int32\n",
      "13 Years: int32\n",
      "14 Years: int32\n",
      "15 Years: int32\n",
      "16 Years: int32\n",
      "17 Years: int32\n",
      "18 Years: int32\n",
      "19 Years: int32\n",
      "20 Years: int32\n",
      "21 Years: int32\n",
      "22 Years: int32\n",
      "23 Years: int32\n",
      "24 Years: int32\n",
      "25 Years: int32\n",
      "26 Years: int32\n",
      "27 Years: int32\n",
      "28 Years: int32\n",
      "29 Years: int32\n",
      "30 Years: int32\n",
      "31 Years: int32\n",
      "32 Years: int32\n",
      "33 Years: int32\n",
      "34 Years: int32\n",
      "35 Years: int32\n",
      "36 Years: int32\n",
      "37 Years: int32\n",
      "38 Years: int32\n",
      "39 Years: int32\n",
      "40 Years: int32\n",
      "41 Years: int32\n",
      "42 Years: int32\n",
      "43 Years: int32\n",
      "44 Years: int32\n",
      "45 Years: int32\n",
      "46 Years: int32\n",
      "47 Years: int32\n",
      "48 Years: int32\n",
      "49 Years: int32\n",
      "50 Years: int32\n",
      "51 Years: int32\n",
      "52 Years: int32\n",
      "53 Years: int32\n",
      "54 Years: int32\n",
      "55 Years: int32\n",
      "56 Years: int32\n",
      "57 Years: int32\n",
      "58 Years: int32\n",
      "59 Years: int32\n",
      "60 Years: int32\n",
      "61 Years: int32\n",
      "62 Years: int32\n",
      "63 Years: int32\n",
      "64 Years: int32\n",
      "65 Years: int32\n",
      "66 Years: int32\n",
      "67 Years: int32\n",
      "68 Years: int32\n",
      "69 Years: int32\n",
      "70 Years: int32\n",
      "71 Years: int32\n",
      "72 Years: int32\n",
      "73 Years: int32\n",
      "74 Years: int32\n",
      "75 Years: int32\n",
      "76 Years: int32\n",
      "77 Years: int32\n",
      "78 Years: int32\n",
      "79 Years: int32\n",
      "80 Years: int32\n",
      "81 Years: int32\n",
      "82 Years: int32\n",
      "83 Years: int32\n",
      "84 Years: int32\n",
      "85 Years: int32\n",
      "86 Years: int32\n",
      "87 Years: int32\n",
      "88 Years: int32\n",
      "89 Years: int32\n",
      "90 Years: int32\n",
      "91 Years: int32\n",
      "92 Years: int32\n",
      "93 Years: int32\n",
      "94 Years: int32\n",
      "95 Years: int32\n",
      "96 Years: int32\n",
      "97  Years: int32\n",
      "98  Years: int32\n",
      "99  Years: int32\n",
      "100 to 104  Years: int32\n",
      "105 to 109  Years: int32\n",
      "110  Years and Over: int32\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_nhop\n",
      "Shape: (3221, 5)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_male_nhop\n",
      "Shape: (3221, 108)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Under 1 Year: int32\n",
      "1 Year: int32\n",
      "2 Years: int32\n",
      "3 Years: int32\n",
      "4 Years: int32\n",
      "5 Years: int32\n",
      "6 Years: int32\n",
      "7 Years: int32\n",
      "8 Years: int32\n",
      "9 Years: int32\n",
      "10 Years: int32\n",
      "11 Years: int32\n",
      "12 Years: int32\n",
      "13 Years: int32\n",
      "14 Years: int32\n",
      "15 Years: int32\n",
      "16 Years: int32\n",
      "17 Years: int32\n",
      "18 Years: int32\n",
      "19 Years: int32\n",
      "20 Years: int32\n",
      "21 Years: int32\n",
      "22 Years: int32\n",
      "23 Years: int32\n",
      "24 Years: int32\n",
      "25 Years: int32\n",
      "26 Years: int32\n",
      "27 Years: int32\n",
      "28 Years: int32\n",
      "29 Years: int32\n",
      "30 Years: int32\n",
      "31 Years: int32\n",
      "32 Years: int32\n",
      "33 Years: int32\n",
      "34 Years: int32\n",
      "35 Years: int32\n",
      "36 Years: int32\n",
      "37 Years: int32\n",
      "38 Years: int32\n",
      "39 Years: int32\n",
      "40 Years: int32\n",
      "41 Years: int32\n",
      "42 Years: int32\n",
      "43 Years: int32\n",
      "44 Years: int32\n",
      "45 Years: int32\n",
      "46 Years: int32\n",
      "47 Years: int32\n",
      "48 Years: int32\n",
      "49 Years: int32\n",
      "50 Years: int32\n",
      "51 Years: int32\n",
      "52 Years: int32\n",
      "53 Years: int32\n",
      "54 Years: int32\n",
      "55 Years: int32\n",
      "56 Years: int32\n",
      "57 Years: int32\n",
      "58 Years: int32\n",
      "59 Years: int32\n",
      "60 Years: int32\n",
      "61 Years: int32\n",
      "62 Years: int32\n",
      "63 Years: int32\n",
      "64 Years: int32\n",
      "65 Years: int32\n",
      "66 Years: int32\n",
      "67 Years: int32\n",
      "68 Years: int32\n",
      "69 Years: int32\n",
      "70 Years: int32\n",
      "71 Years: int32\n",
      "72 Years: int32\n",
      "73 Years: int32\n",
      "74 Years: int32\n",
      "75 Years: int32\n",
      "76 Years: int32\n",
      "77 Years: int32\n",
      "78 Years: int32\n",
      "79 Years: int32\n",
      "80 Years: int32\n",
      "81 Years: int32\n",
      "82 Years: int32\n",
      "83 Years: int32\n",
      "84 Years: int32\n",
      "85 Years: int32\n",
      "86 Years: int32\n",
      "87 Years: int32\n",
      "88 Years: int32\n",
      "89 Years: int32\n",
      "90 Years: int32\n",
      "91 Years: int32\n",
      "92 Years: int32\n",
      "93 Years: int32\n",
      "94 Years: int32\n",
      "95 Years: int32\n",
      "96 Years: int32\n",
      "97  Years: int32\n",
      "98  Years: int32\n",
      "99  Years: int32\n",
      "100 to 104  Years: int32\n",
      "105 to 109  Years: int32\n",
      "110  Years and Over: int32\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_female_nhop\n",
      "Shape: (3221, 108)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Under 1 Year: int32\n",
      "1 Year: int32\n",
      "2 Years: int32\n",
      "3 Years: int32\n",
      "4 Years: int32\n",
      "5 Years: int32\n",
      "6 Years: int32\n",
      "7 Years: int32\n",
      "8 Years: int32\n",
      "9 Years: int32\n",
      "10 Years: int32\n",
      "11 Years: int32\n",
      "12 Years: int32\n",
      "13 Years: int32\n",
      "14 Years: int32\n",
      "15 Years: int32\n",
      "16 Years: int32\n",
      "17 Years: int32\n",
      "18 Years: int32\n",
      "19 Years: int32\n",
      "20 Years: int32\n",
      "21 Years: int32\n",
      "22 Years: int32\n",
      "23 Years: int32\n",
      "24 Years: int32\n",
      "25 Years: int32\n",
      "26 Years: int32\n",
      "27 Years: int32\n",
      "28 Years: int32\n",
      "29 Years: int32\n",
      "30 Years: int32\n",
      "31 Years: int32\n",
      "32 Years: int32\n",
      "33 Years: int32\n",
      "34 Years: int32\n",
      "35 Years: int32\n",
      "36 Years: int32\n",
      "37 Years: int32\n",
      "38 Years: int32\n",
      "39 Years: int32\n",
      "40 Years: int32\n",
      "41 Years: int32\n",
      "42 Years: int32\n",
      "43 Years: int32\n",
      "44 Years: int32\n",
      "45 Years: int32\n",
      "46 Years: int32\n",
      "47 Years: int32\n",
      "48 Years: int32\n",
      "49 Years: int32\n",
      "50 Years: int32\n",
      "51 Years: int32\n",
      "52 Years: int32\n",
      "53 Years: int32\n",
      "54 Years: int32\n",
      "55 Years: int32\n",
      "56 Years: int32\n",
      "57 Years: int32\n",
      "58 Years: int32\n",
      "59 Years: int32\n",
      "60 Years: int32\n",
      "61 Years: int32\n",
      "62 Years: int32\n",
      "63 Years: int32\n",
      "64 Years: int32\n",
      "65 Years: int32\n",
      "66 Years: int32\n",
      "67 Years: int32\n",
      "68 Years: int32\n",
      "69 Years: int32\n",
      "70 Years: int32\n",
      "71 Years: int32\n",
      "72 Years: int32\n",
      "73 Years: int32\n",
      "74 Years: int32\n",
      "75 Years: int32\n",
      "76 Years: int32\n",
      "77 Years: int32\n",
      "78 Years: int32\n",
      "79 Years: int32\n",
      "80 Years: int32\n",
      "81 Years: int32\n",
      "82 Years: int32\n",
      "83 Years: int32\n",
      "84 Years: int32\n",
      "85 Years: int32\n",
      "86 Years: int32\n",
      "87 Years: int32\n",
      "88 Years: int32\n",
      "89 Years: int32\n",
      "90 Years: int32\n",
      "91 Years: int32\n",
      "92 Years: int32\n",
      "93 Years: int32\n",
      "94 Years: int32\n",
      "95 Years: int32\n",
      "96 Years: int32\n",
      "97  Years: int32\n",
      "98  Years: int32\n",
      "99  Years: int32\n",
      "100 to 104  Years: int32\n",
      "105 to 109  Years: int32\n",
      "110  Years and Over: int32\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_sor\n",
      "Shape: (3221, 5)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_male_sor\n",
      "Shape: (3221, 108)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Under 1 Year: int32\n",
      "1 Year: int32\n",
      "2 Years: int32\n",
      "3 Years: int32\n",
      "4 Years: int32\n",
      "5 Years: int32\n",
      "6 Years: int32\n",
      "7 Years: int32\n",
      "8 Years: int32\n",
      "9 Years: int32\n",
      "10 Years: int32\n",
      "11 Years: int32\n",
      "12 Years: int32\n",
      "13 Years: int32\n",
      "14 Years: int32\n",
      "15 Years: int32\n",
      "16 Years: int32\n",
      "17 Years: int32\n",
      "18 Years: int32\n",
      "19 Years: int32\n",
      "20 Years: int32\n",
      "21 Years: int32\n",
      "22 Years: int32\n",
      "23 Years: int32\n",
      "24 Years: int32\n",
      "25 Years: int32\n",
      "26 Years: int32\n",
      "27 Years: int32\n",
      "28 Years: int32\n",
      "29 Years: int32\n",
      "30 Years: int32\n",
      "31 Years: int32\n",
      "32 Years: int32\n",
      "33 Years: int32\n",
      "34 Years: int32\n",
      "35 Years: int32\n",
      "36 Years: int32\n",
      "37 Years: int32\n",
      "38 Years: int32\n",
      "39 Years: int32\n",
      "40 Years: int32\n",
      "41 Years: int32\n",
      "42 Years: int32\n",
      "43 Years: int32\n",
      "44 Years: int32\n",
      "45 Years: int32\n",
      "46 Years: int32\n",
      "47 Years: int32\n",
      "48 Years: int32\n",
      "49 Years: int32\n",
      "50 Years: int32\n",
      "51 Years: int32\n",
      "52 Years: int32\n",
      "53 Years: int32\n",
      "54 Years: int32\n",
      "55 Years: int32\n",
      "56 Years: int32\n",
      "57 Years: int32\n",
      "58 Years: int32\n",
      "59 Years: int32\n",
      "60 Years: int32\n",
      "61 Years: int32\n",
      "62 Years: int32\n",
      "63 Years: int32\n",
      "64 Years: int32\n",
      "65 Years: int32\n",
      "66 Years: int32\n",
      "67 Years: int32\n",
      "68 Years: int32\n",
      "69 Years: int32\n",
      "70 Years: int32\n",
      "71 Years: int32\n",
      "72 Years: int32\n",
      "73 Years: int32\n",
      "74 Years: int32\n",
      "75 Years: int32\n",
      "76 Years: int32\n",
      "77 Years: int32\n",
      "78 Years: int32\n",
      "79 Years: int32\n",
      "80 Years: int32\n",
      "81 Years: int32\n",
      "82 Years: int32\n",
      "83 Years: int32\n",
      "84 Years: int32\n",
      "85 Years: int32\n",
      "86 Years: int32\n",
      "87 Years: int32\n",
      "88 Years: int32\n",
      "89 Years: int32\n",
      "90 Years: int32\n",
      "91 Years: int32\n",
      "92 Years: int32\n",
      "93 Years: int32\n",
      "94 Years: int32\n",
      "95 Years: int32\n",
      "96 Years: int32\n",
      "97  Years: int32\n",
      "98  Years: int32\n",
      "99  Years: int32\n",
      "100 to 104  Years: int32\n",
      "105 to 109  Years: int32\n",
      "110  Years and Over: int32\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_female_sor\n",
      "Shape: (3221, 108)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Under 1 Year: int32\n",
      "1 Year: int32\n",
      "2 Years: int32\n",
      "3 Years: int32\n",
      "4 Years: int32\n",
      "5 Years: int32\n",
      "6 Years: int32\n",
      "7 Years: int32\n",
      "8 Years: int32\n",
      "9 Years: int32\n",
      "10 Years: int32\n",
      "11 Years: int32\n",
      "12 Years: int32\n",
      "13 Years: int32\n",
      "14 Years: int32\n",
      "15 Years: int32\n",
      "16 Years: int32\n",
      "17 Years: int32\n",
      "18 Years: int32\n",
      "19 Years: int32\n",
      "20 Years: int32\n",
      "21 Years: int32\n",
      "22 Years: int32\n",
      "23 Years: int32\n",
      "24 Years: int32\n",
      "25 Years: int32\n",
      "26 Years: int32\n",
      "27 Years: int32\n",
      "28 Years: int32\n",
      "29 Years: int32\n",
      "30 Years: int32\n",
      "31 Years: int32\n",
      "32 Years: int32\n",
      "33 Years: int32\n",
      "34 Years: int32\n",
      "35 Years: int32\n",
      "36 Years: int32\n",
      "37 Years: int32\n",
      "38 Years: int32\n",
      "39 Years: int32\n",
      "40 Years: int32\n",
      "41 Years: int32\n",
      "42 Years: int32\n",
      "43 Years: int32\n",
      "44 Years: int32\n",
      "45 Years: int32\n",
      "46 Years: int32\n",
      "47 Years: int32\n",
      "48 Years: int32\n",
      "49 Years: int32\n",
      "50 Years: int32\n",
      "51 Years: int32\n",
      "52 Years: int32\n",
      "53 Years: int32\n",
      "54 Years: int32\n",
      "55 Years: int32\n",
      "56 Years: int32\n",
      "57 Years: int32\n",
      "58 Years: int32\n",
      "59 Years: int32\n",
      "60 Years: int32\n",
      "61 Years: int32\n",
      "62 Years: int32\n",
      "63 Years: int32\n",
      "64 Years: int32\n",
      "65 Years: int32\n",
      "66 Years: int32\n",
      "67 Years: int32\n",
      "68 Years: int32\n",
      "69 Years: int32\n",
      "70 Years: int32\n",
      "71 Years: int32\n",
      "72 Years: int32\n",
      "73 Years: int32\n",
      "74 Years: int32\n",
      "75 Years: int32\n",
      "76 Years: int32\n",
      "77 Years: int32\n",
      "78 Years: int32\n",
      "79 Years: int32\n",
      "80 Years: int32\n",
      "81 Years: int32\n",
      "82 Years: int32\n",
      "83 Years: int32\n",
      "84 Years: int32\n",
      "85 Years: int32\n",
      "86 Years: int32\n",
      "87 Years: int32\n",
      "88 Years: int32\n",
      "89 Years: int32\n",
      "90 Years: int32\n",
      "91 Years: int32\n",
      "92 Years: int32\n",
      "93 Years: int32\n",
      "94 Years: int32\n",
      "95 Years: int32\n",
      "96 Years: int32\n",
      "97  Years: int32\n",
      "98  Years: int32\n",
      "99  Years: int32\n",
      "100 to 104  Years: int32\n",
      "105 to 109  Years: int32\n",
      "110  Years and Over: int32\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_tom\n",
      "Shape: (3221, 5)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_male_tom\n",
      "Shape: (3221, 108)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Under 1 Year: int32\n",
      "1 Year: int32\n",
      "2 Years: int32\n",
      "3 Years: int32\n",
      "4 Years: int32\n",
      "5 Years: int32\n",
      "6 Years: int32\n",
      "7 Years: int32\n",
      "8 Years: int32\n",
      "9 Years: int32\n",
      "10 Years: int32\n",
      "11 Years: int32\n",
      "12 Years: int32\n",
      "13 Years: int32\n",
      "14 Years: int32\n",
      "15 Years: int32\n",
      "16 Years: int32\n",
      "17 Years: int32\n",
      "18 Years: int32\n",
      "19 Years: int32\n",
      "20 Years: int32\n",
      "21 Years: int32\n",
      "22 Years: int32\n",
      "23 Years: int32\n",
      "24 Years: int32\n",
      "25 Years: int32\n",
      "26 Years: int32\n",
      "27 Years: int32\n",
      "28 Years: int32\n",
      "29 Years: int32\n",
      "30 Years: int32\n",
      "31 Years: int32\n",
      "32 Years: int32\n",
      "33 Years: int32\n",
      "34 Years: int32\n",
      "35 Years: int32\n",
      "36 Years: int32\n",
      "37 Years: int32\n",
      "38 Years: int32\n",
      "39 Years: int32\n",
      "40 Years: int32\n",
      "41 Years: int32\n",
      "42 Years: int32\n",
      "43 Years: int32\n",
      "44 Years: int32\n",
      "45 Years: int32\n",
      "46 Years: int32\n",
      "47 Years: int32\n",
      "48 Years: int32\n",
      "49 Years: int32\n",
      "50 Years: int32\n",
      "51 Years: int32\n",
      "52 Years: int32\n",
      "53 Years: int32\n",
      "54 Years: int32\n",
      "55 Years: int32\n",
      "56 Years: int32\n",
      "57 Years: int32\n",
      "58 Years: int32\n",
      "59 Years: int32\n",
      "60 Years: int32\n",
      "61 Years: int32\n",
      "62 Years: int32\n",
      "63 Years: int32\n",
      "64 Years: int32\n",
      "65 Years: int32\n",
      "66 Years: int32\n",
      "67 Years: int32\n",
      "68 Years: int32\n",
      "69 Years: int32\n",
      "70 Years: int32\n",
      "71 Years: int32\n",
      "72 Years: int32\n",
      "73 Years: int32\n",
      "74 Years: int32\n",
      "75 Years: int32\n",
      "76 Years: int32\n",
      "77 Years: int32\n",
      "78 Years: int32\n",
      "79 Years: int32\n",
      "80 Years: int32\n",
      "81 Years: int32\n",
      "82 Years: int32\n",
      "83 Years: int32\n",
      "84 Years: int32\n",
      "85 Years: int32\n",
      "86 Years: int32\n",
      "87 Years: int32\n",
      "88 Years: int32\n",
      "89 Years: int32\n",
      "90 Years: int32\n",
      "91 Years: int32\n",
      "92 Years: int32\n",
      "93 Years: int32\n",
      "94 Years: int32\n",
      "95 Years: int32\n",
      "96 Years: int32\n",
      "97  Years: int32\n",
      "98  Years: int32\n",
      "99  Years: int32\n",
      "100 to 104  Years: int32\n",
      "105 to 109  Years: int32\n",
      "110  Years and Over: int32\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_female_tom\n",
      "Shape: (3221, 108)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Under 1 Year: int32\n",
      "1 Year: int32\n",
      "2 Years: int32\n",
      "3 Years: int32\n",
      "4 Years: int32\n",
      "5 Years: int32\n",
      "6 Years: int32\n",
      "7 Years: int32\n",
      "8 Years: int32\n",
      "9 Years: int32\n",
      "10 Years: int32\n",
      "11 Years: int32\n",
      "12 Years: int32\n",
      "13 Years: int32\n",
      "14 Years: int32\n",
      "15 Years: int32\n",
      "16 Years: int32\n",
      "17 Years: int32\n",
      "18 Years: int32\n",
      "19 Years: int32\n",
      "20 Years: int32\n",
      "21 Years: int32\n",
      "22 Years: int32\n",
      "23 Years: int32\n",
      "24 Years: int32\n",
      "25 Years: int32\n",
      "26 Years: int32\n",
      "27 Years: int32\n",
      "28 Years: int32\n",
      "29 Years: int32\n",
      "30 Years: int32\n",
      "31 Years: int32\n",
      "32 Years: int32\n",
      "33 Years: int32\n",
      "34 Years: int32\n",
      "35 Years: int32\n",
      "36 Years: int32\n",
      "37 Years: int32\n",
      "38 Years: int32\n",
      "39 Years: int32\n",
      "40 Years: int32\n",
      "41 Years: int32\n",
      "42 Years: int32\n",
      "43 Years: int32\n",
      "44 Years: int32\n",
      "45 Years: int32\n",
      "46 Years: int32\n",
      "47 Years: int32\n",
      "48 Years: int32\n",
      "49 Years: int32\n",
      "50 Years: int32\n",
      "51 Years: int32\n",
      "52 Years: int32\n",
      "53 Years: int32\n",
      "54 Years: int32\n",
      "55 Years: int32\n",
      "56 Years: int32\n",
      "57 Years: int32\n",
      "58 Years: int32\n",
      "59 Years: int32\n",
      "60 Years: int32\n",
      "61 Years: int32\n",
      "62 Years: int32\n",
      "63 Years: int32\n",
      "64 Years: int32\n",
      "65 Years: int32\n",
      "66 Years: int32\n",
      "67 Years: int32\n",
      "68 Years: int32\n",
      "69 Years: int32\n",
      "70 Years: int32\n",
      "71 Years: int32\n",
      "72 Years: int32\n",
      "73 Years: int32\n",
      "74 Years: int32\n",
      "75 Years: int32\n",
      "76 Years: int32\n",
      "77 Years: int32\n",
      "78 Years: int32\n",
      "79 Years: int32\n",
      "80 Years: int32\n",
      "81 Years: int32\n",
      "82 Years: int32\n",
      "83 Years: int32\n",
      "84 Years: int32\n",
      "85 Years: int32\n",
      "86 Years: int32\n",
      "87 Years: int32\n",
      "88 Years: int32\n",
      "89 Years: int32\n",
      "90 Years: int32\n",
      "91 Years: int32\n",
      "92 Years: int32\n",
      "93 Years: int32\n",
      "94 Years: int32\n",
      "95 Years: int32\n",
      "96 Years: int32\n",
      "97  Years: int32\n",
      "98  Years: int32\n",
      "99  Years: int32\n",
      "100 to 104  Years: int32\n",
      "105 to 109  Years: int32\n",
      "110  Years and Over: int32\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_hol\n",
      "Shape: (3221, 5)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_male_hol\n",
      "Shape: (3221, 108)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Under 1 Year: int32\n",
      "1 Year: int32\n",
      "2 Years: int32\n",
      "3 Years: int32\n",
      "4 Years: int32\n",
      "5 Years: int32\n",
      "6 Years: int32\n",
      "7 Years: int32\n",
      "8 Years: int32\n",
      "9 Years: int32\n",
      "10 Years: int32\n",
      "11 Years: int32\n",
      "12 Years: int32\n",
      "13 Years: int32\n",
      "14 Years: int32\n",
      "15 Years: int32\n",
      "16 Years: int32\n",
      "17 Years: int32\n",
      "18 Years: int32\n",
      "19 Years: int32\n",
      "20 Years: int32\n",
      "21 Years: int32\n",
      "22 Years: int32\n",
      "23 Years: int32\n",
      "24 Years: int32\n",
      "25 Years: int32\n",
      "26 Years: int32\n",
      "27 Years: int32\n",
      "28 Years: int32\n",
      "29 Years: int32\n",
      "30 Years: int32\n",
      "31 Years: int32\n",
      "32 Years: int32\n",
      "33 Years: int32\n",
      "34 Years: int32\n",
      "35 Years: int32\n",
      "36 Years: int32\n",
      "37 Years: int32\n",
      "38 Years: int32\n",
      "39 Years: int32\n",
      "40 Years: int32\n",
      "41 Years: int32\n",
      "42 Years: int32\n",
      "43 Years: int32\n",
      "44 Years: int32\n",
      "45 Years: int32\n",
      "46 Years: int32\n",
      "47 Years: int32\n",
      "48 Years: int32\n",
      "49 Years: int32\n",
      "50 Years: int32\n",
      "51 Years: int32\n",
      "52 Years: int32\n",
      "53 Years: int32\n",
      "54 Years: int32\n",
      "55 Years: int32\n",
      "56 Years: int32\n",
      "57 Years: int32\n",
      "58 Years: int32\n",
      "59 Years: int32\n",
      "60 Years: int32\n",
      "61 Years: int32\n",
      "62 Years: int32\n",
      "63 Years: int32\n",
      "64 Years: int32\n",
      "65 Years: int32\n",
      "66 Years: int32\n",
      "67 Years: int32\n",
      "68 Years: int32\n",
      "69 Years: int32\n",
      "70 Years: int32\n",
      "71 Years: int32\n",
      "72 Years: int32\n",
      "73 Years: int32\n",
      "74 Years: int32\n",
      "75 Years: int32\n",
      "76 Years: int32\n",
      "77 Years: int32\n",
      "78 Years: int32\n",
      "79 Years: int32\n",
      "80 Years: int32\n",
      "81 Years: int32\n",
      "82 Years: int32\n",
      "83 Years: int32\n",
      "84 Years: int32\n",
      "85 Years: int32\n",
      "86 Years: int32\n",
      "87 Years: int32\n",
      "88 Years: int32\n",
      "89 Years: int32\n",
      "90 Years: int32\n",
      "91 Years: int32\n",
      "92 Years: int32\n",
      "93 Years: int32\n",
      "94 Years: int32\n",
      "95 Years: int32\n",
      "96 Years: int32\n",
      "97  Years: int32\n",
      "98  Years: int32\n",
      "99  Years: int32\n",
      "100 to 104  Years: int32\n",
      "105 to 109  Years: int32\n",
      "110  Years and Over: int32\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_female_hol\n",
      "Shape: (3221, 108)\n",
      "Dtypes:\n",
      "Total: object\n",
      "Under 1 Year: int32\n",
      "1 Year: int32\n",
      "2 Years: int32\n",
      "3 Years: int32\n",
      "4 Years: int32\n",
      "5 Years: int32\n",
      "6 Years: int32\n",
      "7 Years: int32\n",
      "8 Years: int32\n",
      "9 Years: int32\n",
      "10 Years: int32\n",
      "11 Years: int32\n",
      "12 Years: int32\n",
      "13 Years: int32\n",
      "14 Years: int32\n",
      "15 Years: int32\n",
      "16 Years: int32\n",
      "17 Years: int32\n",
      "18 Years: int32\n",
      "19 Years: int32\n",
      "20 Years: int32\n",
      "21 Years: int32\n",
      "22 Years: int32\n",
      "23 Years: int32\n",
      "24 Years: int32\n",
      "25 Years: int32\n",
      "26 Years: int32\n",
      "27 Years: int32\n",
      "28 Years: int32\n",
      "29 Years: int32\n",
      "30 Years: int32\n",
      "31 Years: int32\n",
      "32 Years: int32\n",
      "33 Years: int32\n",
      "34 Years: int32\n",
      "35 Years: int32\n",
      "36 Years: int32\n",
      "37 Years: int32\n",
      "38 Years: int32\n",
      "39 Years: int32\n",
      "40 Years: int32\n",
      "41 Years: int32\n",
      "42 Years: int32\n",
      "43 Years: int32\n",
      "44 Years: int32\n",
      "45 Years: int32\n",
      "46 Years: int32\n",
      "47 Years: int32\n",
      "48 Years: int32\n",
      "49 Years: int32\n",
      "50 Years: int32\n",
      "51 Years: int32\n",
      "52 Years: int32\n",
      "53 Years: int32\n",
      "54 Years: int32\n",
      "55 Years: int32\n",
      "56 Years: int32\n",
      "57 Years: int32\n",
      "58 Years: int32\n",
      "59 Years: int32\n",
      "60 Years: int32\n",
      "61 Years: int32\n",
      "62 Years: int32\n",
      "63 Years: int32\n",
      "64 Years: int32\n",
      "65 Years: int32\n",
      "66 Years: int32\n",
      "67 Years: int32\n",
      "68 Years: int32\n",
      "69 Years: int32\n",
      "70 Years: int32\n",
      "71 Years: int32\n",
      "72 Years: int32\n",
      "73 Years: int32\n",
      "74 Years: int32\n",
      "75 Years: int32\n",
      "76 Years: int32\n",
      "77 Years: int32\n",
      "78 Years: int32\n",
      "79 Years: int32\n",
      "80 Years: int32\n",
      "81 Years: int32\n",
      "82 Years: int32\n",
      "83 Years: int32\n",
      "84 Years: int32\n",
      "85 Years: int32\n",
      "86 Years: int32\n",
      "87 Years: int32\n",
      "88 Years: int32\n",
      "89 Years: int32\n",
      "90 Years: int32\n",
      "91 Years: int32\n",
      "92 Years: int32\n",
      "93 Years: int32\n",
      "94 Years: int32\n",
      "95 Years: int32\n",
      "96 Years: int32\n",
      "97  Years: int32\n",
      "98  Years: int32\n",
      "99  Years: int32\n",
      "100 to 104  Years: int32\n",
      "105 to 109  Years: int32\n",
      "110  Years and Over: int32\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the names, shapes, and dtypes of the dataframes in 'dfs'\n",
    "print(\"Data Frames in 'dfs':\")\n",
    "for name, df in dfs.items():\n",
    "    print(name)\n",
    "    print(\"Shape:\", df.shape)\n",
    "    print(\"Dtypes:\")\n",
    "    for column, dtype in df.dtypes.items():\n",
    "        print(f\"{column}: {dtype}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Percent to Total column\n",
    "Percent to total for male & female age groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping Dataframes with like structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_df = ['DF_male_all','DF_female_all','DF_total_male_whi',\n",
    "             'DF_total_female_whi','DF_total_male_baa','DF_total_female_baa',\n",
    "             'DF_total_male_aian','DF_total_female_aian','DF_total_male_aa',\n",
    "             'DF_total_female_aa','DF_total_male_nhop','DF_total_female_nhop',\n",
    "             'DF_total_male_sor','DF_total_female_sor','DF_total_male_tom',\n",
    "             'DF_total_female_tom','DF_total_male_hol','DF_total_female_hol'\n",
    "             ]\n",
    "\n",
    "perc_df_2 = ['DF_total_all','DF_total_whi','DF_total_baa','DF_total_aian',\n",
    "             'DF_total_aa','DF_total_nhop','DF_total_sor','DF_total_tom',\n",
    "             'DF_total_hol'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent to total process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3660381315.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = [0 if total == 0 else (value / total)\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the dictionary of dataframes\n",
    "for df_name, df in dfs.items():\n",
    "    if df_name in perc_df:\n",
    "        # Get the list of columns in the dataframe that match cols_int\n",
    "        columns = [col for col in df.columns if col in cols_int]\n",
    "        updated_columns = []\n",
    "\n",
    "        # Reset the index to consolidate memory layout\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Calculate the percentage values for the new column\n",
    "        for col in columns:\n",
    "            new_col_name = f'{col}_perc'\n",
    "            updated_columns.extend([col, new_col_name])\n",
    "\n",
    "            df[new_col_name] = [0 if total == 0 else (value / total)\n",
    "                                for value, total in zip(df[col], df['Total'])]\n",
    "        # Append ['Location', 'State', 'County', 'FIPS'] to updated_columns\n",
    "        updated_columns.extend(['Total','Location', 'State', 'County', 'FIPS'])\n",
    "        # Reorder the columns in the dataframe\n",
    "        df = df[updated_columns]\n",
    "\n",
    "        # Update the dataframe in the 'dfs' dictionary\n",
    "        dfs[df_name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all the name,shape,# of cols, col names of the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frames in 'perc_df':\n",
      "Dataframe Name: DF_male_all\n",
      "Shape: (3221, 211)\n",
      "Number of Columns: 211\n",
      "Columns: ['Under 1 Year', 'Under 1 Year_perc', '1 Year', '1 Year_perc', '2 Years', '2 Years_perc', '3 Years', '3 Years_perc', '4 Years', '4 Years_perc', '5 Years', '5 Years_perc', '6 Years', '6 Years_perc', '7 Years', '7 Years_perc', '8 Years', '8 Years_perc', '9 Years', '9 Years_perc', '10 Years', '10 Years_perc', '11 Years', '11 Years_perc', '12 Years', '12 Years_perc', '13 Years', '13 Years_perc', '14 Years', '14 Years_perc', '15 Years', '15 Years_perc', '16 Years', '16 Years_perc', '17 Years', '17 Years_perc', '18 Years', '18 Years_perc', '19 Years', '19 Years_perc', '20 Years', '20 Years_perc', '21 Years', '21 Years_perc', '22 Years', '22 Years_perc', '23 Years', '23 Years_perc', '24 Years', '24 Years_perc', '25 Years', '25 Years_perc', '26 Years', '26 Years_perc', '27 Years', '27 Years_perc', '28 Years', '28 Years_perc', '29 Years', '29 Years_perc', '30 Years', '30 Years_perc', '31 Years', '31 Years_perc', '32 Years', '32 Years_perc', '33 Years', '33 Years_perc', '34 Years', '34 Years_perc', '35 Years', '35 Years_perc', '36 Years', '36 Years_perc', '37 Years', '37 Years_perc', '38 Years', '38 Years_perc', '39 Years', '39 Years_perc', '40 Years', '40 Years_perc', '41 Years', '41 Years_perc', '42 Years', '42 Years_perc', '43 Years', '43 Years_perc', '44 Years', '44 Years_perc', '45 Years', '45 Years_perc', '46 Years', '46 Years_perc', '47 Years', '47 Years_perc', '48 Years', '48 Years_perc', '49 Years', '49 Years_perc', '50 Years', '50 Years_perc', '51 Years', '51 Years_perc', '52 Years', '52 Years_perc', '53 Years', '53 Years_perc', '54 Years', '54 Years_perc', '55 Years', '55 Years_perc', '56 Years', '56 Years_perc', '57 Years', '57 Years_perc', '58 Years', '58 Years_perc', '59 Years', '59 Years_perc', '60 Years', '60 Years_perc', '61 Years', '61 Years_perc', '62 Years', '62 Years_perc', '63 Years', '63 Years_perc', '64 Years', '64 Years_perc', '65 Years', '65 Years_perc', '66 Years', '66 Years_perc', '67 Years', '67 Years_perc', '68 Years', '68 Years_perc', '69 Years', '69 Years_perc', '70 Years', '70 Years_perc', '71 Years', '71 Years_perc', '72 Years', '72 Years_perc', '73 Years', '73 Years_perc', '74 Years', '74 Years_perc', '75 Years', '75 Years_perc', '76 Years', '76 Years_perc', '77 Years', '77 Years_perc', '78 Years', '78 Years_perc', '79 Years', '79 Years_perc', '80 Years', '80 Years_perc', '81 Years', '81 Years_perc', '82 Years', '82 Years_perc', '83 Years', '83 Years_perc', '84 Years', '84 Years_perc', '85 Years', '85 Years_perc', '86 Years', '86 Years_perc', '87 Years', '87 Years_perc', '88 Years', '88 Years_perc', '89 Years', '89 Years_perc', '90 Years', '90 Years_perc', '91 Years', '91 Years_perc', '92 Years', '92 Years_perc', '93 Years', '93 Years_perc', '94 Years', '94 Years_perc', '95 Years', '95 Years_perc', '96 Years', '96 Years_perc', '97  Years', '97  Years_perc', '98  Years', '98  Years_perc', '99  Years', '99  Years_perc', '100 to 104  Years', '100 to 104  Years_perc', '105 to 109  Years', '105 to 109  Years_perc', '110  Years and Over', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_female_all\n",
      "Shape: (3221, 211)\n",
      "Number of Columns: 211\n",
      "Columns: ['Under 1 Year', 'Under 1 Year_perc', '1 Year', '1 Year_perc', '2 Years', '2 Years_perc', '3 Years', '3 Years_perc', '4 Years', '4 Years_perc', '5 Years', '5 Years_perc', '6 Years', '6 Years_perc', '7 Years', '7 Years_perc', '8 Years', '8 Years_perc', '9 Years', '9 Years_perc', '10 Years', '10 Years_perc', '11 Years', '11 Years_perc', '12 Years', '12 Years_perc', '13 Years', '13 Years_perc', '14 Years', '14 Years_perc', '15 Years', '15 Years_perc', '16 Years', '16 Years_perc', '17 Years', '17 Years_perc', '18 Years', '18 Years_perc', '19 Years', '19 Years_perc', '20 Years', '20 Years_perc', '21 Years', '21 Years_perc', '22 Years', '22 Years_perc', '23 Years', '23 Years_perc', '24 Years', '24 Years_perc', '25 Years', '25 Years_perc', '26 Years', '26 Years_perc', '27 Years', '27 Years_perc', '28 Years', '28 Years_perc', '29 Years', '29 Years_perc', '30 Years', '30 Years_perc', '31 Years', '31 Years_perc', '32 Years', '32 Years_perc', '33 Years', '33 Years_perc', '34 Years', '34 Years_perc', '35 Years', '35 Years_perc', '36 Years', '36 Years_perc', '37 Years', '37 Years_perc', '38 Years', '38 Years_perc', '39 Years', '39 Years_perc', '40 Years', '40 Years_perc', '41 Years', '41 Years_perc', '42 Years', '42 Years_perc', '43 Years', '43 Years_perc', '44 Years', '44 Years_perc', '45 Years', '45 Years_perc', '46 Years', '46 Years_perc', '47 Years', '47 Years_perc', '48 Years', '48 Years_perc', '49 Years', '49 Years_perc', '50 Years', '50 Years_perc', '51 Years', '51 Years_perc', '52 Years', '52 Years_perc', '53 Years', '53 Years_perc', '54 Years', '54 Years_perc', '55 Years', '55 Years_perc', '56 Years', '56 Years_perc', '57 Years', '57 Years_perc', '58 Years', '58 Years_perc', '59 Years', '59 Years_perc', '60 Years', '60 Years_perc', '61 Years', '61 Years_perc', '62 Years', '62 Years_perc', '63 Years', '63 Years_perc', '64 Years', '64 Years_perc', '65 Years', '65 Years_perc', '66 Years', '66 Years_perc', '67 Years', '67 Years_perc', '68 Years', '68 Years_perc', '69 Years', '69 Years_perc', '70 Years', '70 Years_perc', '71 Years', '71 Years_perc', '72 Years', '72 Years_perc', '73 Years', '73 Years_perc', '74 Years', '74 Years_perc', '75 Years', '75 Years_perc', '76 Years', '76 Years_perc', '77 Years', '77 Years_perc', '78 Years', '78 Years_perc', '79 Years', '79 Years_perc', '80 Years', '80 Years_perc', '81 Years', '81 Years_perc', '82 Years', '82 Years_perc', '83 Years', '83 Years_perc', '84 Years', '84 Years_perc', '85 Years', '85 Years_perc', '86 Years', '86 Years_perc', '87 Years', '87 Years_perc', '88 Years', '88 Years_perc', '89 Years', '89 Years_perc', '90 Years', '90 Years_perc', '91 Years', '91 Years_perc', '92 Years', '92 Years_perc', '93 Years', '93 Years_perc', '94 Years', '94 Years_perc', '95 Years', '95 Years_perc', '96 Years', '96 Years_perc', '97  Years', '97  Years_perc', '98  Years', '98  Years_perc', '99  Years', '99  Years_perc', '100 to 104  Years', '100 to 104  Years_perc', '105 to 109  Years', '105 to 109  Years_perc', '110  Years and Over', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_male_whi\n",
      "Shape: (3221, 211)\n",
      "Number of Columns: 211\n",
      "Columns: ['Under 1 Year', 'Under 1 Year_perc', '1 Year', '1 Year_perc', '2 Years', '2 Years_perc', '3 Years', '3 Years_perc', '4 Years', '4 Years_perc', '5 Years', '5 Years_perc', '6 Years', '6 Years_perc', '7 Years', '7 Years_perc', '8 Years', '8 Years_perc', '9 Years', '9 Years_perc', '10 Years', '10 Years_perc', '11 Years', '11 Years_perc', '12 Years', '12 Years_perc', '13 Years', '13 Years_perc', '14 Years', '14 Years_perc', '15 Years', '15 Years_perc', '16 Years', '16 Years_perc', '17 Years', '17 Years_perc', '18 Years', '18 Years_perc', '19 Years', '19 Years_perc', '20 Years', '20 Years_perc', '21 Years', '21 Years_perc', '22 Years', '22 Years_perc', '23 Years', '23 Years_perc', '24 Years', '24 Years_perc', '25 Years', '25 Years_perc', '26 Years', '26 Years_perc', '27 Years', '27 Years_perc', '28 Years', '28 Years_perc', '29 Years', '29 Years_perc', '30 Years', '30 Years_perc', '31 Years', '31 Years_perc', '32 Years', '32 Years_perc', '33 Years', '33 Years_perc', '34 Years', '34 Years_perc', '35 Years', '35 Years_perc', '36 Years', '36 Years_perc', '37 Years', '37 Years_perc', '38 Years', '38 Years_perc', '39 Years', '39 Years_perc', '40 Years', '40 Years_perc', '41 Years', '41 Years_perc', '42 Years', '42 Years_perc', '43 Years', '43 Years_perc', '44 Years', '44 Years_perc', '45 Years', '45 Years_perc', '46 Years', '46 Years_perc', '47 Years', '47 Years_perc', '48 Years', '48 Years_perc', '49 Years', '49 Years_perc', '50 Years', '50 Years_perc', '51 Years', '51 Years_perc', '52 Years', '52 Years_perc', '53 Years', '53 Years_perc', '54 Years', '54 Years_perc', '55 Years', '55 Years_perc', '56 Years', '56 Years_perc', '57 Years', '57 Years_perc', '58 Years', '58 Years_perc', '59 Years', '59 Years_perc', '60 Years', '60 Years_perc', '61 Years', '61 Years_perc', '62 Years', '62 Years_perc', '63 Years', '63 Years_perc', '64 Years', '64 Years_perc', '65 Years', '65 Years_perc', '66 Years', '66 Years_perc', '67 Years', '67 Years_perc', '68 Years', '68 Years_perc', '69 Years', '69 Years_perc', '70 Years', '70 Years_perc', '71 Years', '71 Years_perc', '72 Years', '72 Years_perc', '73 Years', '73 Years_perc', '74 Years', '74 Years_perc', '75 Years', '75 Years_perc', '76 Years', '76 Years_perc', '77 Years', '77 Years_perc', '78 Years', '78 Years_perc', '79 Years', '79 Years_perc', '80 Years', '80 Years_perc', '81 Years', '81 Years_perc', '82 Years', '82 Years_perc', '83 Years', '83 Years_perc', '84 Years', '84 Years_perc', '85 Years', '85 Years_perc', '86 Years', '86 Years_perc', '87 Years', '87 Years_perc', '88 Years', '88 Years_perc', '89 Years', '89 Years_perc', '90 Years', '90 Years_perc', '91 Years', '91 Years_perc', '92 Years', '92 Years_perc', '93 Years', '93 Years_perc', '94 Years', '94 Years_perc', '95 Years', '95 Years_perc', '96 Years', '96 Years_perc', '97  Years', '97  Years_perc', '98  Years', '98  Years_perc', '99  Years', '99  Years_perc', '100 to 104  Years', '100 to 104  Years_perc', '105 to 109  Years', '105 to 109  Years_perc', '110  Years and Over', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_female_whi\n",
      "Shape: (3221, 211)\n",
      "Number of Columns: 211\n",
      "Columns: ['Under 1 Year', 'Under 1 Year_perc', '1 Year', '1 Year_perc', '2 Years', '2 Years_perc', '3 Years', '3 Years_perc', '4 Years', '4 Years_perc', '5 Years', '5 Years_perc', '6 Years', '6 Years_perc', '7 Years', '7 Years_perc', '8 Years', '8 Years_perc', '9 Years', '9 Years_perc', '10 Years', '10 Years_perc', '11 Years', '11 Years_perc', '12 Years', '12 Years_perc', '13 Years', '13 Years_perc', '14 Years', '14 Years_perc', '15 Years', '15 Years_perc', '16 Years', '16 Years_perc', '17 Years', '17 Years_perc', '18 Years', '18 Years_perc', '19 Years', '19 Years_perc', '20 Years', '20 Years_perc', '21 Years', '21 Years_perc', '22 Years', '22 Years_perc', '23 Years', '23 Years_perc', '24 Years', '24 Years_perc', '25 Years', '25 Years_perc', '26 Years', '26 Years_perc', '27 Years', '27 Years_perc', '28 Years', '28 Years_perc', '29 Years', '29 Years_perc', '30 Years', '30 Years_perc', '31 Years', '31 Years_perc', '32 Years', '32 Years_perc', '33 Years', '33 Years_perc', '34 Years', '34 Years_perc', '35 Years', '35 Years_perc', '36 Years', '36 Years_perc', '37 Years', '37 Years_perc', '38 Years', '38 Years_perc', '39 Years', '39 Years_perc', '40 Years', '40 Years_perc', '41 Years', '41 Years_perc', '42 Years', '42 Years_perc', '43 Years', '43 Years_perc', '44 Years', '44 Years_perc', '45 Years', '45 Years_perc', '46 Years', '46 Years_perc', '47 Years', '47 Years_perc', '48 Years', '48 Years_perc', '49 Years', '49 Years_perc', '50 Years', '50 Years_perc', '51 Years', '51 Years_perc', '52 Years', '52 Years_perc', '53 Years', '53 Years_perc', '54 Years', '54 Years_perc', '55 Years', '55 Years_perc', '56 Years', '56 Years_perc', '57 Years', '57 Years_perc', '58 Years', '58 Years_perc', '59 Years', '59 Years_perc', '60 Years', '60 Years_perc', '61 Years', '61 Years_perc', '62 Years', '62 Years_perc', '63 Years', '63 Years_perc', '64 Years', '64 Years_perc', '65 Years', '65 Years_perc', '66 Years', '66 Years_perc', '67 Years', '67 Years_perc', '68 Years', '68 Years_perc', '69 Years', '69 Years_perc', '70 Years', '70 Years_perc', '71 Years', '71 Years_perc', '72 Years', '72 Years_perc', '73 Years', '73 Years_perc', '74 Years', '74 Years_perc', '75 Years', '75 Years_perc', '76 Years', '76 Years_perc', '77 Years', '77 Years_perc', '78 Years', '78 Years_perc', '79 Years', '79 Years_perc', '80 Years', '80 Years_perc', '81 Years', '81 Years_perc', '82 Years', '82 Years_perc', '83 Years', '83 Years_perc', '84 Years', '84 Years_perc', '85 Years', '85 Years_perc', '86 Years', '86 Years_perc', '87 Years', '87 Years_perc', '88 Years', '88 Years_perc', '89 Years', '89 Years_perc', '90 Years', '90 Years_perc', '91 Years', '91 Years_perc', '92 Years', '92 Years_perc', '93 Years', '93 Years_perc', '94 Years', '94 Years_perc', '95 Years', '95 Years_perc', '96 Years', '96 Years_perc', '97  Years', '97  Years_perc', '98  Years', '98  Years_perc', '99  Years', '99  Years_perc', '100 to 104  Years', '100 to 104  Years_perc', '105 to 109  Years', '105 to 109  Years_perc', '110  Years and Over', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_male_baa\n",
      "Shape: (3221, 211)\n",
      "Number of Columns: 211\n",
      "Columns: ['Under 1 Year', 'Under 1 Year_perc', '1 Year', '1 Year_perc', '2 Years', '2 Years_perc', '3 Years', '3 Years_perc', '4 Years', '4 Years_perc', '5 Years', '5 Years_perc', '6 Years', '6 Years_perc', '7 Years', '7 Years_perc', '8 Years', '8 Years_perc', '9 Years', '9 Years_perc', '10 Years', '10 Years_perc', '11 Years', '11 Years_perc', '12 Years', '12 Years_perc', '13 Years', '13 Years_perc', '14 Years', '14 Years_perc', '15 Years', '15 Years_perc', '16 Years', '16 Years_perc', '17 Years', '17 Years_perc', '18 Years', '18 Years_perc', '19 Years', '19 Years_perc', '20 Years', '20 Years_perc', '21 Years', '21 Years_perc', '22 Years', '22 Years_perc', '23 Years', '23 Years_perc', '24 Years', '24 Years_perc', '25 Years', '25 Years_perc', '26 Years', '26 Years_perc', '27 Years', '27 Years_perc', '28 Years', '28 Years_perc', '29 Years', '29 Years_perc', '30 Years', '30 Years_perc', '31 Years', '31 Years_perc', '32 Years', '32 Years_perc', '33 Years', '33 Years_perc', '34 Years', '34 Years_perc', '35 Years', '35 Years_perc', '36 Years', '36 Years_perc', '37 Years', '37 Years_perc', '38 Years', '38 Years_perc', '39 Years', '39 Years_perc', '40 Years', '40 Years_perc', '41 Years', '41 Years_perc', '42 Years', '42 Years_perc', '43 Years', '43 Years_perc', '44 Years', '44 Years_perc', '45 Years', '45 Years_perc', '46 Years', '46 Years_perc', '47 Years', '47 Years_perc', '48 Years', '48 Years_perc', '49 Years', '49 Years_perc', '50 Years', '50 Years_perc', '51 Years', '51 Years_perc', '52 Years', '52 Years_perc', '53 Years', '53 Years_perc', '54 Years', '54 Years_perc', '55 Years', '55 Years_perc', '56 Years', '56 Years_perc', '57 Years', '57 Years_perc', '58 Years', '58 Years_perc', '59 Years', '59 Years_perc', '60 Years', '60 Years_perc', '61 Years', '61 Years_perc', '62 Years', '62 Years_perc', '63 Years', '63 Years_perc', '64 Years', '64 Years_perc', '65 Years', '65 Years_perc', '66 Years', '66 Years_perc', '67 Years', '67 Years_perc', '68 Years', '68 Years_perc', '69 Years', '69 Years_perc', '70 Years', '70 Years_perc', '71 Years', '71 Years_perc', '72 Years', '72 Years_perc', '73 Years', '73 Years_perc', '74 Years', '74 Years_perc', '75 Years', '75 Years_perc', '76 Years', '76 Years_perc', '77 Years', '77 Years_perc', '78 Years', '78 Years_perc', '79 Years', '79 Years_perc', '80 Years', '80 Years_perc', '81 Years', '81 Years_perc', '82 Years', '82 Years_perc', '83 Years', '83 Years_perc', '84 Years', '84 Years_perc', '85 Years', '85 Years_perc', '86 Years', '86 Years_perc', '87 Years', '87 Years_perc', '88 Years', '88 Years_perc', '89 Years', '89 Years_perc', '90 Years', '90 Years_perc', '91 Years', '91 Years_perc', '92 Years', '92 Years_perc', '93 Years', '93 Years_perc', '94 Years', '94 Years_perc', '95 Years', '95 Years_perc', '96 Years', '96 Years_perc', '97  Years', '97  Years_perc', '98  Years', '98  Years_perc', '99  Years', '99  Years_perc', '100 to 104  Years', '100 to 104  Years_perc', '105 to 109  Years', '105 to 109  Years_perc', '110  Years and Over', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_female_baa\n",
      "Shape: (3221, 211)\n",
      "Number of Columns: 211\n",
      "Columns: ['Under 1 Year', 'Under 1 Year_perc', '1 Year', '1 Year_perc', '2 Years', '2 Years_perc', '3 Years', '3 Years_perc', '4 Years', '4 Years_perc', '5 Years', '5 Years_perc', '6 Years', '6 Years_perc', '7 Years', '7 Years_perc', '8 Years', '8 Years_perc', '9 Years', '9 Years_perc', '10 Years', '10 Years_perc', '11 Years', '11 Years_perc', '12 Years', '12 Years_perc', '13 Years', '13 Years_perc', '14 Years', '14 Years_perc', '15 Years', '15 Years_perc', '16 Years', '16 Years_perc', '17 Years', '17 Years_perc', '18 Years', '18 Years_perc', '19 Years', '19 Years_perc', '20 Years', '20 Years_perc', '21 Years', '21 Years_perc', '22 Years', '22 Years_perc', '23 Years', '23 Years_perc', '24 Years', '24 Years_perc', '25 Years', '25 Years_perc', '26 Years', '26 Years_perc', '27 Years', '27 Years_perc', '28 Years', '28 Years_perc', '29 Years', '29 Years_perc', '30 Years', '30 Years_perc', '31 Years', '31 Years_perc', '32 Years', '32 Years_perc', '33 Years', '33 Years_perc', '34 Years', '34 Years_perc', '35 Years', '35 Years_perc', '36 Years', '36 Years_perc', '37 Years', '37 Years_perc', '38 Years', '38 Years_perc', '39 Years', '39 Years_perc', '40 Years', '40 Years_perc', '41 Years', '41 Years_perc', '42 Years', '42 Years_perc', '43 Years', '43 Years_perc', '44 Years', '44 Years_perc', '45 Years', '45 Years_perc', '46 Years', '46 Years_perc', '47 Years', '47 Years_perc', '48 Years', '48 Years_perc', '49 Years', '49 Years_perc', '50 Years', '50 Years_perc', '51 Years', '51 Years_perc', '52 Years', '52 Years_perc', '53 Years', '53 Years_perc', '54 Years', '54 Years_perc', '55 Years', '55 Years_perc', '56 Years', '56 Years_perc', '57 Years', '57 Years_perc', '58 Years', '58 Years_perc', '59 Years', '59 Years_perc', '60 Years', '60 Years_perc', '61 Years', '61 Years_perc', '62 Years', '62 Years_perc', '63 Years', '63 Years_perc', '64 Years', '64 Years_perc', '65 Years', '65 Years_perc', '66 Years', '66 Years_perc', '67 Years', '67 Years_perc', '68 Years', '68 Years_perc', '69 Years', '69 Years_perc', '70 Years', '70 Years_perc', '71 Years', '71 Years_perc', '72 Years', '72 Years_perc', '73 Years', '73 Years_perc', '74 Years', '74 Years_perc', '75 Years', '75 Years_perc', '76 Years', '76 Years_perc', '77 Years', '77 Years_perc', '78 Years', '78 Years_perc', '79 Years', '79 Years_perc', '80 Years', '80 Years_perc', '81 Years', '81 Years_perc', '82 Years', '82 Years_perc', '83 Years', '83 Years_perc', '84 Years', '84 Years_perc', '85 Years', '85 Years_perc', '86 Years', '86 Years_perc', '87 Years', '87 Years_perc', '88 Years', '88 Years_perc', '89 Years', '89 Years_perc', '90 Years', '90 Years_perc', '91 Years', '91 Years_perc', '92 Years', '92 Years_perc', '93 Years', '93 Years_perc', '94 Years', '94 Years_perc', '95 Years', '95 Years_perc', '96 Years', '96 Years_perc', '97  Years', '97  Years_perc', '98  Years', '98  Years_perc', '99  Years', '99  Years_perc', '100 to 104  Years', '100 to 104  Years_perc', '105 to 109  Years', '105 to 109  Years_perc', '110  Years and Over', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_male_aian\n",
      "Shape: (3221, 211)\n",
      "Number of Columns: 211\n",
      "Columns: ['Under 1 Year', 'Under 1 Year_perc', '1 Year', '1 Year_perc', '2 Years', '2 Years_perc', '3 Years', '3 Years_perc', '4 Years', '4 Years_perc', '5 Years', '5 Years_perc', '6 Years', '6 Years_perc', '7 Years', '7 Years_perc', '8 Years', '8 Years_perc', '9 Years', '9 Years_perc', '10 Years', '10 Years_perc', '11 Years', '11 Years_perc', '12 Years', '12 Years_perc', '13 Years', '13 Years_perc', '14 Years', '14 Years_perc', '15 Years', '15 Years_perc', '16 Years', '16 Years_perc', '17 Years', '17 Years_perc', '18 Years', '18 Years_perc', '19 Years', '19 Years_perc', '20 Years', '20 Years_perc', '21 Years', '21 Years_perc', '22 Years', '22 Years_perc', '23 Years', '23 Years_perc', '24 Years', '24 Years_perc', '25 Years', '25 Years_perc', '26 Years', '26 Years_perc', '27 Years', '27 Years_perc', '28 Years', '28 Years_perc', '29 Years', '29 Years_perc', '30 Years', '30 Years_perc', '31 Years', '31 Years_perc', '32 Years', '32 Years_perc', '33 Years', '33 Years_perc', '34 Years', '34 Years_perc', '35 Years', '35 Years_perc', '36 Years', '36 Years_perc', '37 Years', '37 Years_perc', '38 Years', '38 Years_perc', '39 Years', '39 Years_perc', '40 Years', '40 Years_perc', '41 Years', '41 Years_perc', '42 Years', '42 Years_perc', '43 Years', '43 Years_perc', '44 Years', '44 Years_perc', '45 Years', '45 Years_perc', '46 Years', '46 Years_perc', '47 Years', '47 Years_perc', '48 Years', '48 Years_perc', '49 Years', '49 Years_perc', '50 Years', '50 Years_perc', '51 Years', '51 Years_perc', '52 Years', '52 Years_perc', '53 Years', '53 Years_perc', '54 Years', '54 Years_perc', '55 Years', '55 Years_perc', '56 Years', '56 Years_perc', '57 Years', '57 Years_perc', '58 Years', '58 Years_perc', '59 Years', '59 Years_perc', '60 Years', '60 Years_perc', '61 Years', '61 Years_perc', '62 Years', '62 Years_perc', '63 Years', '63 Years_perc', '64 Years', '64 Years_perc', '65 Years', '65 Years_perc', '66 Years', '66 Years_perc', '67 Years', '67 Years_perc', '68 Years', '68 Years_perc', '69 Years', '69 Years_perc', '70 Years', '70 Years_perc', '71 Years', '71 Years_perc', '72 Years', '72 Years_perc', '73 Years', '73 Years_perc', '74 Years', '74 Years_perc', '75 Years', '75 Years_perc', '76 Years', '76 Years_perc', '77 Years', '77 Years_perc', '78 Years', '78 Years_perc', '79 Years', '79 Years_perc', '80 Years', '80 Years_perc', '81 Years', '81 Years_perc', '82 Years', '82 Years_perc', '83 Years', '83 Years_perc', '84 Years', '84 Years_perc', '85 Years', '85 Years_perc', '86 Years', '86 Years_perc', '87 Years', '87 Years_perc', '88 Years', '88 Years_perc', '89 Years', '89 Years_perc', '90 Years', '90 Years_perc', '91 Years', '91 Years_perc', '92 Years', '92 Years_perc', '93 Years', '93 Years_perc', '94 Years', '94 Years_perc', '95 Years', '95 Years_perc', '96 Years', '96 Years_perc', '97  Years', '97  Years_perc', '98  Years', '98  Years_perc', '99  Years', '99  Years_perc', '100 to 104  Years', '100 to 104  Years_perc', '105 to 109  Years', '105 to 109  Years_perc', '110  Years and Over', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_female_aian\n",
      "Shape: (3221, 211)\n",
      "Number of Columns: 211\n",
      "Columns: ['Under 1 Year', 'Under 1 Year_perc', '1 Year', '1 Year_perc', '2 Years', '2 Years_perc', '3 Years', '3 Years_perc', '4 Years', '4 Years_perc', '5 Years', '5 Years_perc', '6 Years', '6 Years_perc', '7 Years', '7 Years_perc', '8 Years', '8 Years_perc', '9 Years', '9 Years_perc', '10 Years', '10 Years_perc', '11 Years', '11 Years_perc', '12 Years', '12 Years_perc', '13 Years', '13 Years_perc', '14 Years', '14 Years_perc', '15 Years', '15 Years_perc', '16 Years', '16 Years_perc', '17 Years', '17 Years_perc', '18 Years', '18 Years_perc', '19 Years', '19 Years_perc', '20 Years', '20 Years_perc', '21 Years', '21 Years_perc', '22 Years', '22 Years_perc', '23 Years', '23 Years_perc', '24 Years', '24 Years_perc', '25 Years', '25 Years_perc', '26 Years', '26 Years_perc', '27 Years', '27 Years_perc', '28 Years', '28 Years_perc', '29 Years', '29 Years_perc', '30 Years', '30 Years_perc', '31 Years', '31 Years_perc', '32 Years', '32 Years_perc', '33 Years', '33 Years_perc', '34 Years', '34 Years_perc', '35 Years', '35 Years_perc', '36 Years', '36 Years_perc', '37 Years', '37 Years_perc', '38 Years', '38 Years_perc', '39 Years', '39 Years_perc', '40 Years', '40 Years_perc', '41 Years', '41 Years_perc', '42 Years', '42 Years_perc', '43 Years', '43 Years_perc', '44 Years', '44 Years_perc', '45 Years', '45 Years_perc', '46 Years', '46 Years_perc', '47 Years', '47 Years_perc', '48 Years', '48 Years_perc', '49 Years', '49 Years_perc', '50 Years', '50 Years_perc', '51 Years', '51 Years_perc', '52 Years', '52 Years_perc', '53 Years', '53 Years_perc', '54 Years', '54 Years_perc', '55 Years', '55 Years_perc', '56 Years', '56 Years_perc', '57 Years', '57 Years_perc', '58 Years', '58 Years_perc', '59 Years', '59 Years_perc', '60 Years', '60 Years_perc', '61 Years', '61 Years_perc', '62 Years', '62 Years_perc', '63 Years', '63 Years_perc', '64 Years', '64 Years_perc', '65 Years', '65 Years_perc', '66 Years', '66 Years_perc', '67 Years', '67 Years_perc', '68 Years', '68 Years_perc', '69 Years', '69 Years_perc', '70 Years', '70 Years_perc', '71 Years', '71 Years_perc', '72 Years', '72 Years_perc', '73 Years', '73 Years_perc', '74 Years', '74 Years_perc', '75 Years', '75 Years_perc', '76 Years', '76 Years_perc', '77 Years', '77 Years_perc', '78 Years', '78 Years_perc', '79 Years', '79 Years_perc', '80 Years', '80 Years_perc', '81 Years', '81 Years_perc', '82 Years', '82 Years_perc', '83 Years', '83 Years_perc', '84 Years', '84 Years_perc', '85 Years', '85 Years_perc', '86 Years', '86 Years_perc', '87 Years', '87 Years_perc', '88 Years', '88 Years_perc', '89 Years', '89 Years_perc', '90 Years', '90 Years_perc', '91 Years', '91 Years_perc', '92 Years', '92 Years_perc', '93 Years', '93 Years_perc', '94 Years', '94 Years_perc', '95 Years', '95 Years_perc', '96 Years', '96 Years_perc', '97  Years', '97  Years_perc', '98  Years', '98  Years_perc', '99  Years', '99  Years_perc', '100 to 104  Years', '100 to 104  Years_perc', '105 to 109  Years', '105 to 109  Years_perc', '110  Years and Over', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_male_aa\n",
      "Shape: (3221, 211)\n",
      "Number of Columns: 211\n",
      "Columns: ['Under 1 Year', 'Under 1 Year_perc', '1 Year', '1 Year_perc', '2 Years', '2 Years_perc', '3 Years', '3 Years_perc', '4 Years', '4 Years_perc', '5 Years', '5 Years_perc', '6 Years', '6 Years_perc', '7 Years', '7 Years_perc', '8 Years', '8 Years_perc', '9 Years', '9 Years_perc', '10 Years', '10 Years_perc', '11 Years', '11 Years_perc', '12 Years', '12 Years_perc', '13 Years', '13 Years_perc', '14 Years', '14 Years_perc', '15 Years', '15 Years_perc', '16 Years', '16 Years_perc', '17 Years', '17 Years_perc', '18 Years', '18 Years_perc', '19 Years', '19 Years_perc', '20 Years', '20 Years_perc', '21 Years', '21 Years_perc', '22 Years', '22 Years_perc', '23 Years', '23 Years_perc', '24 Years', '24 Years_perc', '25 Years', '25 Years_perc', '26 Years', '26 Years_perc', '27 Years', '27 Years_perc', '28 Years', '28 Years_perc', '29 Years', '29 Years_perc', '30 Years', '30 Years_perc', '31 Years', '31 Years_perc', '32 Years', '32 Years_perc', '33 Years', '33 Years_perc', '34 Years', '34 Years_perc', '35 Years', '35 Years_perc', '36 Years', '36 Years_perc', '37 Years', '37 Years_perc', '38 Years', '38 Years_perc', '39 Years', '39 Years_perc', '40 Years', '40 Years_perc', '41 Years', '41 Years_perc', '42 Years', '42 Years_perc', '43 Years', '43 Years_perc', '44 Years', '44 Years_perc', '45 Years', '45 Years_perc', '46 Years', '46 Years_perc', '47 Years', '47 Years_perc', '48 Years', '48 Years_perc', '49 Years', '49 Years_perc', '50 Years', '50 Years_perc', '51 Years', '51 Years_perc', '52 Years', '52 Years_perc', '53 Years', '53 Years_perc', '54 Years', '54 Years_perc', '55 Years', '55 Years_perc', '56 Years', '56 Years_perc', '57 Years', '57 Years_perc', '58 Years', '58 Years_perc', '59 Years', '59 Years_perc', '60 Years', '60 Years_perc', '61 Years', '61 Years_perc', '62 Years', '62 Years_perc', '63 Years', '63 Years_perc', '64 Years', '64 Years_perc', '65 Years', '65 Years_perc', '66 Years', '66 Years_perc', '67 Years', '67 Years_perc', '68 Years', '68 Years_perc', '69 Years', '69 Years_perc', '70 Years', '70 Years_perc', '71 Years', '71 Years_perc', '72 Years', '72 Years_perc', '73 Years', '73 Years_perc', '74 Years', '74 Years_perc', '75 Years', '75 Years_perc', '76 Years', '76 Years_perc', '77 Years', '77 Years_perc', '78 Years', '78 Years_perc', '79 Years', '79 Years_perc', '80 Years', '80 Years_perc', '81 Years', '81 Years_perc', '82 Years', '82 Years_perc', '83 Years', '83 Years_perc', '84 Years', '84 Years_perc', '85 Years', '85 Years_perc', '86 Years', '86 Years_perc', '87 Years', '87 Years_perc', '88 Years', '88 Years_perc', '89 Years', '89 Years_perc', '90 Years', '90 Years_perc', '91 Years', '91 Years_perc', '92 Years', '92 Years_perc', '93 Years', '93 Years_perc', '94 Years', '94 Years_perc', '95 Years', '95 Years_perc', '96 Years', '96 Years_perc', '97  Years', '97  Years_perc', '98  Years', '98  Years_perc', '99  Years', '99  Years_perc', '100 to 104  Years', '100 to 104  Years_perc', '105 to 109  Years', '105 to 109  Years_perc', '110  Years and Over', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_female_aa\n",
      "Shape: (3221, 211)\n",
      "Number of Columns: 211\n",
      "Columns: ['Under 1 Year', 'Under 1 Year_perc', '1 Year', '1 Year_perc', '2 Years', '2 Years_perc', '3 Years', '3 Years_perc', '4 Years', '4 Years_perc', '5 Years', '5 Years_perc', '6 Years', '6 Years_perc', '7 Years', '7 Years_perc', '8 Years', '8 Years_perc', '9 Years', '9 Years_perc', '10 Years', '10 Years_perc', '11 Years', '11 Years_perc', '12 Years', '12 Years_perc', '13 Years', '13 Years_perc', '14 Years', '14 Years_perc', '15 Years', '15 Years_perc', '16 Years', '16 Years_perc', '17 Years', '17 Years_perc', '18 Years', '18 Years_perc', '19 Years', '19 Years_perc', '20 Years', '20 Years_perc', '21 Years', '21 Years_perc', '22 Years', '22 Years_perc', '23 Years', '23 Years_perc', '24 Years', '24 Years_perc', '25 Years', '25 Years_perc', '26 Years', '26 Years_perc', '27 Years', '27 Years_perc', '28 Years', '28 Years_perc', '29 Years', '29 Years_perc', '30 Years', '30 Years_perc', '31 Years', '31 Years_perc', '32 Years', '32 Years_perc', '33 Years', '33 Years_perc', '34 Years', '34 Years_perc', '35 Years', '35 Years_perc', '36 Years', '36 Years_perc', '37 Years', '37 Years_perc', '38 Years', '38 Years_perc', '39 Years', '39 Years_perc', '40 Years', '40 Years_perc', '41 Years', '41 Years_perc', '42 Years', '42 Years_perc', '43 Years', '43 Years_perc', '44 Years', '44 Years_perc', '45 Years', '45 Years_perc', '46 Years', '46 Years_perc', '47 Years', '47 Years_perc', '48 Years', '48 Years_perc', '49 Years', '49 Years_perc', '50 Years', '50 Years_perc', '51 Years', '51 Years_perc', '52 Years', '52 Years_perc', '53 Years', '53 Years_perc', '54 Years', '54 Years_perc', '55 Years', '55 Years_perc', '56 Years', '56 Years_perc', '57 Years', '57 Years_perc', '58 Years', '58 Years_perc', '59 Years', '59 Years_perc', '60 Years', '60 Years_perc', '61 Years', '61 Years_perc', '62 Years', '62 Years_perc', '63 Years', '63 Years_perc', '64 Years', '64 Years_perc', '65 Years', '65 Years_perc', '66 Years', '66 Years_perc', '67 Years', '67 Years_perc', '68 Years', '68 Years_perc', '69 Years', '69 Years_perc', '70 Years', '70 Years_perc', '71 Years', '71 Years_perc', '72 Years', '72 Years_perc', '73 Years', '73 Years_perc', '74 Years', '74 Years_perc', '75 Years', '75 Years_perc', '76 Years', '76 Years_perc', '77 Years', '77 Years_perc', '78 Years', '78 Years_perc', '79 Years', '79 Years_perc', '80 Years', '80 Years_perc', '81 Years', '81 Years_perc', '82 Years', '82 Years_perc', '83 Years', '83 Years_perc', '84 Years', '84 Years_perc', '85 Years', '85 Years_perc', '86 Years', '86 Years_perc', '87 Years', '87 Years_perc', '88 Years', '88 Years_perc', '89 Years', '89 Years_perc', '90 Years', '90 Years_perc', '91 Years', '91 Years_perc', '92 Years', '92 Years_perc', '93 Years', '93 Years_perc', '94 Years', '94 Years_perc', '95 Years', '95 Years_perc', '96 Years', '96 Years_perc', '97  Years', '97  Years_perc', '98  Years', '98  Years_perc', '99  Years', '99  Years_perc', '100 to 104  Years', '100 to 104  Years_perc', '105 to 109  Years', '105 to 109  Years_perc', '110  Years and Over', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_male_nhop\n",
      "Shape: (3221, 211)\n",
      "Number of Columns: 211\n",
      "Columns: ['Under 1 Year', 'Under 1 Year_perc', '1 Year', '1 Year_perc', '2 Years', '2 Years_perc', '3 Years', '3 Years_perc', '4 Years', '4 Years_perc', '5 Years', '5 Years_perc', '6 Years', '6 Years_perc', '7 Years', '7 Years_perc', '8 Years', '8 Years_perc', '9 Years', '9 Years_perc', '10 Years', '10 Years_perc', '11 Years', '11 Years_perc', '12 Years', '12 Years_perc', '13 Years', '13 Years_perc', '14 Years', '14 Years_perc', '15 Years', '15 Years_perc', '16 Years', '16 Years_perc', '17 Years', '17 Years_perc', '18 Years', '18 Years_perc', '19 Years', '19 Years_perc', '20 Years', '20 Years_perc', '21 Years', '21 Years_perc', '22 Years', '22 Years_perc', '23 Years', '23 Years_perc', '24 Years', '24 Years_perc', '25 Years', '25 Years_perc', '26 Years', '26 Years_perc', '27 Years', '27 Years_perc', '28 Years', '28 Years_perc', '29 Years', '29 Years_perc', '30 Years', '30 Years_perc', '31 Years', '31 Years_perc', '32 Years', '32 Years_perc', '33 Years', '33 Years_perc', '34 Years', '34 Years_perc', '35 Years', '35 Years_perc', '36 Years', '36 Years_perc', '37 Years', '37 Years_perc', '38 Years', '38 Years_perc', '39 Years', '39 Years_perc', '40 Years', '40 Years_perc', '41 Years', '41 Years_perc', '42 Years', '42 Years_perc', '43 Years', '43 Years_perc', '44 Years', '44 Years_perc', '45 Years', '45 Years_perc', '46 Years', '46 Years_perc', '47 Years', '47 Years_perc', '48 Years', '48 Years_perc', '49 Years', '49 Years_perc', '50 Years', '50 Years_perc', '51 Years', '51 Years_perc', '52 Years', '52 Years_perc', '53 Years', '53 Years_perc', '54 Years', '54 Years_perc', '55 Years', '55 Years_perc', '56 Years', '56 Years_perc', '57 Years', '57 Years_perc', '58 Years', '58 Years_perc', '59 Years', '59 Years_perc', '60 Years', '60 Years_perc', '61 Years', '61 Years_perc', '62 Years', '62 Years_perc', '63 Years', '63 Years_perc', '64 Years', '64 Years_perc', '65 Years', '65 Years_perc', '66 Years', '66 Years_perc', '67 Years', '67 Years_perc', '68 Years', '68 Years_perc', '69 Years', '69 Years_perc', '70 Years', '70 Years_perc', '71 Years', '71 Years_perc', '72 Years', '72 Years_perc', '73 Years', '73 Years_perc', '74 Years', '74 Years_perc', '75 Years', '75 Years_perc', '76 Years', '76 Years_perc', '77 Years', '77 Years_perc', '78 Years', '78 Years_perc', '79 Years', '79 Years_perc', '80 Years', '80 Years_perc', '81 Years', '81 Years_perc', '82 Years', '82 Years_perc', '83 Years', '83 Years_perc', '84 Years', '84 Years_perc', '85 Years', '85 Years_perc', '86 Years', '86 Years_perc', '87 Years', '87 Years_perc', '88 Years', '88 Years_perc', '89 Years', '89 Years_perc', '90 Years', '90 Years_perc', '91 Years', '91 Years_perc', '92 Years', '92 Years_perc', '93 Years', '93 Years_perc', '94 Years', '94 Years_perc', '95 Years', '95 Years_perc', '96 Years', '96 Years_perc', '97  Years', '97  Years_perc', '98  Years', '98  Years_perc', '99  Years', '99  Years_perc', '100 to 104  Years', '100 to 104  Years_perc', '105 to 109  Years', '105 to 109  Years_perc', '110  Years and Over', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_female_nhop\n",
      "Shape: (3221, 211)\n",
      "Number of Columns: 211\n",
      "Columns: ['Under 1 Year', 'Under 1 Year_perc', '1 Year', '1 Year_perc', '2 Years', '2 Years_perc', '3 Years', '3 Years_perc', '4 Years', '4 Years_perc', '5 Years', '5 Years_perc', '6 Years', '6 Years_perc', '7 Years', '7 Years_perc', '8 Years', '8 Years_perc', '9 Years', '9 Years_perc', '10 Years', '10 Years_perc', '11 Years', '11 Years_perc', '12 Years', '12 Years_perc', '13 Years', '13 Years_perc', '14 Years', '14 Years_perc', '15 Years', '15 Years_perc', '16 Years', '16 Years_perc', '17 Years', '17 Years_perc', '18 Years', '18 Years_perc', '19 Years', '19 Years_perc', '20 Years', '20 Years_perc', '21 Years', '21 Years_perc', '22 Years', '22 Years_perc', '23 Years', '23 Years_perc', '24 Years', '24 Years_perc', '25 Years', '25 Years_perc', '26 Years', '26 Years_perc', '27 Years', '27 Years_perc', '28 Years', '28 Years_perc', '29 Years', '29 Years_perc', '30 Years', '30 Years_perc', '31 Years', '31 Years_perc', '32 Years', '32 Years_perc', '33 Years', '33 Years_perc', '34 Years', '34 Years_perc', '35 Years', '35 Years_perc', '36 Years', '36 Years_perc', '37 Years', '37 Years_perc', '38 Years', '38 Years_perc', '39 Years', '39 Years_perc', '40 Years', '40 Years_perc', '41 Years', '41 Years_perc', '42 Years', '42 Years_perc', '43 Years', '43 Years_perc', '44 Years', '44 Years_perc', '45 Years', '45 Years_perc', '46 Years', '46 Years_perc', '47 Years', '47 Years_perc', '48 Years', '48 Years_perc', '49 Years', '49 Years_perc', '50 Years', '50 Years_perc', '51 Years', '51 Years_perc', '52 Years', '52 Years_perc', '53 Years', '53 Years_perc', '54 Years', '54 Years_perc', '55 Years', '55 Years_perc', '56 Years', '56 Years_perc', '57 Years', '57 Years_perc', '58 Years', '58 Years_perc', '59 Years', '59 Years_perc', '60 Years', '60 Years_perc', '61 Years', '61 Years_perc', '62 Years', '62 Years_perc', '63 Years', '63 Years_perc', '64 Years', '64 Years_perc', '65 Years', '65 Years_perc', '66 Years', '66 Years_perc', '67 Years', '67 Years_perc', '68 Years', '68 Years_perc', '69 Years', '69 Years_perc', '70 Years', '70 Years_perc', '71 Years', '71 Years_perc', '72 Years', '72 Years_perc', '73 Years', '73 Years_perc', '74 Years', '74 Years_perc', '75 Years', '75 Years_perc', '76 Years', '76 Years_perc', '77 Years', '77 Years_perc', '78 Years', '78 Years_perc', '79 Years', '79 Years_perc', '80 Years', '80 Years_perc', '81 Years', '81 Years_perc', '82 Years', '82 Years_perc', '83 Years', '83 Years_perc', '84 Years', '84 Years_perc', '85 Years', '85 Years_perc', '86 Years', '86 Years_perc', '87 Years', '87 Years_perc', '88 Years', '88 Years_perc', '89 Years', '89 Years_perc', '90 Years', '90 Years_perc', '91 Years', '91 Years_perc', '92 Years', '92 Years_perc', '93 Years', '93 Years_perc', '94 Years', '94 Years_perc', '95 Years', '95 Years_perc', '96 Years', '96 Years_perc', '97  Years', '97  Years_perc', '98  Years', '98  Years_perc', '99  Years', '99  Years_perc', '100 to 104  Years', '100 to 104  Years_perc', '105 to 109  Years', '105 to 109  Years_perc', '110  Years and Over', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_male_sor\n",
      "Shape: (3221, 211)\n",
      "Number of Columns: 211\n",
      "Columns: ['Under 1 Year', 'Under 1 Year_perc', '1 Year', '1 Year_perc', '2 Years', '2 Years_perc', '3 Years', '3 Years_perc', '4 Years', '4 Years_perc', '5 Years', '5 Years_perc', '6 Years', '6 Years_perc', '7 Years', '7 Years_perc', '8 Years', '8 Years_perc', '9 Years', '9 Years_perc', '10 Years', '10 Years_perc', '11 Years', '11 Years_perc', '12 Years', '12 Years_perc', '13 Years', '13 Years_perc', '14 Years', '14 Years_perc', '15 Years', '15 Years_perc', '16 Years', '16 Years_perc', '17 Years', '17 Years_perc', '18 Years', '18 Years_perc', '19 Years', '19 Years_perc', '20 Years', '20 Years_perc', '21 Years', '21 Years_perc', '22 Years', '22 Years_perc', '23 Years', '23 Years_perc', '24 Years', '24 Years_perc', '25 Years', '25 Years_perc', '26 Years', '26 Years_perc', '27 Years', '27 Years_perc', '28 Years', '28 Years_perc', '29 Years', '29 Years_perc', '30 Years', '30 Years_perc', '31 Years', '31 Years_perc', '32 Years', '32 Years_perc', '33 Years', '33 Years_perc', '34 Years', '34 Years_perc', '35 Years', '35 Years_perc', '36 Years', '36 Years_perc', '37 Years', '37 Years_perc', '38 Years', '38 Years_perc', '39 Years', '39 Years_perc', '40 Years', '40 Years_perc', '41 Years', '41 Years_perc', '42 Years', '42 Years_perc', '43 Years', '43 Years_perc', '44 Years', '44 Years_perc', '45 Years', '45 Years_perc', '46 Years', '46 Years_perc', '47 Years', '47 Years_perc', '48 Years', '48 Years_perc', '49 Years', '49 Years_perc', '50 Years', '50 Years_perc', '51 Years', '51 Years_perc', '52 Years', '52 Years_perc', '53 Years', '53 Years_perc', '54 Years', '54 Years_perc', '55 Years', '55 Years_perc', '56 Years', '56 Years_perc', '57 Years', '57 Years_perc', '58 Years', '58 Years_perc', '59 Years', '59 Years_perc', '60 Years', '60 Years_perc', '61 Years', '61 Years_perc', '62 Years', '62 Years_perc', '63 Years', '63 Years_perc', '64 Years', '64 Years_perc', '65 Years', '65 Years_perc', '66 Years', '66 Years_perc', '67 Years', '67 Years_perc', '68 Years', '68 Years_perc', '69 Years', '69 Years_perc', '70 Years', '70 Years_perc', '71 Years', '71 Years_perc', '72 Years', '72 Years_perc', '73 Years', '73 Years_perc', '74 Years', '74 Years_perc', '75 Years', '75 Years_perc', '76 Years', '76 Years_perc', '77 Years', '77 Years_perc', '78 Years', '78 Years_perc', '79 Years', '79 Years_perc', '80 Years', '80 Years_perc', '81 Years', '81 Years_perc', '82 Years', '82 Years_perc', '83 Years', '83 Years_perc', '84 Years', '84 Years_perc', '85 Years', '85 Years_perc', '86 Years', '86 Years_perc', '87 Years', '87 Years_perc', '88 Years', '88 Years_perc', '89 Years', '89 Years_perc', '90 Years', '90 Years_perc', '91 Years', '91 Years_perc', '92 Years', '92 Years_perc', '93 Years', '93 Years_perc', '94 Years', '94 Years_perc', '95 Years', '95 Years_perc', '96 Years', '96 Years_perc', '97  Years', '97  Years_perc', '98  Years', '98  Years_perc', '99  Years', '99  Years_perc', '100 to 104  Years', '100 to 104  Years_perc', '105 to 109  Years', '105 to 109  Years_perc', '110  Years and Over', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_female_sor\n",
      "Shape: (3221, 211)\n",
      "Number of Columns: 211\n",
      "Columns: ['Under 1 Year', 'Under 1 Year_perc', '1 Year', '1 Year_perc', '2 Years', '2 Years_perc', '3 Years', '3 Years_perc', '4 Years', '4 Years_perc', '5 Years', '5 Years_perc', '6 Years', '6 Years_perc', '7 Years', '7 Years_perc', '8 Years', '8 Years_perc', '9 Years', '9 Years_perc', '10 Years', '10 Years_perc', '11 Years', '11 Years_perc', '12 Years', '12 Years_perc', '13 Years', '13 Years_perc', '14 Years', '14 Years_perc', '15 Years', '15 Years_perc', '16 Years', '16 Years_perc', '17 Years', '17 Years_perc', '18 Years', '18 Years_perc', '19 Years', '19 Years_perc', '20 Years', '20 Years_perc', '21 Years', '21 Years_perc', '22 Years', '22 Years_perc', '23 Years', '23 Years_perc', '24 Years', '24 Years_perc', '25 Years', '25 Years_perc', '26 Years', '26 Years_perc', '27 Years', '27 Years_perc', '28 Years', '28 Years_perc', '29 Years', '29 Years_perc', '30 Years', '30 Years_perc', '31 Years', '31 Years_perc', '32 Years', '32 Years_perc', '33 Years', '33 Years_perc', '34 Years', '34 Years_perc', '35 Years', '35 Years_perc', '36 Years', '36 Years_perc', '37 Years', '37 Years_perc', '38 Years', '38 Years_perc', '39 Years', '39 Years_perc', '40 Years', '40 Years_perc', '41 Years', '41 Years_perc', '42 Years', '42 Years_perc', '43 Years', '43 Years_perc', '44 Years', '44 Years_perc', '45 Years', '45 Years_perc', '46 Years', '46 Years_perc', '47 Years', '47 Years_perc', '48 Years', '48 Years_perc', '49 Years', '49 Years_perc', '50 Years', '50 Years_perc', '51 Years', '51 Years_perc', '52 Years', '52 Years_perc', '53 Years', '53 Years_perc', '54 Years', '54 Years_perc', '55 Years', '55 Years_perc', '56 Years', '56 Years_perc', '57 Years', '57 Years_perc', '58 Years', '58 Years_perc', '59 Years', '59 Years_perc', '60 Years', '60 Years_perc', '61 Years', '61 Years_perc', '62 Years', '62 Years_perc', '63 Years', '63 Years_perc', '64 Years', '64 Years_perc', '65 Years', '65 Years_perc', '66 Years', '66 Years_perc', '67 Years', '67 Years_perc', '68 Years', '68 Years_perc', '69 Years', '69 Years_perc', '70 Years', '70 Years_perc', '71 Years', '71 Years_perc', '72 Years', '72 Years_perc', '73 Years', '73 Years_perc', '74 Years', '74 Years_perc', '75 Years', '75 Years_perc', '76 Years', '76 Years_perc', '77 Years', '77 Years_perc', '78 Years', '78 Years_perc', '79 Years', '79 Years_perc', '80 Years', '80 Years_perc', '81 Years', '81 Years_perc', '82 Years', '82 Years_perc', '83 Years', '83 Years_perc', '84 Years', '84 Years_perc', '85 Years', '85 Years_perc', '86 Years', '86 Years_perc', '87 Years', '87 Years_perc', '88 Years', '88 Years_perc', '89 Years', '89 Years_perc', '90 Years', '90 Years_perc', '91 Years', '91 Years_perc', '92 Years', '92 Years_perc', '93 Years', '93 Years_perc', '94 Years', '94 Years_perc', '95 Years', '95 Years_perc', '96 Years', '96 Years_perc', '97  Years', '97  Years_perc', '98  Years', '98  Years_perc', '99  Years', '99  Years_perc', '100 to 104  Years', '100 to 104  Years_perc', '105 to 109  Years', '105 to 109  Years_perc', '110  Years and Over', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_male_tom\n",
      "Shape: (3221, 211)\n",
      "Number of Columns: 211\n",
      "Columns: ['Under 1 Year', 'Under 1 Year_perc', '1 Year', '1 Year_perc', '2 Years', '2 Years_perc', '3 Years', '3 Years_perc', '4 Years', '4 Years_perc', '5 Years', '5 Years_perc', '6 Years', '6 Years_perc', '7 Years', '7 Years_perc', '8 Years', '8 Years_perc', '9 Years', '9 Years_perc', '10 Years', '10 Years_perc', '11 Years', '11 Years_perc', '12 Years', '12 Years_perc', '13 Years', '13 Years_perc', '14 Years', '14 Years_perc', '15 Years', '15 Years_perc', '16 Years', '16 Years_perc', '17 Years', '17 Years_perc', '18 Years', '18 Years_perc', '19 Years', '19 Years_perc', '20 Years', '20 Years_perc', '21 Years', '21 Years_perc', '22 Years', '22 Years_perc', '23 Years', '23 Years_perc', '24 Years', '24 Years_perc', '25 Years', '25 Years_perc', '26 Years', '26 Years_perc', '27 Years', '27 Years_perc', '28 Years', '28 Years_perc', '29 Years', '29 Years_perc', '30 Years', '30 Years_perc', '31 Years', '31 Years_perc', '32 Years', '32 Years_perc', '33 Years', '33 Years_perc', '34 Years', '34 Years_perc', '35 Years', '35 Years_perc', '36 Years', '36 Years_perc', '37 Years', '37 Years_perc', '38 Years', '38 Years_perc', '39 Years', '39 Years_perc', '40 Years', '40 Years_perc', '41 Years', '41 Years_perc', '42 Years', '42 Years_perc', '43 Years', '43 Years_perc', '44 Years', '44 Years_perc', '45 Years', '45 Years_perc', '46 Years', '46 Years_perc', '47 Years', '47 Years_perc', '48 Years', '48 Years_perc', '49 Years', '49 Years_perc', '50 Years', '50 Years_perc', '51 Years', '51 Years_perc', '52 Years', '52 Years_perc', '53 Years', '53 Years_perc', '54 Years', '54 Years_perc', '55 Years', '55 Years_perc', '56 Years', '56 Years_perc', '57 Years', '57 Years_perc', '58 Years', '58 Years_perc', '59 Years', '59 Years_perc', '60 Years', '60 Years_perc', '61 Years', '61 Years_perc', '62 Years', '62 Years_perc', '63 Years', '63 Years_perc', '64 Years', '64 Years_perc', '65 Years', '65 Years_perc', '66 Years', '66 Years_perc', '67 Years', '67 Years_perc', '68 Years', '68 Years_perc', '69 Years', '69 Years_perc', '70 Years', '70 Years_perc', '71 Years', '71 Years_perc', '72 Years', '72 Years_perc', '73 Years', '73 Years_perc', '74 Years', '74 Years_perc', '75 Years', '75 Years_perc', '76 Years', '76 Years_perc', '77 Years', '77 Years_perc', '78 Years', '78 Years_perc', '79 Years', '79 Years_perc', '80 Years', '80 Years_perc', '81 Years', '81 Years_perc', '82 Years', '82 Years_perc', '83 Years', '83 Years_perc', '84 Years', '84 Years_perc', '85 Years', '85 Years_perc', '86 Years', '86 Years_perc', '87 Years', '87 Years_perc', '88 Years', '88 Years_perc', '89 Years', '89 Years_perc', '90 Years', '90 Years_perc', '91 Years', '91 Years_perc', '92 Years', '92 Years_perc', '93 Years', '93 Years_perc', '94 Years', '94 Years_perc', '95 Years', '95 Years_perc', '96 Years', '96 Years_perc', '97  Years', '97  Years_perc', '98  Years', '98  Years_perc', '99  Years', '99  Years_perc', '100 to 104  Years', '100 to 104  Years_perc', '105 to 109  Years', '105 to 109  Years_perc', '110  Years and Over', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_female_tom\n",
      "Shape: (3221, 211)\n",
      "Number of Columns: 211\n",
      "Columns: ['Under 1 Year', 'Under 1 Year_perc', '1 Year', '1 Year_perc', '2 Years', '2 Years_perc', '3 Years', '3 Years_perc', '4 Years', '4 Years_perc', '5 Years', '5 Years_perc', '6 Years', '6 Years_perc', '7 Years', '7 Years_perc', '8 Years', '8 Years_perc', '9 Years', '9 Years_perc', '10 Years', '10 Years_perc', '11 Years', '11 Years_perc', '12 Years', '12 Years_perc', '13 Years', '13 Years_perc', '14 Years', '14 Years_perc', '15 Years', '15 Years_perc', '16 Years', '16 Years_perc', '17 Years', '17 Years_perc', '18 Years', '18 Years_perc', '19 Years', '19 Years_perc', '20 Years', '20 Years_perc', '21 Years', '21 Years_perc', '22 Years', '22 Years_perc', '23 Years', '23 Years_perc', '24 Years', '24 Years_perc', '25 Years', '25 Years_perc', '26 Years', '26 Years_perc', '27 Years', '27 Years_perc', '28 Years', '28 Years_perc', '29 Years', '29 Years_perc', '30 Years', '30 Years_perc', '31 Years', '31 Years_perc', '32 Years', '32 Years_perc', '33 Years', '33 Years_perc', '34 Years', '34 Years_perc', '35 Years', '35 Years_perc', '36 Years', '36 Years_perc', '37 Years', '37 Years_perc', '38 Years', '38 Years_perc', '39 Years', '39 Years_perc', '40 Years', '40 Years_perc', '41 Years', '41 Years_perc', '42 Years', '42 Years_perc', '43 Years', '43 Years_perc', '44 Years', '44 Years_perc', '45 Years', '45 Years_perc', '46 Years', '46 Years_perc', '47 Years', '47 Years_perc', '48 Years', '48 Years_perc', '49 Years', '49 Years_perc', '50 Years', '50 Years_perc', '51 Years', '51 Years_perc', '52 Years', '52 Years_perc', '53 Years', '53 Years_perc', '54 Years', '54 Years_perc', '55 Years', '55 Years_perc', '56 Years', '56 Years_perc', '57 Years', '57 Years_perc', '58 Years', '58 Years_perc', '59 Years', '59 Years_perc', '60 Years', '60 Years_perc', '61 Years', '61 Years_perc', '62 Years', '62 Years_perc', '63 Years', '63 Years_perc', '64 Years', '64 Years_perc', '65 Years', '65 Years_perc', '66 Years', '66 Years_perc', '67 Years', '67 Years_perc', '68 Years', '68 Years_perc', '69 Years', '69 Years_perc', '70 Years', '70 Years_perc', '71 Years', '71 Years_perc', '72 Years', '72 Years_perc', '73 Years', '73 Years_perc', '74 Years', '74 Years_perc', '75 Years', '75 Years_perc', '76 Years', '76 Years_perc', '77 Years', '77 Years_perc', '78 Years', '78 Years_perc', '79 Years', '79 Years_perc', '80 Years', '80 Years_perc', '81 Years', '81 Years_perc', '82 Years', '82 Years_perc', '83 Years', '83 Years_perc', '84 Years', '84 Years_perc', '85 Years', '85 Years_perc', '86 Years', '86 Years_perc', '87 Years', '87 Years_perc', '88 Years', '88 Years_perc', '89 Years', '89 Years_perc', '90 Years', '90 Years_perc', '91 Years', '91 Years_perc', '92 Years', '92 Years_perc', '93 Years', '93 Years_perc', '94 Years', '94 Years_perc', '95 Years', '95 Years_perc', '96 Years', '96 Years_perc', '97  Years', '97  Years_perc', '98  Years', '98  Years_perc', '99  Years', '99  Years_perc', '100 to 104  Years', '100 to 104  Years_perc', '105 to 109  Years', '105 to 109  Years_perc', '110  Years and Over', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_male_hol\n",
      "Shape: (3221, 211)\n",
      "Number of Columns: 211\n",
      "Columns: ['Under 1 Year', 'Under 1 Year_perc', '1 Year', '1 Year_perc', '2 Years', '2 Years_perc', '3 Years', '3 Years_perc', '4 Years', '4 Years_perc', '5 Years', '5 Years_perc', '6 Years', '6 Years_perc', '7 Years', '7 Years_perc', '8 Years', '8 Years_perc', '9 Years', '9 Years_perc', '10 Years', '10 Years_perc', '11 Years', '11 Years_perc', '12 Years', '12 Years_perc', '13 Years', '13 Years_perc', '14 Years', '14 Years_perc', '15 Years', '15 Years_perc', '16 Years', '16 Years_perc', '17 Years', '17 Years_perc', '18 Years', '18 Years_perc', '19 Years', '19 Years_perc', '20 Years', '20 Years_perc', '21 Years', '21 Years_perc', '22 Years', '22 Years_perc', '23 Years', '23 Years_perc', '24 Years', '24 Years_perc', '25 Years', '25 Years_perc', '26 Years', '26 Years_perc', '27 Years', '27 Years_perc', '28 Years', '28 Years_perc', '29 Years', '29 Years_perc', '30 Years', '30 Years_perc', '31 Years', '31 Years_perc', '32 Years', '32 Years_perc', '33 Years', '33 Years_perc', '34 Years', '34 Years_perc', '35 Years', '35 Years_perc', '36 Years', '36 Years_perc', '37 Years', '37 Years_perc', '38 Years', '38 Years_perc', '39 Years', '39 Years_perc', '40 Years', '40 Years_perc', '41 Years', '41 Years_perc', '42 Years', '42 Years_perc', '43 Years', '43 Years_perc', '44 Years', '44 Years_perc', '45 Years', '45 Years_perc', '46 Years', '46 Years_perc', '47 Years', '47 Years_perc', '48 Years', '48 Years_perc', '49 Years', '49 Years_perc', '50 Years', '50 Years_perc', '51 Years', '51 Years_perc', '52 Years', '52 Years_perc', '53 Years', '53 Years_perc', '54 Years', '54 Years_perc', '55 Years', '55 Years_perc', '56 Years', '56 Years_perc', '57 Years', '57 Years_perc', '58 Years', '58 Years_perc', '59 Years', '59 Years_perc', '60 Years', '60 Years_perc', '61 Years', '61 Years_perc', '62 Years', '62 Years_perc', '63 Years', '63 Years_perc', '64 Years', '64 Years_perc', '65 Years', '65 Years_perc', '66 Years', '66 Years_perc', '67 Years', '67 Years_perc', '68 Years', '68 Years_perc', '69 Years', '69 Years_perc', '70 Years', '70 Years_perc', '71 Years', '71 Years_perc', '72 Years', '72 Years_perc', '73 Years', '73 Years_perc', '74 Years', '74 Years_perc', '75 Years', '75 Years_perc', '76 Years', '76 Years_perc', '77 Years', '77 Years_perc', '78 Years', '78 Years_perc', '79 Years', '79 Years_perc', '80 Years', '80 Years_perc', '81 Years', '81 Years_perc', '82 Years', '82 Years_perc', '83 Years', '83 Years_perc', '84 Years', '84 Years_perc', '85 Years', '85 Years_perc', '86 Years', '86 Years_perc', '87 Years', '87 Years_perc', '88 Years', '88 Years_perc', '89 Years', '89 Years_perc', '90 Years', '90 Years_perc', '91 Years', '91 Years_perc', '92 Years', '92 Years_perc', '93 Years', '93 Years_perc', '94 Years', '94 Years_perc', '95 Years', '95 Years_perc', '96 Years', '96 Years_perc', '97  Years', '97  Years_perc', '98  Years', '98  Years_perc', '99  Years', '99  Years_perc', '100 to 104  Years', '100 to 104  Years_perc', '105 to 109  Years', '105 to 109  Years_perc', '110  Years and Over', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_female_hol\n",
      "Shape: (3221, 211)\n",
      "Number of Columns: 211\n",
      "Columns: ['Under 1 Year', 'Under 1 Year_perc', '1 Year', '1 Year_perc', '2 Years', '2 Years_perc', '3 Years', '3 Years_perc', '4 Years', '4 Years_perc', '5 Years', '5 Years_perc', '6 Years', '6 Years_perc', '7 Years', '7 Years_perc', '8 Years', '8 Years_perc', '9 Years', '9 Years_perc', '10 Years', '10 Years_perc', '11 Years', '11 Years_perc', '12 Years', '12 Years_perc', '13 Years', '13 Years_perc', '14 Years', '14 Years_perc', '15 Years', '15 Years_perc', '16 Years', '16 Years_perc', '17 Years', '17 Years_perc', '18 Years', '18 Years_perc', '19 Years', '19 Years_perc', '20 Years', '20 Years_perc', '21 Years', '21 Years_perc', '22 Years', '22 Years_perc', '23 Years', '23 Years_perc', '24 Years', '24 Years_perc', '25 Years', '25 Years_perc', '26 Years', '26 Years_perc', '27 Years', '27 Years_perc', '28 Years', '28 Years_perc', '29 Years', '29 Years_perc', '30 Years', '30 Years_perc', '31 Years', '31 Years_perc', '32 Years', '32 Years_perc', '33 Years', '33 Years_perc', '34 Years', '34 Years_perc', '35 Years', '35 Years_perc', '36 Years', '36 Years_perc', '37 Years', '37 Years_perc', '38 Years', '38 Years_perc', '39 Years', '39 Years_perc', '40 Years', '40 Years_perc', '41 Years', '41 Years_perc', '42 Years', '42 Years_perc', '43 Years', '43 Years_perc', '44 Years', '44 Years_perc', '45 Years', '45 Years_perc', '46 Years', '46 Years_perc', '47 Years', '47 Years_perc', '48 Years', '48 Years_perc', '49 Years', '49 Years_perc', '50 Years', '50 Years_perc', '51 Years', '51 Years_perc', '52 Years', '52 Years_perc', '53 Years', '53 Years_perc', '54 Years', '54 Years_perc', '55 Years', '55 Years_perc', '56 Years', '56 Years_perc', '57 Years', '57 Years_perc', '58 Years', '58 Years_perc', '59 Years', '59 Years_perc', '60 Years', '60 Years_perc', '61 Years', '61 Years_perc', '62 Years', '62 Years_perc', '63 Years', '63 Years_perc', '64 Years', '64 Years_perc', '65 Years', '65 Years_perc', '66 Years', '66 Years_perc', '67 Years', '67 Years_perc', '68 Years', '68 Years_perc', '69 Years', '69 Years_perc', '70 Years', '70 Years_perc', '71 Years', '71 Years_perc', '72 Years', '72 Years_perc', '73 Years', '73 Years_perc', '74 Years', '74 Years_perc', '75 Years', '75 Years_perc', '76 Years', '76 Years_perc', '77 Years', '77 Years_perc', '78 Years', '78 Years_perc', '79 Years', '79 Years_perc', '80 Years', '80 Years_perc', '81 Years', '81 Years_perc', '82 Years', '82 Years_perc', '83 Years', '83 Years_perc', '84 Years', '84 Years_perc', '85 Years', '85 Years_perc', '86 Years', '86 Years_perc', '87 Years', '87 Years_perc', '88 Years', '88 Years_perc', '89 Years', '89 Years_perc', '90 Years', '90 Years_perc', '91 Years', '91 Years_perc', '92 Years', '92 Years_perc', '93 Years', '93 Years_perc', '94 Years', '94 Years_perc', '95 Years', '95 Years_perc', '96 Years', '96 Years_perc', '97  Years', '97  Years_perc', '98  Years', '98  Years_perc', '99  Years', '99  Years_perc', '100 to 104  Years', '100 to 104  Years_perc', '105 to 109  Years', '105 to 109  Years_perc', '110  Years and Over', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the dataframes in 'dfs'\n",
    "print(\"Data Frames in 'perc_df':\")\n",
    "for df_name, df in dfs.items():\n",
    "    if df_name in perc_df:\n",
    "        print(\"Dataframe Name:\", df_name)\n",
    "        print(\"Shape:\", df.shape)\n",
    "        print(f\"Number of Columns: {len(df.columns)}\")\n",
    "        print(\"Columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Weighted Average Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing modified dataframes from dict dfs for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the new dictionary 'dfs_perc'\n",
    "dfs_perc = {}\n",
    "\n",
    "# Iterate over the dataframe names in 'perc_df' list\n",
    "for df_name in perc_df:\n",
    "    # Check if the dataframe name exists in 'dfs' dictionary\n",
    "    if df_name in dfs:\n",
    "        # Move the matching dataframe from 'dfs' to 'dfs_perc'\n",
    "        dfs_perc[df_name] = dfs.pop(df_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary 'dfs':\n",
      "9\n",
      "['DF_total_all', 'DF_total_whi', 'DF_total_baa', 'DF_total_aian', 'DF_total_aa', 'DF_total_nhop', 'DF_total_sor', 'DF_total_tom', 'DF_total_hol']\n",
      "\n",
      "Dictionary 'perc_df':\n",
      "18\n",
      "['DF_male_all', 'DF_female_all', 'DF_total_male_whi', 'DF_total_female_whi', 'DF_total_male_baa', 'DF_total_female_baa', 'DF_total_male_aian', 'DF_total_female_aian', 'DF_total_male_aa', 'DF_total_female_aa', 'DF_total_male_nhop', 'DF_total_female_nhop', 'DF_total_male_sor', 'DF_total_female_sor', 'DF_total_male_tom', 'DF_total_female_tom', 'DF_total_male_hol', 'DF_total_female_hol']\n"
     ]
    }
   ],
   "source": [
    "# Printing list of both dataframe dictionaries to verify last step\n",
    "\n",
    "# We should have 9 in dict 'dfs' and 18 in new dict 'perc_df'\n",
    "\n",
    "print(\"Dictionary 'dfs':\")\n",
    "print(len(dfs.keys()))\n",
    "print(list(dfs.keys()))\n",
    "\n",
    "print(\"\\nDictionary 'perc_df':\")\n",
    "print(len(dfs_perc.keys()))\n",
    "print(list(dfs_perc.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables for columns to drop to new dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Under 1 Year_perc','1 Year_perc','2 Years_perc',\n",
    "                  '3 Years_perc','4 Years_perc','5 Years_perc','6 Years_perc',\n",
    "                  '7 Years_perc','8 Years_perc','9 Years_perc','10 Years_perc',\n",
    "                  '11 Years_perc','12 Years_perc','13 Years_perc',\n",
    "                  '14 Years_perc','15 Years_perc','16 Years_perc',\n",
    "                  '17 Years_perc','18 Years_perc','19 Years_perc',\n",
    "                  '20 Years_perc','21 Years_perc','22 Years_perc',\n",
    "                  '23 Years_perc','24 Years_perc','25 Years_perc',\n",
    "                  '26 Years_perc','27 Years_perc','28 Years_perc',\n",
    "                  '29 Years_perc','30 Years_perc','31 Years_perc',\n",
    "                  '32 Years_perc','33 Years_perc','34 Years_perc',\n",
    "                  '35 Years_perc','36 Years_perc','37 Years_perc',\n",
    "                  '38 Years_perc','39 Years_perc','40 Years_perc',\n",
    "                  '41 Years_perc','42 Years_perc','43 Years_perc',\n",
    "                  '44 Years_perc','45 Years_perc','46 Years_perc',\n",
    "                  '47 Years_perc','48 Years_perc','49 Years_perc',\n",
    "                  '50 Years_perc','51 Years_perc','52 Years_perc',\n",
    "                  '53 Years_perc','54 Years_perc','55 Years_perc',\n",
    "                  '56 Years_perc','57 Years_perc','58 Years_perc',\n",
    "                  '59 Years_perc','60 Years_perc','61 Years_perc',\n",
    "                  '62 Years_perc','63 Years_perc','64 Years_perc',\n",
    "                  '65 Years_perc','66 Years_perc','67 Years_perc',\n",
    "                  '68 Years_perc','69 Years_perc','70 Years_perc',\n",
    "                  '71 Years_perc','72 Years_perc','73 Years_perc',\n",
    "                  '74 Years_perc','75 Years_perc','76 Years_perc',\n",
    "                  '77 Years_perc','78 Years_perc','79 Years_perc',\n",
    "                  '80 Years_perc','81 Years_perc','82 Years_perc',\n",
    "                  '83 Years_perc','84 Years_perc','85 Years_perc',\n",
    "                  '86 Years_perc','87 Years_perc','88 Years_perc',\n",
    "                  '89 Years_perc','90 Years_perc','91 Years_perc',\n",
    "                  '92 Years_perc','93 Years_perc','94 Years_perc',\n",
    "                  '95 Years_perc','96 Years_perc','97  Years_perc',\n",
    "                  '98  Years_perc','99  Years_perc','100 to 104  Years_perc',\n",
    "                  '105 to 109  Years_perc','110  Years and Over_perc','Total',\n",
    "                  'Location','State','County','FIPS'\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_columns = {}\n",
    "\n",
    "# Iterate over the dataframes in 'dfs_perc'\n",
    "for df_name, df in dfs_perc.items():\n",
    "    # Store the dropped columns' data\n",
    "    dropped_columns[df_name] = df[columns_to_drop]\n",
    "\n",
    "    # Drop the specified columns from each dataframe\n",
    "    dfs_perc[df_name] = df.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary 'dfs_perc':\n",
      "DataFrame 'DF_male_all' column names:\n",
      "['Under 1 Year', '1 Year', '2 Years', '3 Years', '4 Years', '5 Years', '6 Years', '7 Years', '8 Years', '9 Years', '10 Years', '11 Years', '12 Years', '13 Years', '14 Years', '15 Years', '16 Years', '17 Years', '18 Years', '19 Years', '20 Years', '21 Years', '22 Years', '23 Years', '24 Years', '25 Years', '26 Years', '27 Years', '28 Years', '29 Years', '30 Years', '31 Years', '32 Years', '33 Years', '34 Years', '35 Years', '36 Years', '37 Years', '38 Years', '39 Years', '40 Years', '41 Years', '42 Years', '43 Years', '44 Years', '45 Years', '46 Years', '47 Years', '48 Years', '49 Years', '50 Years', '51 Years', '52 Years', '53 Years', '54 Years', '55 Years', '56 Years', '57 Years', '58 Years', '59 Years', '60 Years', '61 Years', '62 Years', '63 Years', '64 Years', '65 Years', '66 Years', '67 Years', '68 Years', '69 Years', '70 Years', '71 Years', '72 Years', '73 Years', '74 Years', '75 Years', '76 Years', '77 Years', '78 Years', '79 Years', '80 Years', '81 Years', '82 Years', '83 Years', '84 Years', '85 Years', '86 Years', '87 Years', '88 Years', '89 Years', '90 Years', '91 Years', '92 Years', '93 Years', '94 Years', '95 Years', '96 Years', '97  Years', '98  Years', '99  Years', '100 to 104  Years', '105 to 109  Years', '110  Years and Over']\n",
      "DataFrame 'DF_female_all' column names:\n",
      "['Under 1 Year', '1 Year', '2 Years', '3 Years', '4 Years', '5 Years', '6 Years', '7 Years', '8 Years', '9 Years', '10 Years', '11 Years', '12 Years', '13 Years', '14 Years', '15 Years', '16 Years', '17 Years', '18 Years', '19 Years', '20 Years', '21 Years', '22 Years', '23 Years', '24 Years', '25 Years', '26 Years', '27 Years', '28 Years', '29 Years', '30 Years', '31 Years', '32 Years', '33 Years', '34 Years', '35 Years', '36 Years', '37 Years', '38 Years', '39 Years', '40 Years', '41 Years', '42 Years', '43 Years', '44 Years', '45 Years', '46 Years', '47 Years', '48 Years', '49 Years', '50 Years', '51 Years', '52 Years', '53 Years', '54 Years', '55 Years', '56 Years', '57 Years', '58 Years', '59 Years', '60 Years', '61 Years', '62 Years', '63 Years', '64 Years', '65 Years', '66 Years', '67 Years', '68 Years', '69 Years', '70 Years', '71 Years', '72 Years', '73 Years', '74 Years', '75 Years', '76 Years', '77 Years', '78 Years', '79 Years', '80 Years', '81 Years', '82 Years', '83 Years', '84 Years', '85 Years', '86 Years', '87 Years', '88 Years', '89 Years', '90 Years', '91 Years', '92 Years', '93 Years', '94 Years', '95 Years', '96 Years', '97  Years', '98  Years', '99  Years', '100 to 104  Years', '105 to 109  Years', '110  Years and Over']\n",
      "DataFrame 'DF_total_male_whi' column names:\n",
      "['Under 1 Year', '1 Year', '2 Years', '3 Years', '4 Years', '5 Years', '6 Years', '7 Years', '8 Years', '9 Years', '10 Years', '11 Years', '12 Years', '13 Years', '14 Years', '15 Years', '16 Years', '17 Years', '18 Years', '19 Years', '20 Years', '21 Years', '22 Years', '23 Years', '24 Years', '25 Years', '26 Years', '27 Years', '28 Years', '29 Years', '30 Years', '31 Years', '32 Years', '33 Years', '34 Years', '35 Years', '36 Years', '37 Years', '38 Years', '39 Years', '40 Years', '41 Years', '42 Years', '43 Years', '44 Years', '45 Years', '46 Years', '47 Years', '48 Years', '49 Years', '50 Years', '51 Years', '52 Years', '53 Years', '54 Years', '55 Years', '56 Years', '57 Years', '58 Years', '59 Years', '60 Years', '61 Years', '62 Years', '63 Years', '64 Years', '65 Years', '66 Years', '67 Years', '68 Years', '69 Years', '70 Years', '71 Years', '72 Years', '73 Years', '74 Years', '75 Years', '76 Years', '77 Years', '78 Years', '79 Years', '80 Years', '81 Years', '82 Years', '83 Years', '84 Years', '85 Years', '86 Years', '87 Years', '88 Years', '89 Years', '90 Years', '91 Years', '92 Years', '93 Years', '94 Years', '95 Years', '96 Years', '97  Years', '98  Years', '99  Years', '100 to 104  Years', '105 to 109  Years', '110  Years and Over']\n",
      "DataFrame 'DF_total_female_whi' column names:\n",
      "['Under 1 Year', '1 Year', '2 Years', '3 Years', '4 Years', '5 Years', '6 Years', '7 Years', '8 Years', '9 Years', '10 Years', '11 Years', '12 Years', '13 Years', '14 Years', '15 Years', '16 Years', '17 Years', '18 Years', '19 Years', '20 Years', '21 Years', '22 Years', '23 Years', '24 Years', '25 Years', '26 Years', '27 Years', '28 Years', '29 Years', '30 Years', '31 Years', '32 Years', '33 Years', '34 Years', '35 Years', '36 Years', '37 Years', '38 Years', '39 Years', '40 Years', '41 Years', '42 Years', '43 Years', '44 Years', '45 Years', '46 Years', '47 Years', '48 Years', '49 Years', '50 Years', '51 Years', '52 Years', '53 Years', '54 Years', '55 Years', '56 Years', '57 Years', '58 Years', '59 Years', '60 Years', '61 Years', '62 Years', '63 Years', '64 Years', '65 Years', '66 Years', '67 Years', '68 Years', '69 Years', '70 Years', '71 Years', '72 Years', '73 Years', '74 Years', '75 Years', '76 Years', '77 Years', '78 Years', '79 Years', '80 Years', '81 Years', '82 Years', '83 Years', '84 Years', '85 Years', '86 Years', '87 Years', '88 Years', '89 Years', '90 Years', '91 Years', '92 Years', '93 Years', '94 Years', '95 Years', '96 Years', '97  Years', '98  Years', '99  Years', '100 to 104  Years', '105 to 109  Years', '110  Years and Over']\n",
      "DataFrame 'DF_total_male_baa' column names:\n",
      "['Under 1 Year', '1 Year', '2 Years', '3 Years', '4 Years', '5 Years', '6 Years', '7 Years', '8 Years', '9 Years', '10 Years', '11 Years', '12 Years', '13 Years', '14 Years', '15 Years', '16 Years', '17 Years', '18 Years', '19 Years', '20 Years', '21 Years', '22 Years', '23 Years', '24 Years', '25 Years', '26 Years', '27 Years', '28 Years', '29 Years', '30 Years', '31 Years', '32 Years', '33 Years', '34 Years', '35 Years', '36 Years', '37 Years', '38 Years', '39 Years', '40 Years', '41 Years', '42 Years', '43 Years', '44 Years', '45 Years', '46 Years', '47 Years', '48 Years', '49 Years', '50 Years', '51 Years', '52 Years', '53 Years', '54 Years', '55 Years', '56 Years', '57 Years', '58 Years', '59 Years', '60 Years', '61 Years', '62 Years', '63 Years', '64 Years', '65 Years', '66 Years', '67 Years', '68 Years', '69 Years', '70 Years', '71 Years', '72 Years', '73 Years', '74 Years', '75 Years', '76 Years', '77 Years', '78 Years', '79 Years', '80 Years', '81 Years', '82 Years', '83 Years', '84 Years', '85 Years', '86 Years', '87 Years', '88 Years', '89 Years', '90 Years', '91 Years', '92 Years', '93 Years', '94 Years', '95 Years', '96 Years', '97  Years', '98  Years', '99  Years', '100 to 104  Years', '105 to 109  Years', '110  Years and Over']\n",
      "DataFrame 'DF_total_female_baa' column names:\n",
      "['Under 1 Year', '1 Year', '2 Years', '3 Years', '4 Years', '5 Years', '6 Years', '7 Years', '8 Years', '9 Years', '10 Years', '11 Years', '12 Years', '13 Years', '14 Years', '15 Years', '16 Years', '17 Years', '18 Years', '19 Years', '20 Years', '21 Years', '22 Years', '23 Years', '24 Years', '25 Years', '26 Years', '27 Years', '28 Years', '29 Years', '30 Years', '31 Years', '32 Years', '33 Years', '34 Years', '35 Years', '36 Years', '37 Years', '38 Years', '39 Years', '40 Years', '41 Years', '42 Years', '43 Years', '44 Years', '45 Years', '46 Years', '47 Years', '48 Years', '49 Years', '50 Years', '51 Years', '52 Years', '53 Years', '54 Years', '55 Years', '56 Years', '57 Years', '58 Years', '59 Years', '60 Years', '61 Years', '62 Years', '63 Years', '64 Years', '65 Years', '66 Years', '67 Years', '68 Years', '69 Years', '70 Years', '71 Years', '72 Years', '73 Years', '74 Years', '75 Years', '76 Years', '77 Years', '78 Years', '79 Years', '80 Years', '81 Years', '82 Years', '83 Years', '84 Years', '85 Years', '86 Years', '87 Years', '88 Years', '89 Years', '90 Years', '91 Years', '92 Years', '93 Years', '94 Years', '95 Years', '96 Years', '97  Years', '98  Years', '99  Years', '100 to 104  Years', '105 to 109  Years', '110  Years and Over']\n",
      "DataFrame 'DF_total_male_aian' column names:\n",
      "['Under 1 Year', '1 Year', '2 Years', '3 Years', '4 Years', '5 Years', '6 Years', '7 Years', '8 Years', '9 Years', '10 Years', '11 Years', '12 Years', '13 Years', '14 Years', '15 Years', '16 Years', '17 Years', '18 Years', '19 Years', '20 Years', '21 Years', '22 Years', '23 Years', '24 Years', '25 Years', '26 Years', '27 Years', '28 Years', '29 Years', '30 Years', '31 Years', '32 Years', '33 Years', '34 Years', '35 Years', '36 Years', '37 Years', '38 Years', '39 Years', '40 Years', '41 Years', '42 Years', '43 Years', '44 Years', '45 Years', '46 Years', '47 Years', '48 Years', '49 Years', '50 Years', '51 Years', '52 Years', '53 Years', '54 Years', '55 Years', '56 Years', '57 Years', '58 Years', '59 Years', '60 Years', '61 Years', '62 Years', '63 Years', '64 Years', '65 Years', '66 Years', '67 Years', '68 Years', '69 Years', '70 Years', '71 Years', '72 Years', '73 Years', '74 Years', '75 Years', '76 Years', '77 Years', '78 Years', '79 Years', '80 Years', '81 Years', '82 Years', '83 Years', '84 Years', '85 Years', '86 Years', '87 Years', '88 Years', '89 Years', '90 Years', '91 Years', '92 Years', '93 Years', '94 Years', '95 Years', '96 Years', '97  Years', '98  Years', '99  Years', '100 to 104  Years', '105 to 109  Years', '110  Years and Over']\n",
      "DataFrame 'DF_total_female_aian' column names:\n",
      "['Under 1 Year', '1 Year', '2 Years', '3 Years', '4 Years', '5 Years', '6 Years', '7 Years', '8 Years', '9 Years', '10 Years', '11 Years', '12 Years', '13 Years', '14 Years', '15 Years', '16 Years', '17 Years', '18 Years', '19 Years', '20 Years', '21 Years', '22 Years', '23 Years', '24 Years', '25 Years', '26 Years', '27 Years', '28 Years', '29 Years', '30 Years', '31 Years', '32 Years', '33 Years', '34 Years', '35 Years', '36 Years', '37 Years', '38 Years', '39 Years', '40 Years', '41 Years', '42 Years', '43 Years', '44 Years', '45 Years', '46 Years', '47 Years', '48 Years', '49 Years', '50 Years', '51 Years', '52 Years', '53 Years', '54 Years', '55 Years', '56 Years', '57 Years', '58 Years', '59 Years', '60 Years', '61 Years', '62 Years', '63 Years', '64 Years', '65 Years', '66 Years', '67 Years', '68 Years', '69 Years', '70 Years', '71 Years', '72 Years', '73 Years', '74 Years', '75 Years', '76 Years', '77 Years', '78 Years', '79 Years', '80 Years', '81 Years', '82 Years', '83 Years', '84 Years', '85 Years', '86 Years', '87 Years', '88 Years', '89 Years', '90 Years', '91 Years', '92 Years', '93 Years', '94 Years', '95 Years', '96 Years', '97  Years', '98  Years', '99  Years', '100 to 104  Years', '105 to 109  Years', '110  Years and Over']\n",
      "DataFrame 'DF_total_male_aa' column names:\n",
      "['Under 1 Year', '1 Year', '2 Years', '3 Years', '4 Years', '5 Years', '6 Years', '7 Years', '8 Years', '9 Years', '10 Years', '11 Years', '12 Years', '13 Years', '14 Years', '15 Years', '16 Years', '17 Years', '18 Years', '19 Years', '20 Years', '21 Years', '22 Years', '23 Years', '24 Years', '25 Years', '26 Years', '27 Years', '28 Years', '29 Years', '30 Years', '31 Years', '32 Years', '33 Years', '34 Years', '35 Years', '36 Years', '37 Years', '38 Years', '39 Years', '40 Years', '41 Years', '42 Years', '43 Years', '44 Years', '45 Years', '46 Years', '47 Years', '48 Years', '49 Years', '50 Years', '51 Years', '52 Years', '53 Years', '54 Years', '55 Years', '56 Years', '57 Years', '58 Years', '59 Years', '60 Years', '61 Years', '62 Years', '63 Years', '64 Years', '65 Years', '66 Years', '67 Years', '68 Years', '69 Years', '70 Years', '71 Years', '72 Years', '73 Years', '74 Years', '75 Years', '76 Years', '77 Years', '78 Years', '79 Years', '80 Years', '81 Years', '82 Years', '83 Years', '84 Years', '85 Years', '86 Years', '87 Years', '88 Years', '89 Years', '90 Years', '91 Years', '92 Years', '93 Years', '94 Years', '95 Years', '96 Years', '97  Years', '98  Years', '99  Years', '100 to 104  Years', '105 to 109  Years', '110  Years and Over']\n",
      "DataFrame 'DF_total_female_aa' column names:\n",
      "['Under 1 Year', '1 Year', '2 Years', '3 Years', '4 Years', '5 Years', '6 Years', '7 Years', '8 Years', '9 Years', '10 Years', '11 Years', '12 Years', '13 Years', '14 Years', '15 Years', '16 Years', '17 Years', '18 Years', '19 Years', '20 Years', '21 Years', '22 Years', '23 Years', '24 Years', '25 Years', '26 Years', '27 Years', '28 Years', '29 Years', '30 Years', '31 Years', '32 Years', '33 Years', '34 Years', '35 Years', '36 Years', '37 Years', '38 Years', '39 Years', '40 Years', '41 Years', '42 Years', '43 Years', '44 Years', '45 Years', '46 Years', '47 Years', '48 Years', '49 Years', '50 Years', '51 Years', '52 Years', '53 Years', '54 Years', '55 Years', '56 Years', '57 Years', '58 Years', '59 Years', '60 Years', '61 Years', '62 Years', '63 Years', '64 Years', '65 Years', '66 Years', '67 Years', '68 Years', '69 Years', '70 Years', '71 Years', '72 Years', '73 Years', '74 Years', '75 Years', '76 Years', '77 Years', '78 Years', '79 Years', '80 Years', '81 Years', '82 Years', '83 Years', '84 Years', '85 Years', '86 Years', '87 Years', '88 Years', '89 Years', '90 Years', '91 Years', '92 Years', '93 Years', '94 Years', '95 Years', '96 Years', '97  Years', '98  Years', '99  Years', '100 to 104  Years', '105 to 109  Years', '110  Years and Over']\n",
      "DataFrame 'DF_total_male_nhop' column names:\n",
      "['Under 1 Year', '1 Year', '2 Years', '3 Years', '4 Years', '5 Years', '6 Years', '7 Years', '8 Years', '9 Years', '10 Years', '11 Years', '12 Years', '13 Years', '14 Years', '15 Years', '16 Years', '17 Years', '18 Years', '19 Years', '20 Years', '21 Years', '22 Years', '23 Years', '24 Years', '25 Years', '26 Years', '27 Years', '28 Years', '29 Years', '30 Years', '31 Years', '32 Years', '33 Years', '34 Years', '35 Years', '36 Years', '37 Years', '38 Years', '39 Years', '40 Years', '41 Years', '42 Years', '43 Years', '44 Years', '45 Years', '46 Years', '47 Years', '48 Years', '49 Years', '50 Years', '51 Years', '52 Years', '53 Years', '54 Years', '55 Years', '56 Years', '57 Years', '58 Years', '59 Years', '60 Years', '61 Years', '62 Years', '63 Years', '64 Years', '65 Years', '66 Years', '67 Years', '68 Years', '69 Years', '70 Years', '71 Years', '72 Years', '73 Years', '74 Years', '75 Years', '76 Years', '77 Years', '78 Years', '79 Years', '80 Years', '81 Years', '82 Years', '83 Years', '84 Years', '85 Years', '86 Years', '87 Years', '88 Years', '89 Years', '90 Years', '91 Years', '92 Years', '93 Years', '94 Years', '95 Years', '96 Years', '97  Years', '98  Years', '99  Years', '100 to 104  Years', '105 to 109  Years', '110  Years and Over']\n",
      "DataFrame 'DF_total_female_nhop' column names:\n",
      "['Under 1 Year', '1 Year', '2 Years', '3 Years', '4 Years', '5 Years', '6 Years', '7 Years', '8 Years', '9 Years', '10 Years', '11 Years', '12 Years', '13 Years', '14 Years', '15 Years', '16 Years', '17 Years', '18 Years', '19 Years', '20 Years', '21 Years', '22 Years', '23 Years', '24 Years', '25 Years', '26 Years', '27 Years', '28 Years', '29 Years', '30 Years', '31 Years', '32 Years', '33 Years', '34 Years', '35 Years', '36 Years', '37 Years', '38 Years', '39 Years', '40 Years', '41 Years', '42 Years', '43 Years', '44 Years', '45 Years', '46 Years', '47 Years', '48 Years', '49 Years', '50 Years', '51 Years', '52 Years', '53 Years', '54 Years', '55 Years', '56 Years', '57 Years', '58 Years', '59 Years', '60 Years', '61 Years', '62 Years', '63 Years', '64 Years', '65 Years', '66 Years', '67 Years', '68 Years', '69 Years', '70 Years', '71 Years', '72 Years', '73 Years', '74 Years', '75 Years', '76 Years', '77 Years', '78 Years', '79 Years', '80 Years', '81 Years', '82 Years', '83 Years', '84 Years', '85 Years', '86 Years', '87 Years', '88 Years', '89 Years', '90 Years', '91 Years', '92 Years', '93 Years', '94 Years', '95 Years', '96 Years', '97  Years', '98  Years', '99  Years', '100 to 104  Years', '105 to 109  Years', '110  Years and Over']\n",
      "DataFrame 'DF_total_male_sor' column names:\n",
      "['Under 1 Year', '1 Year', '2 Years', '3 Years', '4 Years', '5 Years', '6 Years', '7 Years', '8 Years', '9 Years', '10 Years', '11 Years', '12 Years', '13 Years', '14 Years', '15 Years', '16 Years', '17 Years', '18 Years', '19 Years', '20 Years', '21 Years', '22 Years', '23 Years', '24 Years', '25 Years', '26 Years', '27 Years', '28 Years', '29 Years', '30 Years', '31 Years', '32 Years', '33 Years', '34 Years', '35 Years', '36 Years', '37 Years', '38 Years', '39 Years', '40 Years', '41 Years', '42 Years', '43 Years', '44 Years', '45 Years', '46 Years', '47 Years', '48 Years', '49 Years', '50 Years', '51 Years', '52 Years', '53 Years', '54 Years', '55 Years', '56 Years', '57 Years', '58 Years', '59 Years', '60 Years', '61 Years', '62 Years', '63 Years', '64 Years', '65 Years', '66 Years', '67 Years', '68 Years', '69 Years', '70 Years', '71 Years', '72 Years', '73 Years', '74 Years', '75 Years', '76 Years', '77 Years', '78 Years', '79 Years', '80 Years', '81 Years', '82 Years', '83 Years', '84 Years', '85 Years', '86 Years', '87 Years', '88 Years', '89 Years', '90 Years', '91 Years', '92 Years', '93 Years', '94 Years', '95 Years', '96 Years', '97  Years', '98  Years', '99  Years', '100 to 104  Years', '105 to 109  Years', '110  Years and Over']\n",
      "DataFrame 'DF_total_female_sor' column names:\n",
      "['Under 1 Year', '1 Year', '2 Years', '3 Years', '4 Years', '5 Years', '6 Years', '7 Years', '8 Years', '9 Years', '10 Years', '11 Years', '12 Years', '13 Years', '14 Years', '15 Years', '16 Years', '17 Years', '18 Years', '19 Years', '20 Years', '21 Years', '22 Years', '23 Years', '24 Years', '25 Years', '26 Years', '27 Years', '28 Years', '29 Years', '30 Years', '31 Years', '32 Years', '33 Years', '34 Years', '35 Years', '36 Years', '37 Years', '38 Years', '39 Years', '40 Years', '41 Years', '42 Years', '43 Years', '44 Years', '45 Years', '46 Years', '47 Years', '48 Years', '49 Years', '50 Years', '51 Years', '52 Years', '53 Years', '54 Years', '55 Years', '56 Years', '57 Years', '58 Years', '59 Years', '60 Years', '61 Years', '62 Years', '63 Years', '64 Years', '65 Years', '66 Years', '67 Years', '68 Years', '69 Years', '70 Years', '71 Years', '72 Years', '73 Years', '74 Years', '75 Years', '76 Years', '77 Years', '78 Years', '79 Years', '80 Years', '81 Years', '82 Years', '83 Years', '84 Years', '85 Years', '86 Years', '87 Years', '88 Years', '89 Years', '90 Years', '91 Years', '92 Years', '93 Years', '94 Years', '95 Years', '96 Years', '97  Years', '98  Years', '99  Years', '100 to 104  Years', '105 to 109  Years', '110  Years and Over']\n",
      "DataFrame 'DF_total_male_tom' column names:\n",
      "['Under 1 Year', '1 Year', '2 Years', '3 Years', '4 Years', '5 Years', '6 Years', '7 Years', '8 Years', '9 Years', '10 Years', '11 Years', '12 Years', '13 Years', '14 Years', '15 Years', '16 Years', '17 Years', '18 Years', '19 Years', '20 Years', '21 Years', '22 Years', '23 Years', '24 Years', '25 Years', '26 Years', '27 Years', '28 Years', '29 Years', '30 Years', '31 Years', '32 Years', '33 Years', '34 Years', '35 Years', '36 Years', '37 Years', '38 Years', '39 Years', '40 Years', '41 Years', '42 Years', '43 Years', '44 Years', '45 Years', '46 Years', '47 Years', '48 Years', '49 Years', '50 Years', '51 Years', '52 Years', '53 Years', '54 Years', '55 Years', '56 Years', '57 Years', '58 Years', '59 Years', '60 Years', '61 Years', '62 Years', '63 Years', '64 Years', '65 Years', '66 Years', '67 Years', '68 Years', '69 Years', '70 Years', '71 Years', '72 Years', '73 Years', '74 Years', '75 Years', '76 Years', '77 Years', '78 Years', '79 Years', '80 Years', '81 Years', '82 Years', '83 Years', '84 Years', '85 Years', '86 Years', '87 Years', '88 Years', '89 Years', '90 Years', '91 Years', '92 Years', '93 Years', '94 Years', '95 Years', '96 Years', '97  Years', '98  Years', '99  Years', '100 to 104  Years', '105 to 109  Years', '110  Years and Over']\n",
      "DataFrame 'DF_total_female_tom' column names:\n",
      "['Under 1 Year', '1 Year', '2 Years', '3 Years', '4 Years', '5 Years', '6 Years', '7 Years', '8 Years', '9 Years', '10 Years', '11 Years', '12 Years', '13 Years', '14 Years', '15 Years', '16 Years', '17 Years', '18 Years', '19 Years', '20 Years', '21 Years', '22 Years', '23 Years', '24 Years', '25 Years', '26 Years', '27 Years', '28 Years', '29 Years', '30 Years', '31 Years', '32 Years', '33 Years', '34 Years', '35 Years', '36 Years', '37 Years', '38 Years', '39 Years', '40 Years', '41 Years', '42 Years', '43 Years', '44 Years', '45 Years', '46 Years', '47 Years', '48 Years', '49 Years', '50 Years', '51 Years', '52 Years', '53 Years', '54 Years', '55 Years', '56 Years', '57 Years', '58 Years', '59 Years', '60 Years', '61 Years', '62 Years', '63 Years', '64 Years', '65 Years', '66 Years', '67 Years', '68 Years', '69 Years', '70 Years', '71 Years', '72 Years', '73 Years', '74 Years', '75 Years', '76 Years', '77 Years', '78 Years', '79 Years', '80 Years', '81 Years', '82 Years', '83 Years', '84 Years', '85 Years', '86 Years', '87 Years', '88 Years', '89 Years', '90 Years', '91 Years', '92 Years', '93 Years', '94 Years', '95 Years', '96 Years', '97  Years', '98  Years', '99  Years', '100 to 104  Years', '105 to 109  Years', '110  Years and Over']\n",
      "DataFrame 'DF_total_male_hol' column names:\n",
      "['Under 1 Year', '1 Year', '2 Years', '3 Years', '4 Years', '5 Years', '6 Years', '7 Years', '8 Years', '9 Years', '10 Years', '11 Years', '12 Years', '13 Years', '14 Years', '15 Years', '16 Years', '17 Years', '18 Years', '19 Years', '20 Years', '21 Years', '22 Years', '23 Years', '24 Years', '25 Years', '26 Years', '27 Years', '28 Years', '29 Years', '30 Years', '31 Years', '32 Years', '33 Years', '34 Years', '35 Years', '36 Years', '37 Years', '38 Years', '39 Years', '40 Years', '41 Years', '42 Years', '43 Years', '44 Years', '45 Years', '46 Years', '47 Years', '48 Years', '49 Years', '50 Years', '51 Years', '52 Years', '53 Years', '54 Years', '55 Years', '56 Years', '57 Years', '58 Years', '59 Years', '60 Years', '61 Years', '62 Years', '63 Years', '64 Years', '65 Years', '66 Years', '67 Years', '68 Years', '69 Years', '70 Years', '71 Years', '72 Years', '73 Years', '74 Years', '75 Years', '76 Years', '77 Years', '78 Years', '79 Years', '80 Years', '81 Years', '82 Years', '83 Years', '84 Years', '85 Years', '86 Years', '87 Years', '88 Years', '89 Years', '90 Years', '91 Years', '92 Years', '93 Years', '94 Years', '95 Years', '96 Years', '97  Years', '98  Years', '99  Years', '100 to 104  Years', '105 to 109  Years', '110  Years and Over']\n",
      "DataFrame 'DF_total_female_hol' column names:\n",
      "['Under 1 Year', '1 Year', '2 Years', '3 Years', '4 Years', '5 Years', '6 Years', '7 Years', '8 Years', '9 Years', '10 Years', '11 Years', '12 Years', '13 Years', '14 Years', '15 Years', '16 Years', '17 Years', '18 Years', '19 Years', '20 Years', '21 Years', '22 Years', '23 Years', '24 Years', '25 Years', '26 Years', '27 Years', '28 Years', '29 Years', '30 Years', '31 Years', '32 Years', '33 Years', '34 Years', '35 Years', '36 Years', '37 Years', '38 Years', '39 Years', '40 Years', '41 Years', '42 Years', '43 Years', '44 Years', '45 Years', '46 Years', '47 Years', '48 Years', '49 Years', '50 Years', '51 Years', '52 Years', '53 Years', '54 Years', '55 Years', '56 Years', '57 Years', '58 Years', '59 Years', '60 Years', '61 Years', '62 Years', '63 Years', '64 Years', '65 Years', '66 Years', '67 Years', '68 Years', '69 Years', '70 Years', '71 Years', '72 Years', '73 Years', '74 Years', '75 Years', '76 Years', '77 Years', '78 Years', '79 Years', '80 Years', '81 Years', '82 Years', '83 Years', '84 Years', '85 Years', '86 Years', '87 Years', '88 Years', '89 Years', '90 Years', '91 Years', '92 Years', '93 Years', '94 Years', '95 Years', '96 Years', '97  Years', '98  Years', '99  Years', '100 to 104  Years', '105 to 109  Years', '110  Years and Over']\n",
      "\n",
      "Dictionary 'dropped_columns':\n",
      "DataFrame 'DF_male_all' column names:\n",
      "['Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "DataFrame 'DF_female_all' column names:\n",
      "['Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "DataFrame 'DF_total_male_whi' column names:\n",
      "['Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "DataFrame 'DF_total_female_whi' column names:\n",
      "['Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "DataFrame 'DF_total_male_baa' column names:\n",
      "['Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "DataFrame 'DF_total_female_baa' column names:\n",
      "['Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "DataFrame 'DF_total_male_aian' column names:\n",
      "['Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "DataFrame 'DF_total_female_aian' column names:\n",
      "['Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "DataFrame 'DF_total_male_aa' column names:\n",
      "['Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "DataFrame 'DF_total_female_aa' column names:\n",
      "['Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "DataFrame 'DF_total_male_nhop' column names:\n",
      "['Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "DataFrame 'DF_total_female_nhop' column names:\n",
      "['Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "DataFrame 'DF_total_male_sor' column names:\n",
      "['Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "DataFrame 'DF_total_female_sor' column names:\n",
      "['Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "DataFrame 'DF_total_male_tom' column names:\n",
      "['Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "DataFrame 'DF_total_female_tom' column names:\n",
      "['Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "DataFrame 'DF_total_male_hol' column names:\n",
      "['Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "DataFrame 'DF_total_female_hol' column names:\n",
      "['Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n"
     ]
    }
   ],
   "source": [
    "print(\"Dictionary 'dfs_perc':\")\n",
    "for df_name, df in dfs_perc.items():\n",
    "    print(f\"DataFrame '{df_name}' column names:\")\n",
    "    print(list(df.columns))\n",
    "\n",
    "print(\"\\nDictionary 'dropped_columns':\")\n",
    "for df_name, df in dropped_columns.items():\n",
    "    print(f\"DataFrame '{df_name}' column names:\")\n",
    "    print(list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables for columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_int = ['Under 1 Year','1 Year','2 Years','3 Years','4 Years','5 Years',\n",
    "            '6 Years','7 Years','8 Years','9 Years','10 Years','11 Years',\n",
    "            '12 Years','13 Years','14 Years','15 Years','16 Years','17 Years',\n",
    "            '18 Years','19 Years','20 Years','21 Years','22 Years','23 Years',\n",
    "            '24 Years','25 Years','26 Years','27 Years','28 Years','29 Years',\n",
    "            '30 Years','31 Years','32 Years','33 Years','34 Years','35 Years',\n",
    "            '36 Years','37 Years','38 Years','39 Years','40 Years','41 Years',\n",
    "            '42 Years','43 Years','44 Years','45 Years','46 Years','47 Years',\n",
    "            '48 Years','49 Years','50 Years','51 Years','52 Years','53 Years',\n",
    "            '54 Years','55 Years','56 Years','57 Years','58 Years','59 Years',\n",
    "            '60 Years','61 Years','62 Years','63 Years','64 Years','65 Years',\n",
    "            '66 Years','67 Years','68 Years','69 Years','70 Years','71 Years',\n",
    "            '72 Years','73 Years','74 Years','75 Years','76 Years','77 Years',\n",
    "            '78 Years','79 Years','80 Years','81 Years','82 Years','83 Years',\n",
    "            '84 Years','85 Years','86 Years','87 Years','88 Years','89 Years',\n",
    "            '90 Years','91 Years','92 Years','93 Years','94 Years','95 Years',\n",
    "            '96 Years','97  Years','98  Years','99  Years','100 to 104  Years',\n",
    "            '105 to 109  Years','110  Years and Over'\n",
    "            ]\n",
    "cols_mod = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,\n",
    "            25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,\n",
    "            47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,\n",
    "            69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,\n",
    "            91,92,93,94,95,96,97,98,99,102,107,110\n",
    "            ] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column change process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the dataframes in 'dfs_perc'\n",
    "for df_name, df in dfs_perc.items():\n",
    "    # Change the column names to the list of integers\n",
    "    df.columns = cols_mod\n",
    "    \n",
    "    # Convert the column type to integer\n",
    "    df[cols_mod] = df[cols_mod].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'DF_male_all' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110]\n",
      "DataFrame 'DF_male_all' column types:\n",
      "0      int32\n",
      "1      int32\n",
      "2      int32\n",
      "3      int32\n",
      "4      int32\n",
      "       ...  \n",
      "98     int32\n",
      "99     int32\n",
      "102    int32\n",
      "107    int32\n",
      "110    int32\n",
      "Length: 103, dtype: object\n",
      "\n",
      "DataFrame 'DF_female_all' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110]\n",
      "DataFrame 'DF_female_all' column types:\n",
      "0      int32\n",
      "1      int32\n",
      "2      int32\n",
      "3      int32\n",
      "4      int32\n",
      "       ...  \n",
      "98     int32\n",
      "99     int32\n",
      "102    int32\n",
      "107    int32\n",
      "110    int32\n",
      "Length: 103, dtype: object\n",
      "\n",
      "DataFrame 'DF_total_male_whi' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110]\n",
      "DataFrame 'DF_total_male_whi' column types:\n",
      "0      int32\n",
      "1      int32\n",
      "2      int32\n",
      "3      int32\n",
      "4      int32\n",
      "       ...  \n",
      "98     int32\n",
      "99     int32\n",
      "102    int32\n",
      "107    int32\n",
      "110    int32\n",
      "Length: 103, dtype: object\n",
      "\n",
      "DataFrame 'DF_total_female_whi' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110]\n",
      "DataFrame 'DF_total_female_whi' column types:\n",
      "0      int32\n",
      "1      int32\n",
      "2      int32\n",
      "3      int32\n",
      "4      int32\n",
      "       ...  \n",
      "98     int32\n",
      "99     int32\n",
      "102    int32\n",
      "107    int32\n",
      "110    int32\n",
      "Length: 103, dtype: object\n",
      "\n",
      "DataFrame 'DF_total_male_baa' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110]\n",
      "DataFrame 'DF_total_male_baa' column types:\n",
      "0      int32\n",
      "1      int32\n",
      "2      int32\n",
      "3      int32\n",
      "4      int32\n",
      "       ...  \n",
      "98     int32\n",
      "99     int32\n",
      "102    int32\n",
      "107    int32\n",
      "110    int32\n",
      "Length: 103, dtype: object\n",
      "\n",
      "DataFrame 'DF_total_female_baa' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110]\n",
      "DataFrame 'DF_total_female_baa' column types:\n",
      "0      int32\n",
      "1      int32\n",
      "2      int32\n",
      "3      int32\n",
      "4      int32\n",
      "       ...  \n",
      "98     int32\n",
      "99     int32\n",
      "102    int32\n",
      "107    int32\n",
      "110    int32\n",
      "Length: 103, dtype: object\n",
      "\n",
      "DataFrame 'DF_total_male_aian' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110]\n",
      "DataFrame 'DF_total_male_aian' column types:\n",
      "0      int32\n",
      "1      int32\n",
      "2      int32\n",
      "3      int32\n",
      "4      int32\n",
      "       ...  \n",
      "98     int32\n",
      "99     int32\n",
      "102    int32\n",
      "107    int32\n",
      "110    int32\n",
      "Length: 103, dtype: object\n",
      "\n",
      "DataFrame 'DF_total_female_aian' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110]\n",
      "DataFrame 'DF_total_female_aian' column types:\n",
      "0      int32\n",
      "1      int32\n",
      "2      int32\n",
      "3      int32\n",
      "4      int32\n",
      "       ...  \n",
      "98     int32\n",
      "99     int32\n",
      "102    int32\n",
      "107    int32\n",
      "110    int32\n",
      "Length: 103, dtype: object\n",
      "\n",
      "DataFrame 'DF_total_male_aa' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110]\n",
      "DataFrame 'DF_total_male_aa' column types:\n",
      "0      int32\n",
      "1      int32\n",
      "2      int32\n",
      "3      int32\n",
      "4      int32\n",
      "       ...  \n",
      "98     int32\n",
      "99     int32\n",
      "102    int32\n",
      "107    int32\n",
      "110    int32\n",
      "Length: 103, dtype: object\n",
      "\n",
      "DataFrame 'DF_total_female_aa' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110]\n",
      "DataFrame 'DF_total_female_aa' column types:\n",
      "0      int32\n",
      "1      int32\n",
      "2      int32\n",
      "3      int32\n",
      "4      int32\n",
      "       ...  \n",
      "98     int32\n",
      "99     int32\n",
      "102    int32\n",
      "107    int32\n",
      "110    int32\n",
      "Length: 103, dtype: object\n",
      "\n",
      "DataFrame 'DF_total_male_nhop' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110]\n",
      "DataFrame 'DF_total_male_nhop' column types:\n",
      "0      int32\n",
      "1      int32\n",
      "2      int32\n",
      "3      int32\n",
      "4      int32\n",
      "       ...  \n",
      "98     int32\n",
      "99     int32\n",
      "102    int32\n",
      "107    int32\n",
      "110    int32\n",
      "Length: 103, dtype: object\n",
      "\n",
      "DataFrame 'DF_total_female_nhop' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110]\n",
      "DataFrame 'DF_total_female_nhop' column types:\n",
      "0      int32\n",
      "1      int32\n",
      "2      int32\n",
      "3      int32\n",
      "4      int32\n",
      "       ...  \n",
      "98     int32\n",
      "99     int32\n",
      "102    int32\n",
      "107    int32\n",
      "110    int32\n",
      "Length: 103, dtype: object\n",
      "\n",
      "DataFrame 'DF_total_male_sor' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110]\n",
      "DataFrame 'DF_total_male_sor' column types:\n",
      "0      int32\n",
      "1      int32\n",
      "2      int32\n",
      "3      int32\n",
      "4      int32\n",
      "       ...  \n",
      "98     int32\n",
      "99     int32\n",
      "102    int32\n",
      "107    int32\n",
      "110    int32\n",
      "Length: 103, dtype: object\n",
      "\n",
      "DataFrame 'DF_total_female_sor' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110]\n",
      "DataFrame 'DF_total_female_sor' column types:\n",
      "0      int32\n",
      "1      int32\n",
      "2      int32\n",
      "3      int32\n",
      "4      int32\n",
      "       ...  \n",
      "98     int32\n",
      "99     int32\n",
      "102    int32\n",
      "107    int32\n",
      "110    int32\n",
      "Length: 103, dtype: object\n",
      "\n",
      "DataFrame 'DF_total_male_tom' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110]\n",
      "DataFrame 'DF_total_male_tom' column types:\n",
      "0      int32\n",
      "1      int32\n",
      "2      int32\n",
      "3      int32\n",
      "4      int32\n",
      "       ...  \n",
      "98     int32\n",
      "99     int32\n",
      "102    int32\n",
      "107    int32\n",
      "110    int32\n",
      "Length: 103, dtype: object\n",
      "\n",
      "DataFrame 'DF_total_female_tom' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110]\n",
      "DataFrame 'DF_total_female_tom' column types:\n",
      "0      int32\n",
      "1      int32\n",
      "2      int32\n",
      "3      int32\n",
      "4      int32\n",
      "       ...  \n",
      "98     int32\n",
      "99     int32\n",
      "102    int32\n",
      "107    int32\n",
      "110    int32\n",
      "Length: 103, dtype: object\n",
      "\n",
      "DataFrame 'DF_total_male_hol' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110]\n",
      "DataFrame 'DF_total_male_hol' column types:\n",
      "0      int32\n",
      "1      int32\n",
      "2      int32\n",
      "3      int32\n",
      "4      int32\n",
      "       ...  \n",
      "98     int32\n",
      "99     int32\n",
      "102    int32\n",
      "107    int32\n",
      "110    int32\n",
      "Length: 103, dtype: object\n",
      "\n",
      "DataFrame 'DF_total_female_hol' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110]\n",
      "DataFrame 'DF_total_female_hol' column types:\n",
      "0      int32\n",
      "1      int32\n",
      "2      int32\n",
      "3      int32\n",
      "4      int32\n",
      "       ...  \n",
      "98     int32\n",
      "99     int32\n",
      "102    int32\n",
      "107    int32\n",
      "110    int32\n",
      "Length: 103, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the dataframes in 'dfs_perc'\n",
    "for df_name, df in dfs_perc.items():\n",
    "    print(f\"DataFrame '{df_name}' column names:\")\n",
    "    print(list(df.columns))\n",
    "    print(f\"DataFrame '{df_name}' column types:\")\n",
    "    print(df.dtypes)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding weighted Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Average_Age'] = results\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Average_Age'] = results\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Average_Age'] = results\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Average_Age'] = results\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:24: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  weighted_average = weighted_sum / weights_sum\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Average_Age'] = results\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:24: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  weighted_average = weighted_sum / weights_sum\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Average_Age'] = results\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:24: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  weighted_average = weighted_sum / weights_sum\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Average_Age'] = results\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:24: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  weighted_average = weighted_sum / weights_sum\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Average_Age'] = results\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:24: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  weighted_average = weighted_sum / weights_sum\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Average_Age'] = results\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:24: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  weighted_average = weighted_sum / weights_sum\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Average_Age'] = results\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:24: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  weighted_average = weighted_sum / weights_sum\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Average_Age'] = results\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:24: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  weighted_average = weighted_sum / weights_sum\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Average_Age'] = results\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:24: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  weighted_average = weighted_sum / weights_sum\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Average_Age'] = results\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:24: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  weighted_average = weighted_sum / weights_sum\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Average_Age'] = results\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Average_Age'] = results\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Average_Age'] = results\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:24: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  weighted_average = weighted_sum / weights_sum\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Average_Age'] = results\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:24: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  weighted_average = weighted_sum / weights_sum\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\3227147353.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Average_Age'] = results\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each key-value pair in dfs_perc\n",
    "for df_name, df in dfs_perc.items():\n",
    "    # Get the column names as an array of integers\n",
    "    values = np.array(df.columns, dtype=int)\n",
    "\n",
    "    # Initialize an empty list to store the results\n",
    "    results = []\n",
    "\n",
    "    # Iterate over each row in the dataframe\n",
    "    for _, row in df.iterrows():\n",
    "        # Get the row entries as an array of integers\n",
    "        weights = np.array(row.values, dtype=int)\n",
    "\n",
    "        # Perform element-wise multiplication of values and weights\n",
    "        weighted_values = values * weights\n",
    "\n",
    "        # Sum the products of the multiplications\n",
    "        weighted_sum = np.sum(weighted_values)\n",
    "\n",
    "        # Sum all items in the weights array\n",
    "        weights_sum = np.sum(weights)\n",
    "\n",
    "        # Calculate the weighted average\n",
    "        weighted_average = weighted_sum / weights_sum\n",
    "\n",
    "        # Append the weighted average to the results list\n",
    "        results.append(weighted_average)\n",
    "\n",
    "    # Add the 'Average_Age' column to the dataframe\n",
    "    df['Average_Age'] = results\n",
    "\n",
    "    # Reset the index of the dataframe\n",
    "    df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'DF_male_all' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age']\n",
      "\n",
      "DataFrame 'DF_female_all' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age']\n",
      "\n",
      "DataFrame 'DF_total_male_whi' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age']\n",
      "\n",
      "DataFrame 'DF_total_female_whi' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age']\n",
      "\n",
      "DataFrame 'DF_total_male_baa' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age']\n",
      "\n",
      "DataFrame 'DF_total_female_baa' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age']\n",
      "\n",
      "DataFrame 'DF_total_male_aian' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age']\n",
      "\n",
      "DataFrame 'DF_total_female_aian' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age']\n",
      "\n",
      "DataFrame 'DF_total_male_aa' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age']\n",
      "\n",
      "DataFrame 'DF_total_female_aa' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age']\n",
      "\n",
      "DataFrame 'DF_total_male_nhop' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age']\n",
      "\n",
      "DataFrame 'DF_total_female_nhop' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age']\n",
      "\n",
      "DataFrame 'DF_total_male_sor' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age']\n",
      "\n",
      "DataFrame 'DF_total_female_sor' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age']\n",
      "\n",
      "DataFrame 'DF_total_male_tom' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age']\n",
      "\n",
      "DataFrame 'DF_total_female_tom' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age']\n",
      "\n",
      "DataFrame 'DF_total_male_hol' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age']\n",
      "\n",
      "DataFrame 'DF_total_female_hol' column names:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the dictionaries in 'dropped_string_columns'\n",
    "for df_name, df_dict in dfs_perc.items():\n",
    "    print(f\"DataFrame '{df_name}' column names:\")\n",
    "    print(list(df_dict.keys()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verifying values in column of specific dataframe in 'dfs_perc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'DF_male_all':\n",
      "        0    1    2    3    4    5    6    7    8    9  ...  94  95  96  97  \\\n",
      "0     437  450  511  484  513  525  576  559  549  564  ...   6   8   3   3   \n",
      "1      70   70   84   91   80   90  116   67   97   81  ...   0   2   0   0   \n",
      "2      72   80   83   60   82   78   69   84   67   90  ...   3   1   4   3   \n",
      "3     157  203  182  171  192  161  202  186  158  184  ...   4   7   0   4   \n",
      "4      64   51   65   60   62   79   85   71   76   71  ...   2   0   2   0   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ..  ..  ..  ..   \n",
      "3216   98   86  120  100  109  120  115   96  114   96  ...   3   2   4   0   \n",
      "3217  183  124  170  184  175  185  185  160  188  197  ...   5   5   2   1   \n",
      "3218  190  218  223  195  287  247  211  223  237  185  ...  26   6   3   6   \n",
      "3219   20   10    4   14    9   10   16   17   18   11  ...   0   0   0   0   \n",
      "3220  593  582  669  639  691  704  658  650  687  618  ...  13   5   3   9   \n",
      "\n",
      "      98  99  102  107  110  Average_Age  \n",
      "0      1   0    0    0    0    38.518476  \n",
      "1      0   0    0    0    0    39.192103  \n",
      "2      1   0    1    2    0    40.734192  \n",
      "3      0   0    0    0    0    38.858371  \n",
      "4      0   0    1    1    0    40.306536  \n",
      "...   ..  ..  ...  ...  ...          ...  \n",
      "3216   3   1    1    0    1    39.908089  \n",
      "3217   1   0    1    0    0    39.505269  \n",
      "3218   4   2    5    0    0    37.824757  \n",
      "3219   0   0    1    0    0    37.842043  \n",
      "3220   1   0    4    0    0    37.557007  \n",
      "\n",
      "[3221 rows x 104 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check if 'DF_male_all' exists in 'dfs_perc' dictionary\n",
    "if 'DF_male_all' in dfs_perc:\n",
    "    print(\"DataFrame 'DF_male_all':\")\n",
    "    print(dfs_perc['DF_male_all'])\n",
    "else:\n",
    "    print(\"DataFrame 'DF_male_all' does not exist in 'dfs_perc' dictionary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the dataframes in 'dfs_perc'\n",
    "for df_name, df_perc in dfs_perc.items():\n",
    "    # Get the corresponding dataframe from 'dropped_columns'\n",
    "    df_dropped = dropped_columns[df_name]\n",
    "\n",
    "    # Concatenate the dataframes width-wise\n",
    "    joined_df = pd.concat([df_perc, df_dropped], axis=1)\n",
    "\n",
    "    # Update the 'dfs_perc' dataframe in place with the joined dataframe\n",
    "    dfs_perc[df_name] = joined_df\n",
    "\n",
    "    # Reset the index of the dataframe\n",
    "    dfs_perc[df_name].reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frames in 'dfs_perc':\n",
      "DF_male_all\n",
      "Shape: (3221, 212)\n",
      "Dtypes:\n",
      "0: int32\n",
      "1: int32\n",
      "2: int32\n",
      "3: int32\n",
      "4: int32\n",
      "5: int32\n",
      "6: int32\n",
      "7: int32\n",
      "8: int32\n",
      "9: int32\n",
      "10: int32\n",
      "11: int32\n",
      "12: int32\n",
      "13: int32\n",
      "14: int32\n",
      "15: int32\n",
      "16: int32\n",
      "17: int32\n",
      "18: int32\n",
      "19: int32\n",
      "20: int32\n",
      "21: int32\n",
      "22: int32\n",
      "23: int32\n",
      "24: int32\n",
      "25: int32\n",
      "26: int32\n",
      "27: int32\n",
      "28: int32\n",
      "29: int32\n",
      "30: int32\n",
      "31: int32\n",
      "32: int32\n",
      "33: int32\n",
      "34: int32\n",
      "35: int32\n",
      "36: int32\n",
      "37: int32\n",
      "38: int32\n",
      "39: int32\n",
      "40: int32\n",
      "41: int32\n",
      "42: int32\n",
      "43: int32\n",
      "44: int32\n",
      "45: int32\n",
      "46: int32\n",
      "47: int32\n",
      "48: int32\n",
      "49: int32\n",
      "50: int32\n",
      "51: int32\n",
      "52: int32\n",
      "53: int32\n",
      "54: int32\n",
      "55: int32\n",
      "56: int32\n",
      "57: int32\n",
      "58: int32\n",
      "59: int32\n",
      "60: int32\n",
      "61: int32\n",
      "62: int32\n",
      "63: int32\n",
      "64: int32\n",
      "65: int32\n",
      "66: int32\n",
      "67: int32\n",
      "68: int32\n",
      "69: int32\n",
      "70: int32\n",
      "71: int32\n",
      "72: int32\n",
      "73: int32\n",
      "74: int32\n",
      "75: int32\n",
      "76: int32\n",
      "77: int32\n",
      "78: int32\n",
      "79: int32\n",
      "80: int32\n",
      "81: int32\n",
      "82: int32\n",
      "83: int32\n",
      "84: int32\n",
      "85: int32\n",
      "86: int32\n",
      "87: int32\n",
      "88: int32\n",
      "89: int32\n",
      "90: int32\n",
      "91: int32\n",
      "92: int32\n",
      "93: int32\n",
      "94: int32\n",
      "95: int32\n",
      "96: int32\n",
      "97: int32\n",
      "98: int32\n",
      "99: int32\n",
      "102: int32\n",
      "107: int32\n",
      "110: int32\n",
      "Average_Age: float64\n",
      "Under 1 Year_perc: float64\n",
      "1 Year_perc: float64\n",
      "2 Years_perc: float64\n",
      "3 Years_perc: float64\n",
      "4 Years_perc: float64\n",
      "5 Years_perc: float64\n",
      "6 Years_perc: float64\n",
      "7 Years_perc: float64\n",
      "8 Years_perc: float64\n",
      "9 Years_perc: float64\n",
      "10 Years_perc: float64\n",
      "11 Years_perc: float64\n",
      "12 Years_perc: float64\n",
      "13 Years_perc: float64\n",
      "14 Years_perc: float64\n",
      "15 Years_perc: float64\n",
      "16 Years_perc: float64\n",
      "17 Years_perc: float64\n",
      "18 Years_perc: float64\n",
      "19 Years_perc: float64\n",
      "20 Years_perc: float64\n",
      "21 Years_perc: float64\n",
      "22 Years_perc: float64\n",
      "23 Years_perc: float64\n",
      "24 Years_perc: float64\n",
      "25 Years_perc: float64\n",
      "26 Years_perc: float64\n",
      "27 Years_perc: float64\n",
      "28 Years_perc: float64\n",
      "29 Years_perc: float64\n",
      "30 Years_perc: float64\n",
      "31 Years_perc: float64\n",
      "32 Years_perc: float64\n",
      "33 Years_perc: float64\n",
      "34 Years_perc: float64\n",
      "35 Years_perc: float64\n",
      "36 Years_perc: float64\n",
      "37 Years_perc: float64\n",
      "38 Years_perc: float64\n",
      "39 Years_perc: float64\n",
      "40 Years_perc: float64\n",
      "41 Years_perc: float64\n",
      "42 Years_perc: float64\n",
      "43 Years_perc: float64\n",
      "44 Years_perc: float64\n",
      "45 Years_perc: float64\n",
      "46 Years_perc: float64\n",
      "47 Years_perc: float64\n",
      "48 Years_perc: float64\n",
      "49 Years_perc: float64\n",
      "50 Years_perc: float64\n",
      "51 Years_perc: float64\n",
      "52 Years_perc: float64\n",
      "53 Years_perc: float64\n",
      "54 Years_perc: float64\n",
      "55 Years_perc: float64\n",
      "56 Years_perc: float64\n",
      "57 Years_perc: float64\n",
      "58 Years_perc: float64\n",
      "59 Years_perc: float64\n",
      "60 Years_perc: float64\n",
      "61 Years_perc: float64\n",
      "62 Years_perc: float64\n",
      "63 Years_perc: float64\n",
      "64 Years_perc: float64\n",
      "65 Years_perc: float64\n",
      "66 Years_perc: float64\n",
      "67 Years_perc: float64\n",
      "68 Years_perc: float64\n",
      "69 Years_perc: float64\n",
      "70 Years_perc: float64\n",
      "71 Years_perc: float64\n",
      "72 Years_perc: float64\n",
      "73 Years_perc: float64\n",
      "74 Years_perc: float64\n",
      "75 Years_perc: float64\n",
      "76 Years_perc: float64\n",
      "77 Years_perc: float64\n",
      "78 Years_perc: float64\n",
      "79 Years_perc: float64\n",
      "80 Years_perc: float64\n",
      "81 Years_perc: float64\n",
      "82 Years_perc: float64\n",
      "83 Years_perc: float64\n",
      "84 Years_perc: float64\n",
      "85 Years_perc: float64\n",
      "86 Years_perc: float64\n",
      "87 Years_perc: float64\n",
      "88 Years_perc: float64\n",
      "89 Years_perc: float64\n",
      "90 Years_perc: float64\n",
      "91 Years_perc: float64\n",
      "92 Years_perc: float64\n",
      "93 Years_perc: float64\n",
      "94 Years_perc: float64\n",
      "95 Years_perc: float64\n",
      "96 Years_perc: float64\n",
      "97  Years_perc: float64\n",
      "98  Years_perc: float64\n",
      "99  Years_perc: float64\n",
      "100 to 104  Years_perc: float64\n",
      "105 to 109  Years_perc: float64\n",
      "110  Years and Over_perc: float64\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_female_all\n",
      "Shape: (3221, 212)\n",
      "Dtypes:\n",
      "0: int32\n",
      "1: int32\n",
      "2: int32\n",
      "3: int32\n",
      "4: int32\n",
      "5: int32\n",
      "6: int32\n",
      "7: int32\n",
      "8: int32\n",
      "9: int32\n",
      "10: int32\n",
      "11: int32\n",
      "12: int32\n",
      "13: int32\n",
      "14: int32\n",
      "15: int32\n",
      "16: int32\n",
      "17: int32\n",
      "18: int32\n",
      "19: int32\n",
      "20: int32\n",
      "21: int32\n",
      "22: int32\n",
      "23: int32\n",
      "24: int32\n",
      "25: int32\n",
      "26: int32\n",
      "27: int32\n",
      "28: int32\n",
      "29: int32\n",
      "30: int32\n",
      "31: int32\n",
      "32: int32\n",
      "33: int32\n",
      "34: int32\n",
      "35: int32\n",
      "36: int32\n",
      "37: int32\n",
      "38: int32\n",
      "39: int32\n",
      "40: int32\n",
      "41: int32\n",
      "42: int32\n",
      "43: int32\n",
      "44: int32\n",
      "45: int32\n",
      "46: int32\n",
      "47: int32\n",
      "48: int32\n",
      "49: int32\n",
      "50: int32\n",
      "51: int32\n",
      "52: int32\n",
      "53: int32\n",
      "54: int32\n",
      "55: int32\n",
      "56: int32\n",
      "57: int32\n",
      "58: int32\n",
      "59: int32\n",
      "60: int32\n",
      "61: int32\n",
      "62: int32\n",
      "63: int32\n",
      "64: int32\n",
      "65: int32\n",
      "66: int32\n",
      "67: int32\n",
      "68: int32\n",
      "69: int32\n",
      "70: int32\n",
      "71: int32\n",
      "72: int32\n",
      "73: int32\n",
      "74: int32\n",
      "75: int32\n",
      "76: int32\n",
      "77: int32\n",
      "78: int32\n",
      "79: int32\n",
      "80: int32\n",
      "81: int32\n",
      "82: int32\n",
      "83: int32\n",
      "84: int32\n",
      "85: int32\n",
      "86: int32\n",
      "87: int32\n",
      "88: int32\n",
      "89: int32\n",
      "90: int32\n",
      "91: int32\n",
      "92: int32\n",
      "93: int32\n",
      "94: int32\n",
      "95: int32\n",
      "96: int32\n",
      "97: int32\n",
      "98: int32\n",
      "99: int32\n",
      "102: int32\n",
      "107: int32\n",
      "110: int32\n",
      "Average_Age: float64\n",
      "Under 1 Year_perc: float64\n",
      "1 Year_perc: float64\n",
      "2 Years_perc: float64\n",
      "3 Years_perc: float64\n",
      "4 Years_perc: float64\n",
      "5 Years_perc: float64\n",
      "6 Years_perc: float64\n",
      "7 Years_perc: float64\n",
      "8 Years_perc: float64\n",
      "9 Years_perc: float64\n",
      "10 Years_perc: float64\n",
      "11 Years_perc: float64\n",
      "12 Years_perc: float64\n",
      "13 Years_perc: float64\n",
      "14 Years_perc: float64\n",
      "15 Years_perc: float64\n",
      "16 Years_perc: float64\n",
      "17 Years_perc: float64\n",
      "18 Years_perc: float64\n",
      "19 Years_perc: float64\n",
      "20 Years_perc: float64\n",
      "21 Years_perc: float64\n",
      "22 Years_perc: float64\n",
      "23 Years_perc: float64\n",
      "24 Years_perc: float64\n",
      "25 Years_perc: float64\n",
      "26 Years_perc: float64\n",
      "27 Years_perc: float64\n",
      "28 Years_perc: float64\n",
      "29 Years_perc: float64\n",
      "30 Years_perc: float64\n",
      "31 Years_perc: float64\n",
      "32 Years_perc: float64\n",
      "33 Years_perc: float64\n",
      "34 Years_perc: float64\n",
      "35 Years_perc: float64\n",
      "36 Years_perc: float64\n",
      "37 Years_perc: float64\n",
      "38 Years_perc: float64\n",
      "39 Years_perc: float64\n",
      "40 Years_perc: float64\n",
      "41 Years_perc: float64\n",
      "42 Years_perc: float64\n",
      "43 Years_perc: float64\n",
      "44 Years_perc: float64\n",
      "45 Years_perc: float64\n",
      "46 Years_perc: float64\n",
      "47 Years_perc: float64\n",
      "48 Years_perc: float64\n",
      "49 Years_perc: float64\n",
      "50 Years_perc: float64\n",
      "51 Years_perc: float64\n",
      "52 Years_perc: float64\n",
      "53 Years_perc: float64\n",
      "54 Years_perc: float64\n",
      "55 Years_perc: float64\n",
      "56 Years_perc: float64\n",
      "57 Years_perc: float64\n",
      "58 Years_perc: float64\n",
      "59 Years_perc: float64\n",
      "60 Years_perc: float64\n",
      "61 Years_perc: float64\n",
      "62 Years_perc: float64\n",
      "63 Years_perc: float64\n",
      "64 Years_perc: float64\n",
      "65 Years_perc: float64\n",
      "66 Years_perc: float64\n",
      "67 Years_perc: float64\n",
      "68 Years_perc: float64\n",
      "69 Years_perc: float64\n",
      "70 Years_perc: float64\n",
      "71 Years_perc: float64\n",
      "72 Years_perc: float64\n",
      "73 Years_perc: float64\n",
      "74 Years_perc: float64\n",
      "75 Years_perc: float64\n",
      "76 Years_perc: float64\n",
      "77 Years_perc: float64\n",
      "78 Years_perc: float64\n",
      "79 Years_perc: float64\n",
      "80 Years_perc: float64\n",
      "81 Years_perc: float64\n",
      "82 Years_perc: float64\n",
      "83 Years_perc: float64\n",
      "84 Years_perc: float64\n",
      "85 Years_perc: float64\n",
      "86 Years_perc: float64\n",
      "87 Years_perc: float64\n",
      "88 Years_perc: float64\n",
      "89 Years_perc: float64\n",
      "90 Years_perc: float64\n",
      "91 Years_perc: float64\n",
      "92 Years_perc: float64\n",
      "93 Years_perc: float64\n",
      "94 Years_perc: float64\n",
      "95 Years_perc: float64\n",
      "96 Years_perc: float64\n",
      "97  Years_perc: float64\n",
      "98  Years_perc: float64\n",
      "99  Years_perc: float64\n",
      "100 to 104  Years_perc: float64\n",
      "105 to 109  Years_perc: float64\n",
      "110  Years and Over_perc: float64\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_male_whi\n",
      "Shape: (3221, 212)\n",
      "Dtypes:\n",
      "0: int32\n",
      "1: int32\n",
      "2: int32\n",
      "3: int32\n",
      "4: int32\n",
      "5: int32\n",
      "6: int32\n",
      "7: int32\n",
      "8: int32\n",
      "9: int32\n",
      "10: int32\n",
      "11: int32\n",
      "12: int32\n",
      "13: int32\n",
      "14: int32\n",
      "15: int32\n",
      "16: int32\n",
      "17: int32\n",
      "18: int32\n",
      "19: int32\n",
      "20: int32\n",
      "21: int32\n",
      "22: int32\n",
      "23: int32\n",
      "24: int32\n",
      "25: int32\n",
      "26: int32\n",
      "27: int32\n",
      "28: int32\n",
      "29: int32\n",
      "30: int32\n",
      "31: int32\n",
      "32: int32\n",
      "33: int32\n",
      "34: int32\n",
      "35: int32\n",
      "36: int32\n",
      "37: int32\n",
      "38: int32\n",
      "39: int32\n",
      "40: int32\n",
      "41: int32\n",
      "42: int32\n",
      "43: int32\n",
      "44: int32\n",
      "45: int32\n",
      "46: int32\n",
      "47: int32\n",
      "48: int32\n",
      "49: int32\n",
      "50: int32\n",
      "51: int32\n",
      "52: int32\n",
      "53: int32\n",
      "54: int32\n",
      "55: int32\n",
      "56: int32\n",
      "57: int32\n",
      "58: int32\n",
      "59: int32\n",
      "60: int32\n",
      "61: int32\n",
      "62: int32\n",
      "63: int32\n",
      "64: int32\n",
      "65: int32\n",
      "66: int32\n",
      "67: int32\n",
      "68: int32\n",
      "69: int32\n",
      "70: int32\n",
      "71: int32\n",
      "72: int32\n",
      "73: int32\n",
      "74: int32\n",
      "75: int32\n",
      "76: int32\n",
      "77: int32\n",
      "78: int32\n",
      "79: int32\n",
      "80: int32\n",
      "81: int32\n",
      "82: int32\n",
      "83: int32\n",
      "84: int32\n",
      "85: int32\n",
      "86: int32\n",
      "87: int32\n",
      "88: int32\n",
      "89: int32\n",
      "90: int32\n",
      "91: int32\n",
      "92: int32\n",
      "93: int32\n",
      "94: int32\n",
      "95: int32\n",
      "96: int32\n",
      "97: int32\n",
      "98: int32\n",
      "99: int32\n",
      "102: int32\n",
      "107: int32\n",
      "110: int32\n",
      "Average_Age: float64\n",
      "Under 1 Year_perc: float64\n",
      "1 Year_perc: float64\n",
      "2 Years_perc: float64\n",
      "3 Years_perc: float64\n",
      "4 Years_perc: float64\n",
      "5 Years_perc: float64\n",
      "6 Years_perc: float64\n",
      "7 Years_perc: float64\n",
      "8 Years_perc: float64\n",
      "9 Years_perc: float64\n",
      "10 Years_perc: float64\n",
      "11 Years_perc: float64\n",
      "12 Years_perc: float64\n",
      "13 Years_perc: float64\n",
      "14 Years_perc: float64\n",
      "15 Years_perc: float64\n",
      "16 Years_perc: float64\n",
      "17 Years_perc: float64\n",
      "18 Years_perc: float64\n",
      "19 Years_perc: float64\n",
      "20 Years_perc: float64\n",
      "21 Years_perc: float64\n",
      "22 Years_perc: float64\n",
      "23 Years_perc: float64\n",
      "24 Years_perc: float64\n",
      "25 Years_perc: float64\n",
      "26 Years_perc: float64\n",
      "27 Years_perc: float64\n",
      "28 Years_perc: float64\n",
      "29 Years_perc: float64\n",
      "30 Years_perc: float64\n",
      "31 Years_perc: float64\n",
      "32 Years_perc: float64\n",
      "33 Years_perc: float64\n",
      "34 Years_perc: float64\n",
      "35 Years_perc: float64\n",
      "36 Years_perc: float64\n",
      "37 Years_perc: float64\n",
      "38 Years_perc: float64\n",
      "39 Years_perc: float64\n",
      "40 Years_perc: float64\n",
      "41 Years_perc: float64\n",
      "42 Years_perc: float64\n",
      "43 Years_perc: float64\n",
      "44 Years_perc: float64\n",
      "45 Years_perc: float64\n",
      "46 Years_perc: float64\n",
      "47 Years_perc: float64\n",
      "48 Years_perc: float64\n",
      "49 Years_perc: float64\n",
      "50 Years_perc: float64\n",
      "51 Years_perc: float64\n",
      "52 Years_perc: float64\n",
      "53 Years_perc: float64\n",
      "54 Years_perc: float64\n",
      "55 Years_perc: float64\n",
      "56 Years_perc: float64\n",
      "57 Years_perc: float64\n",
      "58 Years_perc: float64\n",
      "59 Years_perc: float64\n",
      "60 Years_perc: float64\n",
      "61 Years_perc: float64\n",
      "62 Years_perc: float64\n",
      "63 Years_perc: float64\n",
      "64 Years_perc: float64\n",
      "65 Years_perc: float64\n",
      "66 Years_perc: float64\n",
      "67 Years_perc: float64\n",
      "68 Years_perc: float64\n",
      "69 Years_perc: float64\n",
      "70 Years_perc: float64\n",
      "71 Years_perc: float64\n",
      "72 Years_perc: float64\n",
      "73 Years_perc: float64\n",
      "74 Years_perc: float64\n",
      "75 Years_perc: float64\n",
      "76 Years_perc: float64\n",
      "77 Years_perc: float64\n",
      "78 Years_perc: float64\n",
      "79 Years_perc: float64\n",
      "80 Years_perc: float64\n",
      "81 Years_perc: float64\n",
      "82 Years_perc: float64\n",
      "83 Years_perc: float64\n",
      "84 Years_perc: float64\n",
      "85 Years_perc: float64\n",
      "86 Years_perc: float64\n",
      "87 Years_perc: float64\n",
      "88 Years_perc: float64\n",
      "89 Years_perc: float64\n",
      "90 Years_perc: float64\n",
      "91 Years_perc: float64\n",
      "92 Years_perc: float64\n",
      "93 Years_perc: float64\n",
      "94 Years_perc: float64\n",
      "95 Years_perc: float64\n",
      "96 Years_perc: float64\n",
      "97  Years_perc: float64\n",
      "98  Years_perc: float64\n",
      "99  Years_perc: float64\n",
      "100 to 104  Years_perc: float64\n",
      "105 to 109  Years_perc: float64\n",
      "110  Years and Over_perc: float64\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_female_whi\n",
      "Shape: (3221, 212)\n",
      "Dtypes:\n",
      "0: int32\n",
      "1: int32\n",
      "2: int32\n",
      "3: int32\n",
      "4: int32\n",
      "5: int32\n",
      "6: int32\n",
      "7: int32\n",
      "8: int32\n",
      "9: int32\n",
      "10: int32\n",
      "11: int32\n",
      "12: int32\n",
      "13: int32\n",
      "14: int32\n",
      "15: int32\n",
      "16: int32\n",
      "17: int32\n",
      "18: int32\n",
      "19: int32\n",
      "20: int32\n",
      "21: int32\n",
      "22: int32\n",
      "23: int32\n",
      "24: int32\n",
      "25: int32\n",
      "26: int32\n",
      "27: int32\n",
      "28: int32\n",
      "29: int32\n",
      "30: int32\n",
      "31: int32\n",
      "32: int32\n",
      "33: int32\n",
      "34: int32\n",
      "35: int32\n",
      "36: int32\n",
      "37: int32\n",
      "38: int32\n",
      "39: int32\n",
      "40: int32\n",
      "41: int32\n",
      "42: int32\n",
      "43: int32\n",
      "44: int32\n",
      "45: int32\n",
      "46: int32\n",
      "47: int32\n",
      "48: int32\n",
      "49: int32\n",
      "50: int32\n",
      "51: int32\n",
      "52: int32\n",
      "53: int32\n",
      "54: int32\n",
      "55: int32\n",
      "56: int32\n",
      "57: int32\n",
      "58: int32\n",
      "59: int32\n",
      "60: int32\n",
      "61: int32\n",
      "62: int32\n",
      "63: int32\n",
      "64: int32\n",
      "65: int32\n",
      "66: int32\n",
      "67: int32\n",
      "68: int32\n",
      "69: int32\n",
      "70: int32\n",
      "71: int32\n",
      "72: int32\n",
      "73: int32\n",
      "74: int32\n",
      "75: int32\n",
      "76: int32\n",
      "77: int32\n",
      "78: int32\n",
      "79: int32\n",
      "80: int32\n",
      "81: int32\n",
      "82: int32\n",
      "83: int32\n",
      "84: int32\n",
      "85: int32\n",
      "86: int32\n",
      "87: int32\n",
      "88: int32\n",
      "89: int32\n",
      "90: int32\n",
      "91: int32\n",
      "92: int32\n",
      "93: int32\n",
      "94: int32\n",
      "95: int32\n",
      "96: int32\n",
      "97: int32\n",
      "98: int32\n",
      "99: int32\n",
      "102: int32\n",
      "107: int32\n",
      "110: int32\n",
      "Average_Age: float64\n",
      "Under 1 Year_perc: float64\n",
      "1 Year_perc: float64\n",
      "2 Years_perc: float64\n",
      "3 Years_perc: float64\n",
      "4 Years_perc: float64\n",
      "5 Years_perc: float64\n",
      "6 Years_perc: float64\n",
      "7 Years_perc: float64\n",
      "8 Years_perc: float64\n",
      "9 Years_perc: float64\n",
      "10 Years_perc: float64\n",
      "11 Years_perc: float64\n",
      "12 Years_perc: float64\n",
      "13 Years_perc: float64\n",
      "14 Years_perc: float64\n",
      "15 Years_perc: float64\n",
      "16 Years_perc: float64\n",
      "17 Years_perc: float64\n",
      "18 Years_perc: float64\n",
      "19 Years_perc: float64\n",
      "20 Years_perc: float64\n",
      "21 Years_perc: float64\n",
      "22 Years_perc: float64\n",
      "23 Years_perc: float64\n",
      "24 Years_perc: float64\n",
      "25 Years_perc: float64\n",
      "26 Years_perc: float64\n",
      "27 Years_perc: float64\n",
      "28 Years_perc: float64\n",
      "29 Years_perc: float64\n",
      "30 Years_perc: float64\n",
      "31 Years_perc: float64\n",
      "32 Years_perc: float64\n",
      "33 Years_perc: float64\n",
      "34 Years_perc: float64\n",
      "35 Years_perc: float64\n",
      "36 Years_perc: float64\n",
      "37 Years_perc: float64\n",
      "38 Years_perc: float64\n",
      "39 Years_perc: float64\n",
      "40 Years_perc: float64\n",
      "41 Years_perc: float64\n",
      "42 Years_perc: float64\n",
      "43 Years_perc: float64\n",
      "44 Years_perc: float64\n",
      "45 Years_perc: float64\n",
      "46 Years_perc: float64\n",
      "47 Years_perc: float64\n",
      "48 Years_perc: float64\n",
      "49 Years_perc: float64\n",
      "50 Years_perc: float64\n",
      "51 Years_perc: float64\n",
      "52 Years_perc: float64\n",
      "53 Years_perc: float64\n",
      "54 Years_perc: float64\n",
      "55 Years_perc: float64\n",
      "56 Years_perc: float64\n",
      "57 Years_perc: float64\n",
      "58 Years_perc: float64\n",
      "59 Years_perc: float64\n",
      "60 Years_perc: float64\n",
      "61 Years_perc: float64\n",
      "62 Years_perc: float64\n",
      "63 Years_perc: float64\n",
      "64 Years_perc: float64\n",
      "65 Years_perc: float64\n",
      "66 Years_perc: float64\n",
      "67 Years_perc: float64\n",
      "68 Years_perc: float64\n",
      "69 Years_perc: float64\n",
      "70 Years_perc: float64\n",
      "71 Years_perc: float64\n",
      "72 Years_perc: float64\n",
      "73 Years_perc: float64\n",
      "74 Years_perc: float64\n",
      "75 Years_perc: float64\n",
      "76 Years_perc: float64\n",
      "77 Years_perc: float64\n",
      "78 Years_perc: float64\n",
      "79 Years_perc: float64\n",
      "80 Years_perc: float64\n",
      "81 Years_perc: float64\n",
      "82 Years_perc: float64\n",
      "83 Years_perc: float64\n",
      "84 Years_perc: float64\n",
      "85 Years_perc: float64\n",
      "86 Years_perc: float64\n",
      "87 Years_perc: float64\n",
      "88 Years_perc: float64\n",
      "89 Years_perc: float64\n",
      "90 Years_perc: float64\n",
      "91 Years_perc: float64\n",
      "92 Years_perc: float64\n",
      "93 Years_perc: float64\n",
      "94 Years_perc: float64\n",
      "95 Years_perc: float64\n",
      "96 Years_perc: float64\n",
      "97  Years_perc: float64\n",
      "98  Years_perc: float64\n",
      "99  Years_perc: float64\n",
      "100 to 104  Years_perc: float64\n",
      "105 to 109  Years_perc: float64\n",
      "110  Years and Over_perc: float64\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_male_baa\n",
      "Shape: (3221, 212)\n",
      "Dtypes:\n",
      "0: int32\n",
      "1: int32\n",
      "2: int32\n",
      "3: int32\n",
      "4: int32\n",
      "5: int32\n",
      "6: int32\n",
      "7: int32\n",
      "8: int32\n",
      "9: int32\n",
      "10: int32\n",
      "11: int32\n",
      "12: int32\n",
      "13: int32\n",
      "14: int32\n",
      "15: int32\n",
      "16: int32\n",
      "17: int32\n",
      "18: int32\n",
      "19: int32\n",
      "20: int32\n",
      "21: int32\n",
      "22: int32\n",
      "23: int32\n",
      "24: int32\n",
      "25: int32\n",
      "26: int32\n",
      "27: int32\n",
      "28: int32\n",
      "29: int32\n",
      "30: int32\n",
      "31: int32\n",
      "32: int32\n",
      "33: int32\n",
      "34: int32\n",
      "35: int32\n",
      "36: int32\n",
      "37: int32\n",
      "38: int32\n",
      "39: int32\n",
      "40: int32\n",
      "41: int32\n",
      "42: int32\n",
      "43: int32\n",
      "44: int32\n",
      "45: int32\n",
      "46: int32\n",
      "47: int32\n",
      "48: int32\n",
      "49: int32\n",
      "50: int32\n",
      "51: int32\n",
      "52: int32\n",
      "53: int32\n",
      "54: int32\n",
      "55: int32\n",
      "56: int32\n",
      "57: int32\n",
      "58: int32\n",
      "59: int32\n",
      "60: int32\n",
      "61: int32\n",
      "62: int32\n",
      "63: int32\n",
      "64: int32\n",
      "65: int32\n",
      "66: int32\n",
      "67: int32\n",
      "68: int32\n",
      "69: int32\n",
      "70: int32\n",
      "71: int32\n",
      "72: int32\n",
      "73: int32\n",
      "74: int32\n",
      "75: int32\n",
      "76: int32\n",
      "77: int32\n",
      "78: int32\n",
      "79: int32\n",
      "80: int32\n",
      "81: int32\n",
      "82: int32\n",
      "83: int32\n",
      "84: int32\n",
      "85: int32\n",
      "86: int32\n",
      "87: int32\n",
      "88: int32\n",
      "89: int32\n",
      "90: int32\n",
      "91: int32\n",
      "92: int32\n",
      "93: int32\n",
      "94: int32\n",
      "95: int32\n",
      "96: int32\n",
      "97: int32\n",
      "98: int32\n",
      "99: int32\n",
      "102: int32\n",
      "107: int32\n",
      "110: int32\n",
      "Average_Age: float64\n",
      "Under 1 Year_perc: float64\n",
      "1 Year_perc: float64\n",
      "2 Years_perc: float64\n",
      "3 Years_perc: float64\n",
      "4 Years_perc: float64\n",
      "5 Years_perc: float64\n",
      "6 Years_perc: float64\n",
      "7 Years_perc: float64\n",
      "8 Years_perc: float64\n",
      "9 Years_perc: float64\n",
      "10 Years_perc: float64\n",
      "11 Years_perc: float64\n",
      "12 Years_perc: float64\n",
      "13 Years_perc: float64\n",
      "14 Years_perc: float64\n",
      "15 Years_perc: float64\n",
      "16 Years_perc: float64\n",
      "17 Years_perc: float64\n",
      "18 Years_perc: float64\n",
      "19 Years_perc: float64\n",
      "20 Years_perc: float64\n",
      "21 Years_perc: float64\n",
      "22 Years_perc: float64\n",
      "23 Years_perc: float64\n",
      "24 Years_perc: float64\n",
      "25 Years_perc: float64\n",
      "26 Years_perc: float64\n",
      "27 Years_perc: float64\n",
      "28 Years_perc: float64\n",
      "29 Years_perc: float64\n",
      "30 Years_perc: float64\n",
      "31 Years_perc: float64\n",
      "32 Years_perc: float64\n",
      "33 Years_perc: float64\n",
      "34 Years_perc: float64\n",
      "35 Years_perc: float64\n",
      "36 Years_perc: float64\n",
      "37 Years_perc: float64\n",
      "38 Years_perc: float64\n",
      "39 Years_perc: float64\n",
      "40 Years_perc: float64\n",
      "41 Years_perc: float64\n",
      "42 Years_perc: float64\n",
      "43 Years_perc: float64\n",
      "44 Years_perc: float64\n",
      "45 Years_perc: float64\n",
      "46 Years_perc: float64\n",
      "47 Years_perc: float64\n",
      "48 Years_perc: float64\n",
      "49 Years_perc: float64\n",
      "50 Years_perc: float64\n",
      "51 Years_perc: float64\n",
      "52 Years_perc: float64\n",
      "53 Years_perc: float64\n",
      "54 Years_perc: float64\n",
      "55 Years_perc: float64\n",
      "56 Years_perc: float64\n",
      "57 Years_perc: float64\n",
      "58 Years_perc: float64\n",
      "59 Years_perc: float64\n",
      "60 Years_perc: float64\n",
      "61 Years_perc: float64\n",
      "62 Years_perc: float64\n",
      "63 Years_perc: float64\n",
      "64 Years_perc: float64\n",
      "65 Years_perc: float64\n",
      "66 Years_perc: float64\n",
      "67 Years_perc: float64\n",
      "68 Years_perc: float64\n",
      "69 Years_perc: float64\n",
      "70 Years_perc: float64\n",
      "71 Years_perc: float64\n",
      "72 Years_perc: float64\n",
      "73 Years_perc: float64\n",
      "74 Years_perc: float64\n",
      "75 Years_perc: float64\n",
      "76 Years_perc: float64\n",
      "77 Years_perc: float64\n",
      "78 Years_perc: float64\n",
      "79 Years_perc: float64\n",
      "80 Years_perc: float64\n",
      "81 Years_perc: float64\n",
      "82 Years_perc: float64\n",
      "83 Years_perc: float64\n",
      "84 Years_perc: float64\n",
      "85 Years_perc: float64\n",
      "86 Years_perc: float64\n",
      "87 Years_perc: float64\n",
      "88 Years_perc: float64\n",
      "89 Years_perc: float64\n",
      "90 Years_perc: float64\n",
      "91 Years_perc: float64\n",
      "92 Years_perc: float64\n",
      "93 Years_perc: float64\n",
      "94 Years_perc: float64\n",
      "95 Years_perc: float64\n",
      "96 Years_perc: float64\n",
      "97  Years_perc: float64\n",
      "98  Years_perc: float64\n",
      "99  Years_perc: float64\n",
      "100 to 104  Years_perc: float64\n",
      "105 to 109  Years_perc: float64\n",
      "110  Years and Over_perc: float64\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_female_baa\n",
      "Shape: (3221, 212)\n",
      "Dtypes:\n",
      "0: int32\n",
      "1: int32\n",
      "2: int32\n",
      "3: int32\n",
      "4: int32\n",
      "5: int32\n",
      "6: int32\n",
      "7: int32\n",
      "8: int32\n",
      "9: int32\n",
      "10: int32\n",
      "11: int32\n",
      "12: int32\n",
      "13: int32\n",
      "14: int32\n",
      "15: int32\n",
      "16: int32\n",
      "17: int32\n",
      "18: int32\n",
      "19: int32\n",
      "20: int32\n",
      "21: int32\n",
      "22: int32\n",
      "23: int32\n",
      "24: int32\n",
      "25: int32\n",
      "26: int32\n",
      "27: int32\n",
      "28: int32\n",
      "29: int32\n",
      "30: int32\n",
      "31: int32\n",
      "32: int32\n",
      "33: int32\n",
      "34: int32\n",
      "35: int32\n",
      "36: int32\n",
      "37: int32\n",
      "38: int32\n",
      "39: int32\n",
      "40: int32\n",
      "41: int32\n",
      "42: int32\n",
      "43: int32\n",
      "44: int32\n",
      "45: int32\n",
      "46: int32\n",
      "47: int32\n",
      "48: int32\n",
      "49: int32\n",
      "50: int32\n",
      "51: int32\n",
      "52: int32\n",
      "53: int32\n",
      "54: int32\n",
      "55: int32\n",
      "56: int32\n",
      "57: int32\n",
      "58: int32\n",
      "59: int32\n",
      "60: int32\n",
      "61: int32\n",
      "62: int32\n",
      "63: int32\n",
      "64: int32\n",
      "65: int32\n",
      "66: int32\n",
      "67: int32\n",
      "68: int32\n",
      "69: int32\n",
      "70: int32\n",
      "71: int32\n",
      "72: int32\n",
      "73: int32\n",
      "74: int32\n",
      "75: int32\n",
      "76: int32\n",
      "77: int32\n",
      "78: int32\n",
      "79: int32\n",
      "80: int32\n",
      "81: int32\n",
      "82: int32\n",
      "83: int32\n",
      "84: int32\n",
      "85: int32\n",
      "86: int32\n",
      "87: int32\n",
      "88: int32\n",
      "89: int32\n",
      "90: int32\n",
      "91: int32\n",
      "92: int32\n",
      "93: int32\n",
      "94: int32\n",
      "95: int32\n",
      "96: int32\n",
      "97: int32\n",
      "98: int32\n",
      "99: int32\n",
      "102: int32\n",
      "107: int32\n",
      "110: int32\n",
      "Average_Age: float64\n",
      "Under 1 Year_perc: float64\n",
      "1 Year_perc: float64\n",
      "2 Years_perc: float64\n",
      "3 Years_perc: float64\n",
      "4 Years_perc: float64\n",
      "5 Years_perc: float64\n",
      "6 Years_perc: float64\n",
      "7 Years_perc: float64\n",
      "8 Years_perc: float64\n",
      "9 Years_perc: float64\n",
      "10 Years_perc: float64\n",
      "11 Years_perc: float64\n",
      "12 Years_perc: float64\n",
      "13 Years_perc: float64\n",
      "14 Years_perc: float64\n",
      "15 Years_perc: float64\n",
      "16 Years_perc: float64\n",
      "17 Years_perc: float64\n",
      "18 Years_perc: float64\n",
      "19 Years_perc: float64\n",
      "20 Years_perc: float64\n",
      "21 Years_perc: float64\n",
      "22 Years_perc: float64\n",
      "23 Years_perc: float64\n",
      "24 Years_perc: float64\n",
      "25 Years_perc: float64\n",
      "26 Years_perc: float64\n",
      "27 Years_perc: float64\n",
      "28 Years_perc: float64\n",
      "29 Years_perc: float64\n",
      "30 Years_perc: float64\n",
      "31 Years_perc: float64\n",
      "32 Years_perc: float64\n",
      "33 Years_perc: float64\n",
      "34 Years_perc: float64\n",
      "35 Years_perc: float64\n",
      "36 Years_perc: float64\n",
      "37 Years_perc: float64\n",
      "38 Years_perc: float64\n",
      "39 Years_perc: float64\n",
      "40 Years_perc: float64\n",
      "41 Years_perc: float64\n",
      "42 Years_perc: float64\n",
      "43 Years_perc: float64\n",
      "44 Years_perc: float64\n",
      "45 Years_perc: float64\n",
      "46 Years_perc: float64\n",
      "47 Years_perc: float64\n",
      "48 Years_perc: float64\n",
      "49 Years_perc: float64\n",
      "50 Years_perc: float64\n",
      "51 Years_perc: float64\n",
      "52 Years_perc: float64\n",
      "53 Years_perc: float64\n",
      "54 Years_perc: float64\n",
      "55 Years_perc: float64\n",
      "56 Years_perc: float64\n",
      "57 Years_perc: float64\n",
      "58 Years_perc: float64\n",
      "59 Years_perc: float64\n",
      "60 Years_perc: float64\n",
      "61 Years_perc: float64\n",
      "62 Years_perc: float64\n",
      "63 Years_perc: float64\n",
      "64 Years_perc: float64\n",
      "65 Years_perc: float64\n",
      "66 Years_perc: float64\n",
      "67 Years_perc: float64\n",
      "68 Years_perc: float64\n",
      "69 Years_perc: float64\n",
      "70 Years_perc: float64\n",
      "71 Years_perc: float64\n",
      "72 Years_perc: float64\n",
      "73 Years_perc: float64\n",
      "74 Years_perc: float64\n",
      "75 Years_perc: float64\n",
      "76 Years_perc: float64\n",
      "77 Years_perc: float64\n",
      "78 Years_perc: float64\n",
      "79 Years_perc: float64\n",
      "80 Years_perc: float64\n",
      "81 Years_perc: float64\n",
      "82 Years_perc: float64\n",
      "83 Years_perc: float64\n",
      "84 Years_perc: float64\n",
      "85 Years_perc: float64\n",
      "86 Years_perc: float64\n",
      "87 Years_perc: float64\n",
      "88 Years_perc: float64\n",
      "89 Years_perc: float64\n",
      "90 Years_perc: float64\n",
      "91 Years_perc: float64\n",
      "92 Years_perc: float64\n",
      "93 Years_perc: float64\n",
      "94 Years_perc: float64\n",
      "95 Years_perc: float64\n",
      "96 Years_perc: float64\n",
      "97  Years_perc: float64\n",
      "98  Years_perc: float64\n",
      "99  Years_perc: float64\n",
      "100 to 104  Years_perc: float64\n",
      "105 to 109  Years_perc: float64\n",
      "110  Years and Over_perc: float64\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_male_aian\n",
      "Shape: (3221, 212)\n",
      "Dtypes:\n",
      "0: int32\n",
      "1: int32\n",
      "2: int32\n",
      "3: int32\n",
      "4: int32\n",
      "5: int32\n",
      "6: int32\n",
      "7: int32\n",
      "8: int32\n",
      "9: int32\n",
      "10: int32\n",
      "11: int32\n",
      "12: int32\n",
      "13: int32\n",
      "14: int32\n",
      "15: int32\n",
      "16: int32\n",
      "17: int32\n",
      "18: int32\n",
      "19: int32\n",
      "20: int32\n",
      "21: int32\n",
      "22: int32\n",
      "23: int32\n",
      "24: int32\n",
      "25: int32\n",
      "26: int32\n",
      "27: int32\n",
      "28: int32\n",
      "29: int32\n",
      "30: int32\n",
      "31: int32\n",
      "32: int32\n",
      "33: int32\n",
      "34: int32\n",
      "35: int32\n",
      "36: int32\n",
      "37: int32\n",
      "38: int32\n",
      "39: int32\n",
      "40: int32\n",
      "41: int32\n",
      "42: int32\n",
      "43: int32\n",
      "44: int32\n",
      "45: int32\n",
      "46: int32\n",
      "47: int32\n",
      "48: int32\n",
      "49: int32\n",
      "50: int32\n",
      "51: int32\n",
      "52: int32\n",
      "53: int32\n",
      "54: int32\n",
      "55: int32\n",
      "56: int32\n",
      "57: int32\n",
      "58: int32\n",
      "59: int32\n",
      "60: int32\n",
      "61: int32\n",
      "62: int32\n",
      "63: int32\n",
      "64: int32\n",
      "65: int32\n",
      "66: int32\n",
      "67: int32\n",
      "68: int32\n",
      "69: int32\n",
      "70: int32\n",
      "71: int32\n",
      "72: int32\n",
      "73: int32\n",
      "74: int32\n",
      "75: int32\n",
      "76: int32\n",
      "77: int32\n",
      "78: int32\n",
      "79: int32\n",
      "80: int32\n",
      "81: int32\n",
      "82: int32\n",
      "83: int32\n",
      "84: int32\n",
      "85: int32\n",
      "86: int32\n",
      "87: int32\n",
      "88: int32\n",
      "89: int32\n",
      "90: int32\n",
      "91: int32\n",
      "92: int32\n",
      "93: int32\n",
      "94: int32\n",
      "95: int32\n",
      "96: int32\n",
      "97: int32\n",
      "98: int32\n",
      "99: int32\n",
      "102: int32\n",
      "107: int32\n",
      "110: int32\n",
      "Average_Age: float64\n",
      "Under 1 Year_perc: float64\n",
      "1 Year_perc: float64\n",
      "2 Years_perc: float64\n",
      "3 Years_perc: float64\n",
      "4 Years_perc: float64\n",
      "5 Years_perc: float64\n",
      "6 Years_perc: float64\n",
      "7 Years_perc: float64\n",
      "8 Years_perc: float64\n",
      "9 Years_perc: float64\n",
      "10 Years_perc: float64\n",
      "11 Years_perc: float64\n",
      "12 Years_perc: float64\n",
      "13 Years_perc: float64\n",
      "14 Years_perc: float64\n",
      "15 Years_perc: float64\n",
      "16 Years_perc: float64\n",
      "17 Years_perc: float64\n",
      "18 Years_perc: float64\n",
      "19 Years_perc: float64\n",
      "20 Years_perc: float64\n",
      "21 Years_perc: float64\n",
      "22 Years_perc: float64\n",
      "23 Years_perc: float64\n",
      "24 Years_perc: float64\n",
      "25 Years_perc: float64\n",
      "26 Years_perc: float64\n",
      "27 Years_perc: float64\n",
      "28 Years_perc: float64\n",
      "29 Years_perc: float64\n",
      "30 Years_perc: float64\n",
      "31 Years_perc: float64\n",
      "32 Years_perc: float64\n",
      "33 Years_perc: float64\n",
      "34 Years_perc: float64\n",
      "35 Years_perc: float64\n",
      "36 Years_perc: float64\n",
      "37 Years_perc: float64\n",
      "38 Years_perc: float64\n",
      "39 Years_perc: float64\n",
      "40 Years_perc: float64\n",
      "41 Years_perc: float64\n",
      "42 Years_perc: float64\n",
      "43 Years_perc: float64\n",
      "44 Years_perc: float64\n",
      "45 Years_perc: float64\n",
      "46 Years_perc: float64\n",
      "47 Years_perc: float64\n",
      "48 Years_perc: float64\n",
      "49 Years_perc: float64\n",
      "50 Years_perc: float64\n",
      "51 Years_perc: float64\n",
      "52 Years_perc: float64\n",
      "53 Years_perc: float64\n",
      "54 Years_perc: float64\n",
      "55 Years_perc: float64\n",
      "56 Years_perc: float64\n",
      "57 Years_perc: float64\n",
      "58 Years_perc: float64\n",
      "59 Years_perc: float64\n",
      "60 Years_perc: float64\n",
      "61 Years_perc: float64\n",
      "62 Years_perc: float64\n",
      "63 Years_perc: float64\n",
      "64 Years_perc: float64\n",
      "65 Years_perc: float64\n",
      "66 Years_perc: float64\n",
      "67 Years_perc: float64\n",
      "68 Years_perc: float64\n",
      "69 Years_perc: float64\n",
      "70 Years_perc: float64\n",
      "71 Years_perc: float64\n",
      "72 Years_perc: float64\n",
      "73 Years_perc: float64\n",
      "74 Years_perc: float64\n",
      "75 Years_perc: float64\n",
      "76 Years_perc: float64\n",
      "77 Years_perc: float64\n",
      "78 Years_perc: float64\n",
      "79 Years_perc: float64\n",
      "80 Years_perc: float64\n",
      "81 Years_perc: float64\n",
      "82 Years_perc: float64\n",
      "83 Years_perc: float64\n",
      "84 Years_perc: float64\n",
      "85 Years_perc: float64\n",
      "86 Years_perc: float64\n",
      "87 Years_perc: float64\n",
      "88 Years_perc: float64\n",
      "89 Years_perc: float64\n",
      "90 Years_perc: float64\n",
      "91 Years_perc: float64\n",
      "92 Years_perc: float64\n",
      "93 Years_perc: float64\n",
      "94 Years_perc: float64\n",
      "95 Years_perc: float64\n",
      "96 Years_perc: float64\n",
      "97  Years_perc: float64\n",
      "98  Years_perc: float64\n",
      "99  Years_perc: float64\n",
      "100 to 104  Years_perc: float64\n",
      "105 to 109  Years_perc: float64\n",
      "110  Years and Over_perc: float64\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_female_aian\n",
      "Shape: (3221, 212)\n",
      "Dtypes:\n",
      "0: int32\n",
      "1: int32\n",
      "2: int32\n",
      "3: int32\n",
      "4: int32\n",
      "5: int32\n",
      "6: int32\n",
      "7: int32\n",
      "8: int32\n",
      "9: int32\n",
      "10: int32\n",
      "11: int32\n",
      "12: int32\n",
      "13: int32\n",
      "14: int32\n",
      "15: int32\n",
      "16: int32\n",
      "17: int32\n",
      "18: int32\n",
      "19: int32\n",
      "20: int32\n",
      "21: int32\n",
      "22: int32\n",
      "23: int32\n",
      "24: int32\n",
      "25: int32\n",
      "26: int32\n",
      "27: int32\n",
      "28: int32\n",
      "29: int32\n",
      "30: int32\n",
      "31: int32\n",
      "32: int32\n",
      "33: int32\n",
      "34: int32\n",
      "35: int32\n",
      "36: int32\n",
      "37: int32\n",
      "38: int32\n",
      "39: int32\n",
      "40: int32\n",
      "41: int32\n",
      "42: int32\n",
      "43: int32\n",
      "44: int32\n",
      "45: int32\n",
      "46: int32\n",
      "47: int32\n",
      "48: int32\n",
      "49: int32\n",
      "50: int32\n",
      "51: int32\n",
      "52: int32\n",
      "53: int32\n",
      "54: int32\n",
      "55: int32\n",
      "56: int32\n",
      "57: int32\n",
      "58: int32\n",
      "59: int32\n",
      "60: int32\n",
      "61: int32\n",
      "62: int32\n",
      "63: int32\n",
      "64: int32\n",
      "65: int32\n",
      "66: int32\n",
      "67: int32\n",
      "68: int32\n",
      "69: int32\n",
      "70: int32\n",
      "71: int32\n",
      "72: int32\n",
      "73: int32\n",
      "74: int32\n",
      "75: int32\n",
      "76: int32\n",
      "77: int32\n",
      "78: int32\n",
      "79: int32\n",
      "80: int32\n",
      "81: int32\n",
      "82: int32\n",
      "83: int32\n",
      "84: int32\n",
      "85: int32\n",
      "86: int32\n",
      "87: int32\n",
      "88: int32\n",
      "89: int32\n",
      "90: int32\n",
      "91: int32\n",
      "92: int32\n",
      "93: int32\n",
      "94: int32\n",
      "95: int32\n",
      "96: int32\n",
      "97: int32\n",
      "98: int32\n",
      "99: int32\n",
      "102: int32\n",
      "107: int32\n",
      "110: int32\n",
      "Average_Age: float64\n",
      "Under 1 Year_perc: float64\n",
      "1 Year_perc: float64\n",
      "2 Years_perc: float64\n",
      "3 Years_perc: float64\n",
      "4 Years_perc: float64\n",
      "5 Years_perc: float64\n",
      "6 Years_perc: float64\n",
      "7 Years_perc: float64\n",
      "8 Years_perc: float64\n",
      "9 Years_perc: float64\n",
      "10 Years_perc: float64\n",
      "11 Years_perc: float64\n",
      "12 Years_perc: float64\n",
      "13 Years_perc: float64\n",
      "14 Years_perc: float64\n",
      "15 Years_perc: float64\n",
      "16 Years_perc: float64\n",
      "17 Years_perc: float64\n",
      "18 Years_perc: float64\n",
      "19 Years_perc: float64\n",
      "20 Years_perc: float64\n",
      "21 Years_perc: float64\n",
      "22 Years_perc: float64\n",
      "23 Years_perc: float64\n",
      "24 Years_perc: float64\n",
      "25 Years_perc: float64\n",
      "26 Years_perc: float64\n",
      "27 Years_perc: float64\n",
      "28 Years_perc: float64\n",
      "29 Years_perc: float64\n",
      "30 Years_perc: float64\n",
      "31 Years_perc: float64\n",
      "32 Years_perc: float64\n",
      "33 Years_perc: float64\n",
      "34 Years_perc: float64\n",
      "35 Years_perc: float64\n",
      "36 Years_perc: float64\n",
      "37 Years_perc: float64\n",
      "38 Years_perc: float64\n",
      "39 Years_perc: float64\n",
      "40 Years_perc: float64\n",
      "41 Years_perc: float64\n",
      "42 Years_perc: float64\n",
      "43 Years_perc: float64\n",
      "44 Years_perc: float64\n",
      "45 Years_perc: float64\n",
      "46 Years_perc: float64\n",
      "47 Years_perc: float64\n",
      "48 Years_perc: float64\n",
      "49 Years_perc: float64\n",
      "50 Years_perc: float64\n",
      "51 Years_perc: float64\n",
      "52 Years_perc: float64\n",
      "53 Years_perc: float64\n",
      "54 Years_perc: float64\n",
      "55 Years_perc: float64\n",
      "56 Years_perc: float64\n",
      "57 Years_perc: float64\n",
      "58 Years_perc: float64\n",
      "59 Years_perc: float64\n",
      "60 Years_perc: float64\n",
      "61 Years_perc: float64\n",
      "62 Years_perc: float64\n",
      "63 Years_perc: float64\n",
      "64 Years_perc: float64\n",
      "65 Years_perc: float64\n",
      "66 Years_perc: float64\n",
      "67 Years_perc: float64\n",
      "68 Years_perc: float64\n",
      "69 Years_perc: float64\n",
      "70 Years_perc: float64\n",
      "71 Years_perc: float64\n",
      "72 Years_perc: float64\n",
      "73 Years_perc: float64\n",
      "74 Years_perc: float64\n",
      "75 Years_perc: float64\n",
      "76 Years_perc: float64\n",
      "77 Years_perc: float64\n",
      "78 Years_perc: float64\n",
      "79 Years_perc: float64\n",
      "80 Years_perc: float64\n",
      "81 Years_perc: float64\n",
      "82 Years_perc: float64\n",
      "83 Years_perc: float64\n",
      "84 Years_perc: float64\n",
      "85 Years_perc: float64\n",
      "86 Years_perc: float64\n",
      "87 Years_perc: float64\n",
      "88 Years_perc: float64\n",
      "89 Years_perc: float64\n",
      "90 Years_perc: float64\n",
      "91 Years_perc: float64\n",
      "92 Years_perc: float64\n",
      "93 Years_perc: float64\n",
      "94 Years_perc: float64\n",
      "95 Years_perc: float64\n",
      "96 Years_perc: float64\n",
      "97  Years_perc: float64\n",
      "98  Years_perc: float64\n",
      "99  Years_perc: float64\n",
      "100 to 104  Years_perc: float64\n",
      "105 to 109  Years_perc: float64\n",
      "110  Years and Over_perc: float64\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_male_aa\n",
      "Shape: (3221, 212)\n",
      "Dtypes:\n",
      "0: int32\n",
      "1: int32\n",
      "2: int32\n",
      "3: int32\n",
      "4: int32\n",
      "5: int32\n",
      "6: int32\n",
      "7: int32\n",
      "8: int32\n",
      "9: int32\n",
      "10: int32\n",
      "11: int32\n",
      "12: int32\n",
      "13: int32\n",
      "14: int32\n",
      "15: int32\n",
      "16: int32\n",
      "17: int32\n",
      "18: int32\n",
      "19: int32\n",
      "20: int32\n",
      "21: int32\n",
      "22: int32\n",
      "23: int32\n",
      "24: int32\n",
      "25: int32\n",
      "26: int32\n",
      "27: int32\n",
      "28: int32\n",
      "29: int32\n",
      "30: int32\n",
      "31: int32\n",
      "32: int32\n",
      "33: int32\n",
      "34: int32\n",
      "35: int32\n",
      "36: int32\n",
      "37: int32\n",
      "38: int32\n",
      "39: int32\n",
      "40: int32\n",
      "41: int32\n",
      "42: int32\n",
      "43: int32\n",
      "44: int32\n",
      "45: int32\n",
      "46: int32\n",
      "47: int32\n",
      "48: int32\n",
      "49: int32\n",
      "50: int32\n",
      "51: int32\n",
      "52: int32\n",
      "53: int32\n",
      "54: int32\n",
      "55: int32\n",
      "56: int32\n",
      "57: int32\n",
      "58: int32\n",
      "59: int32\n",
      "60: int32\n",
      "61: int32\n",
      "62: int32\n",
      "63: int32\n",
      "64: int32\n",
      "65: int32\n",
      "66: int32\n",
      "67: int32\n",
      "68: int32\n",
      "69: int32\n",
      "70: int32\n",
      "71: int32\n",
      "72: int32\n",
      "73: int32\n",
      "74: int32\n",
      "75: int32\n",
      "76: int32\n",
      "77: int32\n",
      "78: int32\n",
      "79: int32\n",
      "80: int32\n",
      "81: int32\n",
      "82: int32\n",
      "83: int32\n",
      "84: int32\n",
      "85: int32\n",
      "86: int32\n",
      "87: int32\n",
      "88: int32\n",
      "89: int32\n",
      "90: int32\n",
      "91: int32\n",
      "92: int32\n",
      "93: int32\n",
      "94: int32\n",
      "95: int32\n",
      "96: int32\n",
      "97: int32\n",
      "98: int32\n",
      "99: int32\n",
      "102: int32\n",
      "107: int32\n",
      "110: int32\n",
      "Average_Age: float64\n",
      "Under 1 Year_perc: float64\n",
      "1 Year_perc: float64\n",
      "2 Years_perc: float64\n",
      "3 Years_perc: float64\n",
      "4 Years_perc: float64\n",
      "5 Years_perc: float64\n",
      "6 Years_perc: float64\n",
      "7 Years_perc: float64\n",
      "8 Years_perc: float64\n",
      "9 Years_perc: float64\n",
      "10 Years_perc: float64\n",
      "11 Years_perc: float64\n",
      "12 Years_perc: float64\n",
      "13 Years_perc: float64\n",
      "14 Years_perc: float64\n",
      "15 Years_perc: float64\n",
      "16 Years_perc: float64\n",
      "17 Years_perc: float64\n",
      "18 Years_perc: float64\n",
      "19 Years_perc: float64\n",
      "20 Years_perc: float64\n",
      "21 Years_perc: float64\n",
      "22 Years_perc: float64\n",
      "23 Years_perc: float64\n",
      "24 Years_perc: float64\n",
      "25 Years_perc: float64\n",
      "26 Years_perc: float64\n",
      "27 Years_perc: float64\n",
      "28 Years_perc: float64\n",
      "29 Years_perc: float64\n",
      "30 Years_perc: float64\n",
      "31 Years_perc: float64\n",
      "32 Years_perc: float64\n",
      "33 Years_perc: float64\n",
      "34 Years_perc: float64\n",
      "35 Years_perc: float64\n",
      "36 Years_perc: float64\n",
      "37 Years_perc: float64\n",
      "38 Years_perc: float64\n",
      "39 Years_perc: float64\n",
      "40 Years_perc: float64\n",
      "41 Years_perc: float64\n",
      "42 Years_perc: float64\n",
      "43 Years_perc: float64\n",
      "44 Years_perc: float64\n",
      "45 Years_perc: float64\n",
      "46 Years_perc: float64\n",
      "47 Years_perc: float64\n",
      "48 Years_perc: float64\n",
      "49 Years_perc: float64\n",
      "50 Years_perc: float64\n",
      "51 Years_perc: float64\n",
      "52 Years_perc: float64\n",
      "53 Years_perc: float64\n",
      "54 Years_perc: float64\n",
      "55 Years_perc: float64\n",
      "56 Years_perc: float64\n",
      "57 Years_perc: float64\n",
      "58 Years_perc: float64\n",
      "59 Years_perc: float64\n",
      "60 Years_perc: float64\n",
      "61 Years_perc: float64\n",
      "62 Years_perc: float64\n",
      "63 Years_perc: float64\n",
      "64 Years_perc: float64\n",
      "65 Years_perc: float64\n",
      "66 Years_perc: float64\n",
      "67 Years_perc: float64\n",
      "68 Years_perc: float64\n",
      "69 Years_perc: float64\n",
      "70 Years_perc: float64\n",
      "71 Years_perc: float64\n",
      "72 Years_perc: float64\n",
      "73 Years_perc: float64\n",
      "74 Years_perc: float64\n",
      "75 Years_perc: float64\n",
      "76 Years_perc: float64\n",
      "77 Years_perc: float64\n",
      "78 Years_perc: float64\n",
      "79 Years_perc: float64\n",
      "80 Years_perc: float64\n",
      "81 Years_perc: float64\n",
      "82 Years_perc: float64\n",
      "83 Years_perc: float64\n",
      "84 Years_perc: float64\n",
      "85 Years_perc: float64\n",
      "86 Years_perc: float64\n",
      "87 Years_perc: float64\n",
      "88 Years_perc: float64\n",
      "89 Years_perc: float64\n",
      "90 Years_perc: float64\n",
      "91 Years_perc: float64\n",
      "92 Years_perc: float64\n",
      "93 Years_perc: float64\n",
      "94 Years_perc: float64\n",
      "95 Years_perc: float64\n",
      "96 Years_perc: float64\n",
      "97  Years_perc: float64\n",
      "98  Years_perc: float64\n",
      "99  Years_perc: float64\n",
      "100 to 104  Years_perc: float64\n",
      "105 to 109  Years_perc: float64\n",
      "110  Years and Over_perc: float64\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_female_aa\n",
      "Shape: (3221, 212)\n",
      "Dtypes:\n",
      "0: int32\n",
      "1: int32\n",
      "2: int32\n",
      "3: int32\n",
      "4: int32\n",
      "5: int32\n",
      "6: int32\n",
      "7: int32\n",
      "8: int32\n",
      "9: int32\n",
      "10: int32\n",
      "11: int32\n",
      "12: int32\n",
      "13: int32\n",
      "14: int32\n",
      "15: int32\n",
      "16: int32\n",
      "17: int32\n",
      "18: int32\n",
      "19: int32\n",
      "20: int32\n",
      "21: int32\n",
      "22: int32\n",
      "23: int32\n",
      "24: int32\n",
      "25: int32\n",
      "26: int32\n",
      "27: int32\n",
      "28: int32\n",
      "29: int32\n",
      "30: int32\n",
      "31: int32\n",
      "32: int32\n",
      "33: int32\n",
      "34: int32\n",
      "35: int32\n",
      "36: int32\n",
      "37: int32\n",
      "38: int32\n",
      "39: int32\n",
      "40: int32\n",
      "41: int32\n",
      "42: int32\n",
      "43: int32\n",
      "44: int32\n",
      "45: int32\n",
      "46: int32\n",
      "47: int32\n",
      "48: int32\n",
      "49: int32\n",
      "50: int32\n",
      "51: int32\n",
      "52: int32\n",
      "53: int32\n",
      "54: int32\n",
      "55: int32\n",
      "56: int32\n",
      "57: int32\n",
      "58: int32\n",
      "59: int32\n",
      "60: int32\n",
      "61: int32\n",
      "62: int32\n",
      "63: int32\n",
      "64: int32\n",
      "65: int32\n",
      "66: int32\n",
      "67: int32\n",
      "68: int32\n",
      "69: int32\n",
      "70: int32\n",
      "71: int32\n",
      "72: int32\n",
      "73: int32\n",
      "74: int32\n",
      "75: int32\n",
      "76: int32\n",
      "77: int32\n",
      "78: int32\n",
      "79: int32\n",
      "80: int32\n",
      "81: int32\n",
      "82: int32\n",
      "83: int32\n",
      "84: int32\n",
      "85: int32\n",
      "86: int32\n",
      "87: int32\n",
      "88: int32\n",
      "89: int32\n",
      "90: int32\n",
      "91: int32\n",
      "92: int32\n",
      "93: int32\n",
      "94: int32\n",
      "95: int32\n",
      "96: int32\n",
      "97: int32\n",
      "98: int32\n",
      "99: int32\n",
      "102: int32\n",
      "107: int32\n",
      "110: int32\n",
      "Average_Age: float64\n",
      "Under 1 Year_perc: float64\n",
      "1 Year_perc: float64\n",
      "2 Years_perc: float64\n",
      "3 Years_perc: float64\n",
      "4 Years_perc: float64\n",
      "5 Years_perc: float64\n",
      "6 Years_perc: float64\n",
      "7 Years_perc: float64\n",
      "8 Years_perc: float64\n",
      "9 Years_perc: float64\n",
      "10 Years_perc: float64\n",
      "11 Years_perc: float64\n",
      "12 Years_perc: float64\n",
      "13 Years_perc: float64\n",
      "14 Years_perc: float64\n",
      "15 Years_perc: float64\n",
      "16 Years_perc: float64\n",
      "17 Years_perc: float64\n",
      "18 Years_perc: float64\n",
      "19 Years_perc: float64\n",
      "20 Years_perc: float64\n",
      "21 Years_perc: float64\n",
      "22 Years_perc: float64\n",
      "23 Years_perc: float64\n",
      "24 Years_perc: float64\n",
      "25 Years_perc: float64\n",
      "26 Years_perc: float64\n",
      "27 Years_perc: float64\n",
      "28 Years_perc: float64\n",
      "29 Years_perc: float64\n",
      "30 Years_perc: float64\n",
      "31 Years_perc: float64\n",
      "32 Years_perc: float64\n",
      "33 Years_perc: float64\n",
      "34 Years_perc: float64\n",
      "35 Years_perc: float64\n",
      "36 Years_perc: float64\n",
      "37 Years_perc: float64\n",
      "38 Years_perc: float64\n",
      "39 Years_perc: float64\n",
      "40 Years_perc: float64\n",
      "41 Years_perc: float64\n",
      "42 Years_perc: float64\n",
      "43 Years_perc: float64\n",
      "44 Years_perc: float64\n",
      "45 Years_perc: float64\n",
      "46 Years_perc: float64\n",
      "47 Years_perc: float64\n",
      "48 Years_perc: float64\n",
      "49 Years_perc: float64\n",
      "50 Years_perc: float64\n",
      "51 Years_perc: float64\n",
      "52 Years_perc: float64\n",
      "53 Years_perc: float64\n",
      "54 Years_perc: float64\n",
      "55 Years_perc: float64\n",
      "56 Years_perc: float64\n",
      "57 Years_perc: float64\n",
      "58 Years_perc: float64\n",
      "59 Years_perc: float64\n",
      "60 Years_perc: float64\n",
      "61 Years_perc: float64\n",
      "62 Years_perc: float64\n",
      "63 Years_perc: float64\n",
      "64 Years_perc: float64\n",
      "65 Years_perc: float64\n",
      "66 Years_perc: float64\n",
      "67 Years_perc: float64\n",
      "68 Years_perc: float64\n",
      "69 Years_perc: float64\n",
      "70 Years_perc: float64\n",
      "71 Years_perc: float64\n",
      "72 Years_perc: float64\n",
      "73 Years_perc: float64\n",
      "74 Years_perc: float64\n",
      "75 Years_perc: float64\n",
      "76 Years_perc: float64\n",
      "77 Years_perc: float64\n",
      "78 Years_perc: float64\n",
      "79 Years_perc: float64\n",
      "80 Years_perc: float64\n",
      "81 Years_perc: float64\n",
      "82 Years_perc: float64\n",
      "83 Years_perc: float64\n",
      "84 Years_perc: float64\n",
      "85 Years_perc: float64\n",
      "86 Years_perc: float64\n",
      "87 Years_perc: float64\n",
      "88 Years_perc: float64\n",
      "89 Years_perc: float64\n",
      "90 Years_perc: float64\n",
      "91 Years_perc: float64\n",
      "92 Years_perc: float64\n",
      "93 Years_perc: float64\n",
      "94 Years_perc: float64\n",
      "95 Years_perc: float64\n",
      "96 Years_perc: float64\n",
      "97  Years_perc: float64\n",
      "98  Years_perc: float64\n",
      "99  Years_perc: float64\n",
      "100 to 104  Years_perc: float64\n",
      "105 to 109  Years_perc: float64\n",
      "110  Years and Over_perc: float64\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_male_nhop\n",
      "Shape: (3221, 212)\n",
      "Dtypes:\n",
      "0: int32\n",
      "1: int32\n",
      "2: int32\n",
      "3: int32\n",
      "4: int32\n",
      "5: int32\n",
      "6: int32\n",
      "7: int32\n",
      "8: int32\n",
      "9: int32\n",
      "10: int32\n",
      "11: int32\n",
      "12: int32\n",
      "13: int32\n",
      "14: int32\n",
      "15: int32\n",
      "16: int32\n",
      "17: int32\n",
      "18: int32\n",
      "19: int32\n",
      "20: int32\n",
      "21: int32\n",
      "22: int32\n",
      "23: int32\n",
      "24: int32\n",
      "25: int32\n",
      "26: int32\n",
      "27: int32\n",
      "28: int32\n",
      "29: int32\n",
      "30: int32\n",
      "31: int32\n",
      "32: int32\n",
      "33: int32\n",
      "34: int32\n",
      "35: int32\n",
      "36: int32\n",
      "37: int32\n",
      "38: int32\n",
      "39: int32\n",
      "40: int32\n",
      "41: int32\n",
      "42: int32\n",
      "43: int32\n",
      "44: int32\n",
      "45: int32\n",
      "46: int32\n",
      "47: int32\n",
      "48: int32\n",
      "49: int32\n",
      "50: int32\n",
      "51: int32\n",
      "52: int32\n",
      "53: int32\n",
      "54: int32\n",
      "55: int32\n",
      "56: int32\n",
      "57: int32\n",
      "58: int32\n",
      "59: int32\n",
      "60: int32\n",
      "61: int32\n",
      "62: int32\n",
      "63: int32\n",
      "64: int32\n",
      "65: int32\n",
      "66: int32\n",
      "67: int32\n",
      "68: int32\n",
      "69: int32\n",
      "70: int32\n",
      "71: int32\n",
      "72: int32\n",
      "73: int32\n",
      "74: int32\n",
      "75: int32\n",
      "76: int32\n",
      "77: int32\n",
      "78: int32\n",
      "79: int32\n",
      "80: int32\n",
      "81: int32\n",
      "82: int32\n",
      "83: int32\n",
      "84: int32\n",
      "85: int32\n",
      "86: int32\n",
      "87: int32\n",
      "88: int32\n",
      "89: int32\n",
      "90: int32\n",
      "91: int32\n",
      "92: int32\n",
      "93: int32\n",
      "94: int32\n",
      "95: int32\n",
      "96: int32\n",
      "97: int32\n",
      "98: int32\n",
      "99: int32\n",
      "102: int32\n",
      "107: int32\n",
      "110: int32\n",
      "Average_Age: float64\n",
      "Under 1 Year_perc: float64\n",
      "1 Year_perc: float64\n",
      "2 Years_perc: float64\n",
      "3 Years_perc: float64\n",
      "4 Years_perc: float64\n",
      "5 Years_perc: float64\n",
      "6 Years_perc: float64\n",
      "7 Years_perc: float64\n",
      "8 Years_perc: float64\n",
      "9 Years_perc: float64\n",
      "10 Years_perc: float64\n",
      "11 Years_perc: float64\n",
      "12 Years_perc: float64\n",
      "13 Years_perc: float64\n",
      "14 Years_perc: float64\n",
      "15 Years_perc: float64\n",
      "16 Years_perc: float64\n",
      "17 Years_perc: float64\n",
      "18 Years_perc: float64\n",
      "19 Years_perc: float64\n",
      "20 Years_perc: float64\n",
      "21 Years_perc: float64\n",
      "22 Years_perc: float64\n",
      "23 Years_perc: float64\n",
      "24 Years_perc: float64\n",
      "25 Years_perc: float64\n",
      "26 Years_perc: float64\n",
      "27 Years_perc: float64\n",
      "28 Years_perc: float64\n",
      "29 Years_perc: float64\n",
      "30 Years_perc: float64\n",
      "31 Years_perc: float64\n",
      "32 Years_perc: float64\n",
      "33 Years_perc: float64\n",
      "34 Years_perc: float64\n",
      "35 Years_perc: float64\n",
      "36 Years_perc: float64\n",
      "37 Years_perc: float64\n",
      "38 Years_perc: float64\n",
      "39 Years_perc: float64\n",
      "40 Years_perc: float64\n",
      "41 Years_perc: float64\n",
      "42 Years_perc: float64\n",
      "43 Years_perc: float64\n",
      "44 Years_perc: float64\n",
      "45 Years_perc: float64\n",
      "46 Years_perc: float64\n",
      "47 Years_perc: float64\n",
      "48 Years_perc: float64\n",
      "49 Years_perc: float64\n",
      "50 Years_perc: float64\n",
      "51 Years_perc: float64\n",
      "52 Years_perc: float64\n",
      "53 Years_perc: float64\n",
      "54 Years_perc: float64\n",
      "55 Years_perc: float64\n",
      "56 Years_perc: float64\n",
      "57 Years_perc: float64\n",
      "58 Years_perc: float64\n",
      "59 Years_perc: float64\n",
      "60 Years_perc: float64\n",
      "61 Years_perc: float64\n",
      "62 Years_perc: float64\n",
      "63 Years_perc: float64\n",
      "64 Years_perc: float64\n",
      "65 Years_perc: float64\n",
      "66 Years_perc: float64\n",
      "67 Years_perc: float64\n",
      "68 Years_perc: float64\n",
      "69 Years_perc: float64\n",
      "70 Years_perc: float64\n",
      "71 Years_perc: float64\n",
      "72 Years_perc: float64\n",
      "73 Years_perc: float64\n",
      "74 Years_perc: float64\n",
      "75 Years_perc: float64\n",
      "76 Years_perc: float64\n",
      "77 Years_perc: float64\n",
      "78 Years_perc: float64\n",
      "79 Years_perc: float64\n",
      "80 Years_perc: float64\n",
      "81 Years_perc: float64\n",
      "82 Years_perc: float64\n",
      "83 Years_perc: float64\n",
      "84 Years_perc: float64\n",
      "85 Years_perc: float64\n",
      "86 Years_perc: float64\n",
      "87 Years_perc: float64\n",
      "88 Years_perc: float64\n",
      "89 Years_perc: float64\n",
      "90 Years_perc: float64\n",
      "91 Years_perc: float64\n",
      "92 Years_perc: float64\n",
      "93 Years_perc: float64\n",
      "94 Years_perc: float64\n",
      "95 Years_perc: float64\n",
      "96 Years_perc: float64\n",
      "97  Years_perc: float64\n",
      "98  Years_perc: float64\n",
      "99  Years_perc: float64\n",
      "100 to 104  Years_perc: float64\n",
      "105 to 109  Years_perc: float64\n",
      "110  Years and Over_perc: float64\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_female_nhop\n",
      "Shape: (3221, 212)\n",
      "Dtypes:\n",
      "0: int32\n",
      "1: int32\n",
      "2: int32\n",
      "3: int32\n",
      "4: int32\n",
      "5: int32\n",
      "6: int32\n",
      "7: int32\n",
      "8: int32\n",
      "9: int32\n",
      "10: int32\n",
      "11: int32\n",
      "12: int32\n",
      "13: int32\n",
      "14: int32\n",
      "15: int32\n",
      "16: int32\n",
      "17: int32\n",
      "18: int32\n",
      "19: int32\n",
      "20: int32\n",
      "21: int32\n",
      "22: int32\n",
      "23: int32\n",
      "24: int32\n",
      "25: int32\n",
      "26: int32\n",
      "27: int32\n",
      "28: int32\n",
      "29: int32\n",
      "30: int32\n",
      "31: int32\n",
      "32: int32\n",
      "33: int32\n",
      "34: int32\n",
      "35: int32\n",
      "36: int32\n",
      "37: int32\n",
      "38: int32\n",
      "39: int32\n",
      "40: int32\n",
      "41: int32\n",
      "42: int32\n",
      "43: int32\n",
      "44: int32\n",
      "45: int32\n",
      "46: int32\n",
      "47: int32\n",
      "48: int32\n",
      "49: int32\n",
      "50: int32\n",
      "51: int32\n",
      "52: int32\n",
      "53: int32\n",
      "54: int32\n",
      "55: int32\n",
      "56: int32\n",
      "57: int32\n",
      "58: int32\n",
      "59: int32\n",
      "60: int32\n",
      "61: int32\n",
      "62: int32\n",
      "63: int32\n",
      "64: int32\n",
      "65: int32\n",
      "66: int32\n",
      "67: int32\n",
      "68: int32\n",
      "69: int32\n",
      "70: int32\n",
      "71: int32\n",
      "72: int32\n",
      "73: int32\n",
      "74: int32\n",
      "75: int32\n",
      "76: int32\n",
      "77: int32\n",
      "78: int32\n",
      "79: int32\n",
      "80: int32\n",
      "81: int32\n",
      "82: int32\n",
      "83: int32\n",
      "84: int32\n",
      "85: int32\n",
      "86: int32\n",
      "87: int32\n",
      "88: int32\n",
      "89: int32\n",
      "90: int32\n",
      "91: int32\n",
      "92: int32\n",
      "93: int32\n",
      "94: int32\n",
      "95: int32\n",
      "96: int32\n",
      "97: int32\n",
      "98: int32\n",
      "99: int32\n",
      "102: int32\n",
      "107: int32\n",
      "110: int32\n",
      "Average_Age: float64\n",
      "Under 1 Year_perc: float64\n",
      "1 Year_perc: float64\n",
      "2 Years_perc: float64\n",
      "3 Years_perc: float64\n",
      "4 Years_perc: float64\n",
      "5 Years_perc: float64\n",
      "6 Years_perc: float64\n",
      "7 Years_perc: float64\n",
      "8 Years_perc: float64\n",
      "9 Years_perc: float64\n",
      "10 Years_perc: float64\n",
      "11 Years_perc: float64\n",
      "12 Years_perc: float64\n",
      "13 Years_perc: float64\n",
      "14 Years_perc: float64\n",
      "15 Years_perc: float64\n",
      "16 Years_perc: float64\n",
      "17 Years_perc: float64\n",
      "18 Years_perc: float64\n",
      "19 Years_perc: float64\n",
      "20 Years_perc: float64\n",
      "21 Years_perc: float64\n",
      "22 Years_perc: float64\n",
      "23 Years_perc: float64\n",
      "24 Years_perc: float64\n",
      "25 Years_perc: float64\n",
      "26 Years_perc: float64\n",
      "27 Years_perc: float64\n",
      "28 Years_perc: float64\n",
      "29 Years_perc: float64\n",
      "30 Years_perc: float64\n",
      "31 Years_perc: float64\n",
      "32 Years_perc: float64\n",
      "33 Years_perc: float64\n",
      "34 Years_perc: float64\n",
      "35 Years_perc: float64\n",
      "36 Years_perc: float64\n",
      "37 Years_perc: float64\n",
      "38 Years_perc: float64\n",
      "39 Years_perc: float64\n",
      "40 Years_perc: float64\n",
      "41 Years_perc: float64\n",
      "42 Years_perc: float64\n",
      "43 Years_perc: float64\n",
      "44 Years_perc: float64\n",
      "45 Years_perc: float64\n",
      "46 Years_perc: float64\n",
      "47 Years_perc: float64\n",
      "48 Years_perc: float64\n",
      "49 Years_perc: float64\n",
      "50 Years_perc: float64\n",
      "51 Years_perc: float64\n",
      "52 Years_perc: float64\n",
      "53 Years_perc: float64\n",
      "54 Years_perc: float64\n",
      "55 Years_perc: float64\n",
      "56 Years_perc: float64\n",
      "57 Years_perc: float64\n",
      "58 Years_perc: float64\n",
      "59 Years_perc: float64\n",
      "60 Years_perc: float64\n",
      "61 Years_perc: float64\n",
      "62 Years_perc: float64\n",
      "63 Years_perc: float64\n",
      "64 Years_perc: float64\n",
      "65 Years_perc: float64\n",
      "66 Years_perc: float64\n",
      "67 Years_perc: float64\n",
      "68 Years_perc: float64\n",
      "69 Years_perc: float64\n",
      "70 Years_perc: float64\n",
      "71 Years_perc: float64\n",
      "72 Years_perc: float64\n",
      "73 Years_perc: float64\n",
      "74 Years_perc: float64\n",
      "75 Years_perc: float64\n",
      "76 Years_perc: float64\n",
      "77 Years_perc: float64\n",
      "78 Years_perc: float64\n",
      "79 Years_perc: float64\n",
      "80 Years_perc: float64\n",
      "81 Years_perc: float64\n",
      "82 Years_perc: float64\n",
      "83 Years_perc: float64\n",
      "84 Years_perc: float64\n",
      "85 Years_perc: float64\n",
      "86 Years_perc: float64\n",
      "87 Years_perc: float64\n",
      "88 Years_perc: float64\n",
      "89 Years_perc: float64\n",
      "90 Years_perc: float64\n",
      "91 Years_perc: float64\n",
      "92 Years_perc: float64\n",
      "93 Years_perc: float64\n",
      "94 Years_perc: float64\n",
      "95 Years_perc: float64\n",
      "96 Years_perc: float64\n",
      "97  Years_perc: float64\n",
      "98  Years_perc: float64\n",
      "99  Years_perc: float64\n",
      "100 to 104  Years_perc: float64\n",
      "105 to 109  Years_perc: float64\n",
      "110  Years and Over_perc: float64\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_male_sor\n",
      "Shape: (3221, 212)\n",
      "Dtypes:\n",
      "0: int32\n",
      "1: int32\n",
      "2: int32\n",
      "3: int32\n",
      "4: int32\n",
      "5: int32\n",
      "6: int32\n",
      "7: int32\n",
      "8: int32\n",
      "9: int32\n",
      "10: int32\n",
      "11: int32\n",
      "12: int32\n",
      "13: int32\n",
      "14: int32\n",
      "15: int32\n",
      "16: int32\n",
      "17: int32\n",
      "18: int32\n",
      "19: int32\n",
      "20: int32\n",
      "21: int32\n",
      "22: int32\n",
      "23: int32\n",
      "24: int32\n",
      "25: int32\n",
      "26: int32\n",
      "27: int32\n",
      "28: int32\n",
      "29: int32\n",
      "30: int32\n",
      "31: int32\n",
      "32: int32\n",
      "33: int32\n",
      "34: int32\n",
      "35: int32\n",
      "36: int32\n",
      "37: int32\n",
      "38: int32\n",
      "39: int32\n",
      "40: int32\n",
      "41: int32\n",
      "42: int32\n",
      "43: int32\n",
      "44: int32\n",
      "45: int32\n",
      "46: int32\n",
      "47: int32\n",
      "48: int32\n",
      "49: int32\n",
      "50: int32\n",
      "51: int32\n",
      "52: int32\n",
      "53: int32\n",
      "54: int32\n",
      "55: int32\n",
      "56: int32\n",
      "57: int32\n",
      "58: int32\n",
      "59: int32\n",
      "60: int32\n",
      "61: int32\n",
      "62: int32\n",
      "63: int32\n",
      "64: int32\n",
      "65: int32\n",
      "66: int32\n",
      "67: int32\n",
      "68: int32\n",
      "69: int32\n",
      "70: int32\n",
      "71: int32\n",
      "72: int32\n",
      "73: int32\n",
      "74: int32\n",
      "75: int32\n",
      "76: int32\n",
      "77: int32\n",
      "78: int32\n",
      "79: int32\n",
      "80: int32\n",
      "81: int32\n",
      "82: int32\n",
      "83: int32\n",
      "84: int32\n",
      "85: int32\n",
      "86: int32\n",
      "87: int32\n",
      "88: int32\n",
      "89: int32\n",
      "90: int32\n",
      "91: int32\n",
      "92: int32\n",
      "93: int32\n",
      "94: int32\n",
      "95: int32\n",
      "96: int32\n",
      "97: int32\n",
      "98: int32\n",
      "99: int32\n",
      "102: int32\n",
      "107: int32\n",
      "110: int32\n",
      "Average_Age: float64\n",
      "Under 1 Year_perc: float64\n",
      "1 Year_perc: float64\n",
      "2 Years_perc: float64\n",
      "3 Years_perc: float64\n",
      "4 Years_perc: float64\n",
      "5 Years_perc: float64\n",
      "6 Years_perc: float64\n",
      "7 Years_perc: float64\n",
      "8 Years_perc: float64\n",
      "9 Years_perc: float64\n",
      "10 Years_perc: float64\n",
      "11 Years_perc: float64\n",
      "12 Years_perc: float64\n",
      "13 Years_perc: float64\n",
      "14 Years_perc: float64\n",
      "15 Years_perc: float64\n",
      "16 Years_perc: float64\n",
      "17 Years_perc: float64\n",
      "18 Years_perc: float64\n",
      "19 Years_perc: float64\n",
      "20 Years_perc: float64\n",
      "21 Years_perc: float64\n",
      "22 Years_perc: float64\n",
      "23 Years_perc: float64\n",
      "24 Years_perc: float64\n",
      "25 Years_perc: float64\n",
      "26 Years_perc: float64\n",
      "27 Years_perc: float64\n",
      "28 Years_perc: float64\n",
      "29 Years_perc: float64\n",
      "30 Years_perc: float64\n",
      "31 Years_perc: float64\n",
      "32 Years_perc: float64\n",
      "33 Years_perc: float64\n",
      "34 Years_perc: float64\n",
      "35 Years_perc: float64\n",
      "36 Years_perc: float64\n",
      "37 Years_perc: float64\n",
      "38 Years_perc: float64\n",
      "39 Years_perc: float64\n",
      "40 Years_perc: float64\n",
      "41 Years_perc: float64\n",
      "42 Years_perc: float64\n",
      "43 Years_perc: float64\n",
      "44 Years_perc: float64\n",
      "45 Years_perc: float64\n",
      "46 Years_perc: float64\n",
      "47 Years_perc: float64\n",
      "48 Years_perc: float64\n",
      "49 Years_perc: float64\n",
      "50 Years_perc: float64\n",
      "51 Years_perc: float64\n",
      "52 Years_perc: float64\n",
      "53 Years_perc: float64\n",
      "54 Years_perc: float64\n",
      "55 Years_perc: float64\n",
      "56 Years_perc: float64\n",
      "57 Years_perc: float64\n",
      "58 Years_perc: float64\n",
      "59 Years_perc: float64\n",
      "60 Years_perc: float64\n",
      "61 Years_perc: float64\n",
      "62 Years_perc: float64\n",
      "63 Years_perc: float64\n",
      "64 Years_perc: float64\n",
      "65 Years_perc: float64\n",
      "66 Years_perc: float64\n",
      "67 Years_perc: float64\n",
      "68 Years_perc: float64\n",
      "69 Years_perc: float64\n",
      "70 Years_perc: float64\n",
      "71 Years_perc: float64\n",
      "72 Years_perc: float64\n",
      "73 Years_perc: float64\n",
      "74 Years_perc: float64\n",
      "75 Years_perc: float64\n",
      "76 Years_perc: float64\n",
      "77 Years_perc: float64\n",
      "78 Years_perc: float64\n",
      "79 Years_perc: float64\n",
      "80 Years_perc: float64\n",
      "81 Years_perc: float64\n",
      "82 Years_perc: float64\n",
      "83 Years_perc: float64\n",
      "84 Years_perc: float64\n",
      "85 Years_perc: float64\n",
      "86 Years_perc: float64\n",
      "87 Years_perc: float64\n",
      "88 Years_perc: float64\n",
      "89 Years_perc: float64\n",
      "90 Years_perc: float64\n",
      "91 Years_perc: float64\n",
      "92 Years_perc: float64\n",
      "93 Years_perc: float64\n",
      "94 Years_perc: float64\n",
      "95 Years_perc: float64\n",
      "96 Years_perc: float64\n",
      "97  Years_perc: float64\n",
      "98  Years_perc: float64\n",
      "99  Years_perc: float64\n",
      "100 to 104  Years_perc: float64\n",
      "105 to 109  Years_perc: float64\n",
      "110  Years and Over_perc: float64\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_female_sor\n",
      "Shape: (3221, 212)\n",
      "Dtypes:\n",
      "0: int32\n",
      "1: int32\n",
      "2: int32\n",
      "3: int32\n",
      "4: int32\n",
      "5: int32\n",
      "6: int32\n",
      "7: int32\n",
      "8: int32\n",
      "9: int32\n",
      "10: int32\n",
      "11: int32\n",
      "12: int32\n",
      "13: int32\n",
      "14: int32\n",
      "15: int32\n",
      "16: int32\n",
      "17: int32\n",
      "18: int32\n",
      "19: int32\n",
      "20: int32\n",
      "21: int32\n",
      "22: int32\n",
      "23: int32\n",
      "24: int32\n",
      "25: int32\n",
      "26: int32\n",
      "27: int32\n",
      "28: int32\n",
      "29: int32\n",
      "30: int32\n",
      "31: int32\n",
      "32: int32\n",
      "33: int32\n",
      "34: int32\n",
      "35: int32\n",
      "36: int32\n",
      "37: int32\n",
      "38: int32\n",
      "39: int32\n",
      "40: int32\n",
      "41: int32\n",
      "42: int32\n",
      "43: int32\n",
      "44: int32\n",
      "45: int32\n",
      "46: int32\n",
      "47: int32\n",
      "48: int32\n",
      "49: int32\n",
      "50: int32\n",
      "51: int32\n",
      "52: int32\n",
      "53: int32\n",
      "54: int32\n",
      "55: int32\n",
      "56: int32\n",
      "57: int32\n",
      "58: int32\n",
      "59: int32\n",
      "60: int32\n",
      "61: int32\n",
      "62: int32\n",
      "63: int32\n",
      "64: int32\n",
      "65: int32\n",
      "66: int32\n",
      "67: int32\n",
      "68: int32\n",
      "69: int32\n",
      "70: int32\n",
      "71: int32\n",
      "72: int32\n",
      "73: int32\n",
      "74: int32\n",
      "75: int32\n",
      "76: int32\n",
      "77: int32\n",
      "78: int32\n",
      "79: int32\n",
      "80: int32\n",
      "81: int32\n",
      "82: int32\n",
      "83: int32\n",
      "84: int32\n",
      "85: int32\n",
      "86: int32\n",
      "87: int32\n",
      "88: int32\n",
      "89: int32\n",
      "90: int32\n",
      "91: int32\n",
      "92: int32\n",
      "93: int32\n",
      "94: int32\n",
      "95: int32\n",
      "96: int32\n",
      "97: int32\n",
      "98: int32\n",
      "99: int32\n",
      "102: int32\n",
      "107: int32\n",
      "110: int32\n",
      "Average_Age: float64\n",
      "Under 1 Year_perc: float64\n",
      "1 Year_perc: float64\n",
      "2 Years_perc: float64\n",
      "3 Years_perc: float64\n",
      "4 Years_perc: float64\n",
      "5 Years_perc: float64\n",
      "6 Years_perc: float64\n",
      "7 Years_perc: float64\n",
      "8 Years_perc: float64\n",
      "9 Years_perc: float64\n",
      "10 Years_perc: float64\n",
      "11 Years_perc: float64\n",
      "12 Years_perc: float64\n",
      "13 Years_perc: float64\n",
      "14 Years_perc: float64\n",
      "15 Years_perc: float64\n",
      "16 Years_perc: float64\n",
      "17 Years_perc: float64\n",
      "18 Years_perc: float64\n",
      "19 Years_perc: float64\n",
      "20 Years_perc: float64\n",
      "21 Years_perc: float64\n",
      "22 Years_perc: float64\n",
      "23 Years_perc: float64\n",
      "24 Years_perc: float64\n",
      "25 Years_perc: float64\n",
      "26 Years_perc: float64\n",
      "27 Years_perc: float64\n",
      "28 Years_perc: float64\n",
      "29 Years_perc: float64\n",
      "30 Years_perc: float64\n",
      "31 Years_perc: float64\n",
      "32 Years_perc: float64\n",
      "33 Years_perc: float64\n",
      "34 Years_perc: float64\n",
      "35 Years_perc: float64\n",
      "36 Years_perc: float64\n",
      "37 Years_perc: float64\n",
      "38 Years_perc: float64\n",
      "39 Years_perc: float64\n",
      "40 Years_perc: float64\n",
      "41 Years_perc: float64\n",
      "42 Years_perc: float64\n",
      "43 Years_perc: float64\n",
      "44 Years_perc: float64\n",
      "45 Years_perc: float64\n",
      "46 Years_perc: float64\n",
      "47 Years_perc: float64\n",
      "48 Years_perc: float64\n",
      "49 Years_perc: float64\n",
      "50 Years_perc: float64\n",
      "51 Years_perc: float64\n",
      "52 Years_perc: float64\n",
      "53 Years_perc: float64\n",
      "54 Years_perc: float64\n",
      "55 Years_perc: float64\n",
      "56 Years_perc: float64\n",
      "57 Years_perc: float64\n",
      "58 Years_perc: float64\n",
      "59 Years_perc: float64\n",
      "60 Years_perc: float64\n",
      "61 Years_perc: float64\n",
      "62 Years_perc: float64\n",
      "63 Years_perc: float64\n",
      "64 Years_perc: float64\n",
      "65 Years_perc: float64\n",
      "66 Years_perc: float64\n",
      "67 Years_perc: float64\n",
      "68 Years_perc: float64\n",
      "69 Years_perc: float64\n",
      "70 Years_perc: float64\n",
      "71 Years_perc: float64\n",
      "72 Years_perc: float64\n",
      "73 Years_perc: float64\n",
      "74 Years_perc: float64\n",
      "75 Years_perc: float64\n",
      "76 Years_perc: float64\n",
      "77 Years_perc: float64\n",
      "78 Years_perc: float64\n",
      "79 Years_perc: float64\n",
      "80 Years_perc: float64\n",
      "81 Years_perc: float64\n",
      "82 Years_perc: float64\n",
      "83 Years_perc: float64\n",
      "84 Years_perc: float64\n",
      "85 Years_perc: float64\n",
      "86 Years_perc: float64\n",
      "87 Years_perc: float64\n",
      "88 Years_perc: float64\n",
      "89 Years_perc: float64\n",
      "90 Years_perc: float64\n",
      "91 Years_perc: float64\n",
      "92 Years_perc: float64\n",
      "93 Years_perc: float64\n",
      "94 Years_perc: float64\n",
      "95 Years_perc: float64\n",
      "96 Years_perc: float64\n",
      "97  Years_perc: float64\n",
      "98  Years_perc: float64\n",
      "99  Years_perc: float64\n",
      "100 to 104  Years_perc: float64\n",
      "105 to 109  Years_perc: float64\n",
      "110  Years and Over_perc: float64\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_male_tom\n",
      "Shape: (3221, 212)\n",
      "Dtypes:\n",
      "0: int32\n",
      "1: int32\n",
      "2: int32\n",
      "3: int32\n",
      "4: int32\n",
      "5: int32\n",
      "6: int32\n",
      "7: int32\n",
      "8: int32\n",
      "9: int32\n",
      "10: int32\n",
      "11: int32\n",
      "12: int32\n",
      "13: int32\n",
      "14: int32\n",
      "15: int32\n",
      "16: int32\n",
      "17: int32\n",
      "18: int32\n",
      "19: int32\n",
      "20: int32\n",
      "21: int32\n",
      "22: int32\n",
      "23: int32\n",
      "24: int32\n",
      "25: int32\n",
      "26: int32\n",
      "27: int32\n",
      "28: int32\n",
      "29: int32\n",
      "30: int32\n",
      "31: int32\n",
      "32: int32\n",
      "33: int32\n",
      "34: int32\n",
      "35: int32\n",
      "36: int32\n",
      "37: int32\n",
      "38: int32\n",
      "39: int32\n",
      "40: int32\n",
      "41: int32\n",
      "42: int32\n",
      "43: int32\n",
      "44: int32\n",
      "45: int32\n",
      "46: int32\n",
      "47: int32\n",
      "48: int32\n",
      "49: int32\n",
      "50: int32\n",
      "51: int32\n",
      "52: int32\n",
      "53: int32\n",
      "54: int32\n",
      "55: int32\n",
      "56: int32\n",
      "57: int32\n",
      "58: int32\n",
      "59: int32\n",
      "60: int32\n",
      "61: int32\n",
      "62: int32\n",
      "63: int32\n",
      "64: int32\n",
      "65: int32\n",
      "66: int32\n",
      "67: int32\n",
      "68: int32\n",
      "69: int32\n",
      "70: int32\n",
      "71: int32\n",
      "72: int32\n",
      "73: int32\n",
      "74: int32\n",
      "75: int32\n",
      "76: int32\n",
      "77: int32\n",
      "78: int32\n",
      "79: int32\n",
      "80: int32\n",
      "81: int32\n",
      "82: int32\n",
      "83: int32\n",
      "84: int32\n",
      "85: int32\n",
      "86: int32\n",
      "87: int32\n",
      "88: int32\n",
      "89: int32\n",
      "90: int32\n",
      "91: int32\n",
      "92: int32\n",
      "93: int32\n",
      "94: int32\n",
      "95: int32\n",
      "96: int32\n",
      "97: int32\n",
      "98: int32\n",
      "99: int32\n",
      "102: int32\n",
      "107: int32\n",
      "110: int32\n",
      "Average_Age: float64\n",
      "Under 1 Year_perc: float64\n",
      "1 Year_perc: float64\n",
      "2 Years_perc: float64\n",
      "3 Years_perc: float64\n",
      "4 Years_perc: float64\n",
      "5 Years_perc: float64\n",
      "6 Years_perc: float64\n",
      "7 Years_perc: float64\n",
      "8 Years_perc: float64\n",
      "9 Years_perc: float64\n",
      "10 Years_perc: float64\n",
      "11 Years_perc: float64\n",
      "12 Years_perc: float64\n",
      "13 Years_perc: float64\n",
      "14 Years_perc: float64\n",
      "15 Years_perc: float64\n",
      "16 Years_perc: float64\n",
      "17 Years_perc: float64\n",
      "18 Years_perc: float64\n",
      "19 Years_perc: float64\n",
      "20 Years_perc: float64\n",
      "21 Years_perc: float64\n",
      "22 Years_perc: float64\n",
      "23 Years_perc: float64\n",
      "24 Years_perc: float64\n",
      "25 Years_perc: float64\n",
      "26 Years_perc: float64\n",
      "27 Years_perc: float64\n",
      "28 Years_perc: float64\n",
      "29 Years_perc: float64\n",
      "30 Years_perc: float64\n",
      "31 Years_perc: float64\n",
      "32 Years_perc: float64\n",
      "33 Years_perc: float64\n",
      "34 Years_perc: float64\n",
      "35 Years_perc: float64\n",
      "36 Years_perc: float64\n",
      "37 Years_perc: float64\n",
      "38 Years_perc: float64\n",
      "39 Years_perc: float64\n",
      "40 Years_perc: float64\n",
      "41 Years_perc: float64\n",
      "42 Years_perc: float64\n",
      "43 Years_perc: float64\n",
      "44 Years_perc: float64\n",
      "45 Years_perc: float64\n",
      "46 Years_perc: float64\n",
      "47 Years_perc: float64\n",
      "48 Years_perc: float64\n",
      "49 Years_perc: float64\n",
      "50 Years_perc: float64\n",
      "51 Years_perc: float64\n",
      "52 Years_perc: float64\n",
      "53 Years_perc: float64\n",
      "54 Years_perc: float64\n",
      "55 Years_perc: float64\n",
      "56 Years_perc: float64\n",
      "57 Years_perc: float64\n",
      "58 Years_perc: float64\n",
      "59 Years_perc: float64\n",
      "60 Years_perc: float64\n",
      "61 Years_perc: float64\n",
      "62 Years_perc: float64\n",
      "63 Years_perc: float64\n",
      "64 Years_perc: float64\n",
      "65 Years_perc: float64\n",
      "66 Years_perc: float64\n",
      "67 Years_perc: float64\n",
      "68 Years_perc: float64\n",
      "69 Years_perc: float64\n",
      "70 Years_perc: float64\n",
      "71 Years_perc: float64\n",
      "72 Years_perc: float64\n",
      "73 Years_perc: float64\n",
      "74 Years_perc: float64\n",
      "75 Years_perc: float64\n",
      "76 Years_perc: float64\n",
      "77 Years_perc: float64\n",
      "78 Years_perc: float64\n",
      "79 Years_perc: float64\n",
      "80 Years_perc: float64\n",
      "81 Years_perc: float64\n",
      "82 Years_perc: float64\n",
      "83 Years_perc: float64\n",
      "84 Years_perc: float64\n",
      "85 Years_perc: float64\n",
      "86 Years_perc: float64\n",
      "87 Years_perc: float64\n",
      "88 Years_perc: float64\n",
      "89 Years_perc: float64\n",
      "90 Years_perc: float64\n",
      "91 Years_perc: float64\n",
      "92 Years_perc: float64\n",
      "93 Years_perc: float64\n",
      "94 Years_perc: float64\n",
      "95 Years_perc: float64\n",
      "96 Years_perc: float64\n",
      "97  Years_perc: float64\n",
      "98  Years_perc: float64\n",
      "99  Years_perc: float64\n",
      "100 to 104  Years_perc: float64\n",
      "105 to 109  Years_perc: float64\n",
      "110  Years and Over_perc: float64\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_female_tom\n",
      "Shape: (3221, 212)\n",
      "Dtypes:\n",
      "0: int32\n",
      "1: int32\n",
      "2: int32\n",
      "3: int32\n",
      "4: int32\n",
      "5: int32\n",
      "6: int32\n",
      "7: int32\n",
      "8: int32\n",
      "9: int32\n",
      "10: int32\n",
      "11: int32\n",
      "12: int32\n",
      "13: int32\n",
      "14: int32\n",
      "15: int32\n",
      "16: int32\n",
      "17: int32\n",
      "18: int32\n",
      "19: int32\n",
      "20: int32\n",
      "21: int32\n",
      "22: int32\n",
      "23: int32\n",
      "24: int32\n",
      "25: int32\n",
      "26: int32\n",
      "27: int32\n",
      "28: int32\n",
      "29: int32\n",
      "30: int32\n",
      "31: int32\n",
      "32: int32\n",
      "33: int32\n",
      "34: int32\n",
      "35: int32\n",
      "36: int32\n",
      "37: int32\n",
      "38: int32\n",
      "39: int32\n",
      "40: int32\n",
      "41: int32\n",
      "42: int32\n",
      "43: int32\n",
      "44: int32\n",
      "45: int32\n",
      "46: int32\n",
      "47: int32\n",
      "48: int32\n",
      "49: int32\n",
      "50: int32\n",
      "51: int32\n",
      "52: int32\n",
      "53: int32\n",
      "54: int32\n",
      "55: int32\n",
      "56: int32\n",
      "57: int32\n",
      "58: int32\n",
      "59: int32\n",
      "60: int32\n",
      "61: int32\n",
      "62: int32\n",
      "63: int32\n",
      "64: int32\n",
      "65: int32\n",
      "66: int32\n",
      "67: int32\n",
      "68: int32\n",
      "69: int32\n",
      "70: int32\n",
      "71: int32\n",
      "72: int32\n",
      "73: int32\n",
      "74: int32\n",
      "75: int32\n",
      "76: int32\n",
      "77: int32\n",
      "78: int32\n",
      "79: int32\n",
      "80: int32\n",
      "81: int32\n",
      "82: int32\n",
      "83: int32\n",
      "84: int32\n",
      "85: int32\n",
      "86: int32\n",
      "87: int32\n",
      "88: int32\n",
      "89: int32\n",
      "90: int32\n",
      "91: int32\n",
      "92: int32\n",
      "93: int32\n",
      "94: int32\n",
      "95: int32\n",
      "96: int32\n",
      "97: int32\n",
      "98: int32\n",
      "99: int32\n",
      "102: int32\n",
      "107: int32\n",
      "110: int32\n",
      "Average_Age: float64\n",
      "Under 1 Year_perc: float64\n",
      "1 Year_perc: float64\n",
      "2 Years_perc: float64\n",
      "3 Years_perc: float64\n",
      "4 Years_perc: float64\n",
      "5 Years_perc: float64\n",
      "6 Years_perc: float64\n",
      "7 Years_perc: float64\n",
      "8 Years_perc: float64\n",
      "9 Years_perc: float64\n",
      "10 Years_perc: float64\n",
      "11 Years_perc: float64\n",
      "12 Years_perc: float64\n",
      "13 Years_perc: float64\n",
      "14 Years_perc: float64\n",
      "15 Years_perc: float64\n",
      "16 Years_perc: float64\n",
      "17 Years_perc: float64\n",
      "18 Years_perc: float64\n",
      "19 Years_perc: float64\n",
      "20 Years_perc: float64\n",
      "21 Years_perc: float64\n",
      "22 Years_perc: float64\n",
      "23 Years_perc: float64\n",
      "24 Years_perc: float64\n",
      "25 Years_perc: float64\n",
      "26 Years_perc: float64\n",
      "27 Years_perc: float64\n",
      "28 Years_perc: float64\n",
      "29 Years_perc: float64\n",
      "30 Years_perc: float64\n",
      "31 Years_perc: float64\n",
      "32 Years_perc: float64\n",
      "33 Years_perc: float64\n",
      "34 Years_perc: float64\n",
      "35 Years_perc: float64\n",
      "36 Years_perc: float64\n",
      "37 Years_perc: float64\n",
      "38 Years_perc: float64\n",
      "39 Years_perc: float64\n",
      "40 Years_perc: float64\n",
      "41 Years_perc: float64\n",
      "42 Years_perc: float64\n",
      "43 Years_perc: float64\n",
      "44 Years_perc: float64\n",
      "45 Years_perc: float64\n",
      "46 Years_perc: float64\n",
      "47 Years_perc: float64\n",
      "48 Years_perc: float64\n",
      "49 Years_perc: float64\n",
      "50 Years_perc: float64\n",
      "51 Years_perc: float64\n",
      "52 Years_perc: float64\n",
      "53 Years_perc: float64\n",
      "54 Years_perc: float64\n",
      "55 Years_perc: float64\n",
      "56 Years_perc: float64\n",
      "57 Years_perc: float64\n",
      "58 Years_perc: float64\n",
      "59 Years_perc: float64\n",
      "60 Years_perc: float64\n",
      "61 Years_perc: float64\n",
      "62 Years_perc: float64\n",
      "63 Years_perc: float64\n",
      "64 Years_perc: float64\n",
      "65 Years_perc: float64\n",
      "66 Years_perc: float64\n",
      "67 Years_perc: float64\n",
      "68 Years_perc: float64\n",
      "69 Years_perc: float64\n",
      "70 Years_perc: float64\n",
      "71 Years_perc: float64\n",
      "72 Years_perc: float64\n",
      "73 Years_perc: float64\n",
      "74 Years_perc: float64\n",
      "75 Years_perc: float64\n",
      "76 Years_perc: float64\n",
      "77 Years_perc: float64\n",
      "78 Years_perc: float64\n",
      "79 Years_perc: float64\n",
      "80 Years_perc: float64\n",
      "81 Years_perc: float64\n",
      "82 Years_perc: float64\n",
      "83 Years_perc: float64\n",
      "84 Years_perc: float64\n",
      "85 Years_perc: float64\n",
      "86 Years_perc: float64\n",
      "87 Years_perc: float64\n",
      "88 Years_perc: float64\n",
      "89 Years_perc: float64\n",
      "90 Years_perc: float64\n",
      "91 Years_perc: float64\n",
      "92 Years_perc: float64\n",
      "93 Years_perc: float64\n",
      "94 Years_perc: float64\n",
      "95 Years_perc: float64\n",
      "96 Years_perc: float64\n",
      "97  Years_perc: float64\n",
      "98  Years_perc: float64\n",
      "99  Years_perc: float64\n",
      "100 to 104  Years_perc: float64\n",
      "105 to 109  Years_perc: float64\n",
      "110  Years and Over_perc: float64\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_male_hol\n",
      "Shape: (3221, 212)\n",
      "Dtypes:\n",
      "0: int32\n",
      "1: int32\n",
      "2: int32\n",
      "3: int32\n",
      "4: int32\n",
      "5: int32\n",
      "6: int32\n",
      "7: int32\n",
      "8: int32\n",
      "9: int32\n",
      "10: int32\n",
      "11: int32\n",
      "12: int32\n",
      "13: int32\n",
      "14: int32\n",
      "15: int32\n",
      "16: int32\n",
      "17: int32\n",
      "18: int32\n",
      "19: int32\n",
      "20: int32\n",
      "21: int32\n",
      "22: int32\n",
      "23: int32\n",
      "24: int32\n",
      "25: int32\n",
      "26: int32\n",
      "27: int32\n",
      "28: int32\n",
      "29: int32\n",
      "30: int32\n",
      "31: int32\n",
      "32: int32\n",
      "33: int32\n",
      "34: int32\n",
      "35: int32\n",
      "36: int32\n",
      "37: int32\n",
      "38: int32\n",
      "39: int32\n",
      "40: int32\n",
      "41: int32\n",
      "42: int32\n",
      "43: int32\n",
      "44: int32\n",
      "45: int32\n",
      "46: int32\n",
      "47: int32\n",
      "48: int32\n",
      "49: int32\n",
      "50: int32\n",
      "51: int32\n",
      "52: int32\n",
      "53: int32\n",
      "54: int32\n",
      "55: int32\n",
      "56: int32\n",
      "57: int32\n",
      "58: int32\n",
      "59: int32\n",
      "60: int32\n",
      "61: int32\n",
      "62: int32\n",
      "63: int32\n",
      "64: int32\n",
      "65: int32\n",
      "66: int32\n",
      "67: int32\n",
      "68: int32\n",
      "69: int32\n",
      "70: int32\n",
      "71: int32\n",
      "72: int32\n",
      "73: int32\n",
      "74: int32\n",
      "75: int32\n",
      "76: int32\n",
      "77: int32\n",
      "78: int32\n",
      "79: int32\n",
      "80: int32\n",
      "81: int32\n",
      "82: int32\n",
      "83: int32\n",
      "84: int32\n",
      "85: int32\n",
      "86: int32\n",
      "87: int32\n",
      "88: int32\n",
      "89: int32\n",
      "90: int32\n",
      "91: int32\n",
      "92: int32\n",
      "93: int32\n",
      "94: int32\n",
      "95: int32\n",
      "96: int32\n",
      "97: int32\n",
      "98: int32\n",
      "99: int32\n",
      "102: int32\n",
      "107: int32\n",
      "110: int32\n",
      "Average_Age: float64\n",
      "Under 1 Year_perc: float64\n",
      "1 Year_perc: float64\n",
      "2 Years_perc: float64\n",
      "3 Years_perc: float64\n",
      "4 Years_perc: float64\n",
      "5 Years_perc: float64\n",
      "6 Years_perc: float64\n",
      "7 Years_perc: float64\n",
      "8 Years_perc: float64\n",
      "9 Years_perc: float64\n",
      "10 Years_perc: float64\n",
      "11 Years_perc: float64\n",
      "12 Years_perc: float64\n",
      "13 Years_perc: float64\n",
      "14 Years_perc: float64\n",
      "15 Years_perc: float64\n",
      "16 Years_perc: float64\n",
      "17 Years_perc: float64\n",
      "18 Years_perc: float64\n",
      "19 Years_perc: float64\n",
      "20 Years_perc: float64\n",
      "21 Years_perc: float64\n",
      "22 Years_perc: float64\n",
      "23 Years_perc: float64\n",
      "24 Years_perc: float64\n",
      "25 Years_perc: float64\n",
      "26 Years_perc: float64\n",
      "27 Years_perc: float64\n",
      "28 Years_perc: float64\n",
      "29 Years_perc: float64\n",
      "30 Years_perc: float64\n",
      "31 Years_perc: float64\n",
      "32 Years_perc: float64\n",
      "33 Years_perc: float64\n",
      "34 Years_perc: float64\n",
      "35 Years_perc: float64\n",
      "36 Years_perc: float64\n",
      "37 Years_perc: float64\n",
      "38 Years_perc: float64\n",
      "39 Years_perc: float64\n",
      "40 Years_perc: float64\n",
      "41 Years_perc: float64\n",
      "42 Years_perc: float64\n",
      "43 Years_perc: float64\n",
      "44 Years_perc: float64\n",
      "45 Years_perc: float64\n",
      "46 Years_perc: float64\n",
      "47 Years_perc: float64\n",
      "48 Years_perc: float64\n",
      "49 Years_perc: float64\n",
      "50 Years_perc: float64\n",
      "51 Years_perc: float64\n",
      "52 Years_perc: float64\n",
      "53 Years_perc: float64\n",
      "54 Years_perc: float64\n",
      "55 Years_perc: float64\n",
      "56 Years_perc: float64\n",
      "57 Years_perc: float64\n",
      "58 Years_perc: float64\n",
      "59 Years_perc: float64\n",
      "60 Years_perc: float64\n",
      "61 Years_perc: float64\n",
      "62 Years_perc: float64\n",
      "63 Years_perc: float64\n",
      "64 Years_perc: float64\n",
      "65 Years_perc: float64\n",
      "66 Years_perc: float64\n",
      "67 Years_perc: float64\n",
      "68 Years_perc: float64\n",
      "69 Years_perc: float64\n",
      "70 Years_perc: float64\n",
      "71 Years_perc: float64\n",
      "72 Years_perc: float64\n",
      "73 Years_perc: float64\n",
      "74 Years_perc: float64\n",
      "75 Years_perc: float64\n",
      "76 Years_perc: float64\n",
      "77 Years_perc: float64\n",
      "78 Years_perc: float64\n",
      "79 Years_perc: float64\n",
      "80 Years_perc: float64\n",
      "81 Years_perc: float64\n",
      "82 Years_perc: float64\n",
      "83 Years_perc: float64\n",
      "84 Years_perc: float64\n",
      "85 Years_perc: float64\n",
      "86 Years_perc: float64\n",
      "87 Years_perc: float64\n",
      "88 Years_perc: float64\n",
      "89 Years_perc: float64\n",
      "90 Years_perc: float64\n",
      "91 Years_perc: float64\n",
      "92 Years_perc: float64\n",
      "93 Years_perc: float64\n",
      "94 Years_perc: float64\n",
      "95 Years_perc: float64\n",
      "96 Years_perc: float64\n",
      "97  Years_perc: float64\n",
      "98  Years_perc: float64\n",
      "99  Years_perc: float64\n",
      "100 to 104  Years_perc: float64\n",
      "105 to 109  Years_perc: float64\n",
      "110  Years and Over_perc: float64\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n",
      "DF_total_female_hol\n",
      "Shape: (3221, 212)\n",
      "Dtypes:\n",
      "0: int32\n",
      "1: int32\n",
      "2: int32\n",
      "3: int32\n",
      "4: int32\n",
      "5: int32\n",
      "6: int32\n",
      "7: int32\n",
      "8: int32\n",
      "9: int32\n",
      "10: int32\n",
      "11: int32\n",
      "12: int32\n",
      "13: int32\n",
      "14: int32\n",
      "15: int32\n",
      "16: int32\n",
      "17: int32\n",
      "18: int32\n",
      "19: int32\n",
      "20: int32\n",
      "21: int32\n",
      "22: int32\n",
      "23: int32\n",
      "24: int32\n",
      "25: int32\n",
      "26: int32\n",
      "27: int32\n",
      "28: int32\n",
      "29: int32\n",
      "30: int32\n",
      "31: int32\n",
      "32: int32\n",
      "33: int32\n",
      "34: int32\n",
      "35: int32\n",
      "36: int32\n",
      "37: int32\n",
      "38: int32\n",
      "39: int32\n",
      "40: int32\n",
      "41: int32\n",
      "42: int32\n",
      "43: int32\n",
      "44: int32\n",
      "45: int32\n",
      "46: int32\n",
      "47: int32\n",
      "48: int32\n",
      "49: int32\n",
      "50: int32\n",
      "51: int32\n",
      "52: int32\n",
      "53: int32\n",
      "54: int32\n",
      "55: int32\n",
      "56: int32\n",
      "57: int32\n",
      "58: int32\n",
      "59: int32\n",
      "60: int32\n",
      "61: int32\n",
      "62: int32\n",
      "63: int32\n",
      "64: int32\n",
      "65: int32\n",
      "66: int32\n",
      "67: int32\n",
      "68: int32\n",
      "69: int32\n",
      "70: int32\n",
      "71: int32\n",
      "72: int32\n",
      "73: int32\n",
      "74: int32\n",
      "75: int32\n",
      "76: int32\n",
      "77: int32\n",
      "78: int32\n",
      "79: int32\n",
      "80: int32\n",
      "81: int32\n",
      "82: int32\n",
      "83: int32\n",
      "84: int32\n",
      "85: int32\n",
      "86: int32\n",
      "87: int32\n",
      "88: int32\n",
      "89: int32\n",
      "90: int32\n",
      "91: int32\n",
      "92: int32\n",
      "93: int32\n",
      "94: int32\n",
      "95: int32\n",
      "96: int32\n",
      "97: int32\n",
      "98: int32\n",
      "99: int32\n",
      "102: int32\n",
      "107: int32\n",
      "110: int32\n",
      "Average_Age: float64\n",
      "Under 1 Year_perc: float64\n",
      "1 Year_perc: float64\n",
      "2 Years_perc: float64\n",
      "3 Years_perc: float64\n",
      "4 Years_perc: float64\n",
      "5 Years_perc: float64\n",
      "6 Years_perc: float64\n",
      "7 Years_perc: float64\n",
      "8 Years_perc: float64\n",
      "9 Years_perc: float64\n",
      "10 Years_perc: float64\n",
      "11 Years_perc: float64\n",
      "12 Years_perc: float64\n",
      "13 Years_perc: float64\n",
      "14 Years_perc: float64\n",
      "15 Years_perc: float64\n",
      "16 Years_perc: float64\n",
      "17 Years_perc: float64\n",
      "18 Years_perc: float64\n",
      "19 Years_perc: float64\n",
      "20 Years_perc: float64\n",
      "21 Years_perc: float64\n",
      "22 Years_perc: float64\n",
      "23 Years_perc: float64\n",
      "24 Years_perc: float64\n",
      "25 Years_perc: float64\n",
      "26 Years_perc: float64\n",
      "27 Years_perc: float64\n",
      "28 Years_perc: float64\n",
      "29 Years_perc: float64\n",
      "30 Years_perc: float64\n",
      "31 Years_perc: float64\n",
      "32 Years_perc: float64\n",
      "33 Years_perc: float64\n",
      "34 Years_perc: float64\n",
      "35 Years_perc: float64\n",
      "36 Years_perc: float64\n",
      "37 Years_perc: float64\n",
      "38 Years_perc: float64\n",
      "39 Years_perc: float64\n",
      "40 Years_perc: float64\n",
      "41 Years_perc: float64\n",
      "42 Years_perc: float64\n",
      "43 Years_perc: float64\n",
      "44 Years_perc: float64\n",
      "45 Years_perc: float64\n",
      "46 Years_perc: float64\n",
      "47 Years_perc: float64\n",
      "48 Years_perc: float64\n",
      "49 Years_perc: float64\n",
      "50 Years_perc: float64\n",
      "51 Years_perc: float64\n",
      "52 Years_perc: float64\n",
      "53 Years_perc: float64\n",
      "54 Years_perc: float64\n",
      "55 Years_perc: float64\n",
      "56 Years_perc: float64\n",
      "57 Years_perc: float64\n",
      "58 Years_perc: float64\n",
      "59 Years_perc: float64\n",
      "60 Years_perc: float64\n",
      "61 Years_perc: float64\n",
      "62 Years_perc: float64\n",
      "63 Years_perc: float64\n",
      "64 Years_perc: float64\n",
      "65 Years_perc: float64\n",
      "66 Years_perc: float64\n",
      "67 Years_perc: float64\n",
      "68 Years_perc: float64\n",
      "69 Years_perc: float64\n",
      "70 Years_perc: float64\n",
      "71 Years_perc: float64\n",
      "72 Years_perc: float64\n",
      "73 Years_perc: float64\n",
      "74 Years_perc: float64\n",
      "75 Years_perc: float64\n",
      "76 Years_perc: float64\n",
      "77 Years_perc: float64\n",
      "78 Years_perc: float64\n",
      "79 Years_perc: float64\n",
      "80 Years_perc: float64\n",
      "81 Years_perc: float64\n",
      "82 Years_perc: float64\n",
      "83 Years_perc: float64\n",
      "84 Years_perc: float64\n",
      "85 Years_perc: float64\n",
      "86 Years_perc: float64\n",
      "87 Years_perc: float64\n",
      "88 Years_perc: float64\n",
      "89 Years_perc: float64\n",
      "90 Years_perc: float64\n",
      "91 Years_perc: float64\n",
      "92 Years_perc: float64\n",
      "93 Years_perc: float64\n",
      "94 Years_perc: float64\n",
      "95 Years_perc: float64\n",
      "96 Years_perc: float64\n",
      "97  Years_perc: float64\n",
      "98  Years_perc: float64\n",
      "99  Years_perc: float64\n",
      "100 to 104  Years_perc: float64\n",
      "105 to 109  Years_perc: float64\n",
      "110  Years and Over_perc: float64\n",
      "Total: object\n",
      "Location: object\n",
      "State: object\n",
      "County: object\n",
      "FIPS: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the names, shapes, and dtypes of the dataframes in 'dfs_perc'\n",
    "print(\"Data Frames in 'dfs_perc':\")\n",
    "for name, df in dfs_perc.items():\n",
    "    print(name)\n",
    "    print(\"Shape:\", df.shape)\n",
    "    print(\"Dtypes:\")\n",
    "    for column, dtype in df.dtypes.items():\n",
    "        print(f\"{column}: {dtype}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting a specific dataframe to verify information has migrated correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0    1    2    3    4    5    6    7    8    9   10   11   12   13  \\\n",
      "0     437  450  511  484  513  525  576  559  549  564  573  595  594  597   \n",
      "1      70   70   84   91   80   90  116   67   97   81   97   83   85  113   \n",
      "2      72   80   83   60   82   78   69   84   67   90   82   79   84  102   \n",
      "3     157  203  182  171  192  161  202  186  158  184  211  220  208  213   \n",
      "4      64   51   65   60   62   79   85   71   76   71   78   85   55   92   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "3216   98   86  120  100  109  120  115   96  114   96  114  113  127  117   \n",
      "3217  183  124  170  184  175  185  185  160  188  197  189  181  227  181   \n",
      "3218  190  218  223  195  287  247  211  223  237  185  228  244  232  248   \n",
      "3219   20   10    4   14    9   10   16   17   18   11   12   18   18   19   \n",
      "3220  593  582  669  639  691  704  658  650  687  618  670  700  755  720   \n",
      "\n",
      "       14   15   16   17   18   19   20   21   22   23   24   25   26   27  \\\n",
      "0     565  593  587  614  580  486  474  486  414  457  439  451  458  509   \n",
      "1      89   85  108   92   71   71   87   36   40   78   57   27   64   60   \n",
      "2      88   75   88   65   49   71   77   48   79   58   60   77   84   86   \n",
      "3     197  187  197  209  400  537  522  518  399  289  237  240  275  232   \n",
      "4      75   77   85   65   92   66   78   48   25   68   61   66   54   50   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "3216  113  134  102  115  114  115   99  114   62   86   87   99   71   94   \n",
      "3217  183  186  193  184  193  158  175  158  164  139  149  168  127  134   \n",
      "3218  255  249  212  245  212  231  200  209  204  203  217  266  249  336   \n",
      "3219   18   24    9   18   17   52   43   49   41   42   24   22   53   30   \n",
      "3220  736  722  722  708  809  890  819  753  730  660  643  575  594  618   \n",
      "\n",
      "       28   29   30   31   32   33   34   35   36   37   38   39   40   41  \\\n",
      "0     480  490  539  517  489  506  478  460  491  501  525  579  560  509   \n",
      "1      42   96   78   93   47   70   70   72   80   76   83   74   63   99   \n",
      "2      73   54   82   65   58   73   40   75   56   65   77   79   74   53   \n",
      "3     180  233  234  209  233  173  208  221  215  191  207  212  181  197   \n",
      "4      86   68   59   49   63   34   71   79   40   56   73  105   53   80   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "3216   98   96   66   91   94   72  119  105   87  106   84   76   95   98   \n",
      "3217  139  141  153  159  150  127  141  160  127  170  170  194  168  191   \n",
      "3218  299  321  349  360  379  348  339  361  325  383  406  294  387  335   \n",
      "3219   40   28   35   28   23   33   22   20   12   21   46   27   27   16   \n",
      "3220  641  547  619  561  598  589  621  602  596  588  655  612  605  557   \n",
      "\n",
      "       42   43   44   45   46   47   48   49   50   51   52   53   54   55  \\\n",
      "0     523  534  490  581  534  496  603  632  619  584  626  535  533  601   \n",
      "1      61   84   93   83   69   62  105   65  107   71   70   76   62   99   \n",
      "2      56   59   59   71  103   91   85   90   83   93   81   66   87   52   \n",
      "3     219  206  196  189  183  163  215  195  186  195  208  205  216  218   \n",
      "4      60   88   78   77   67   88   74  101   71   87   99   89   90   66   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "3216  100  121   70  103  116   61   93  118   99  105  129  151   96  112   \n",
      "3217  148  195  151  163  163  154  205  188  152  182  172  159  211  203   \n",
      "3218  349  285  261  344  311  277  293  240  264  294  225  233  216  246   \n",
      "3219   23   21   33   25   24    5   17   13   19   18   28   18   16    4   \n",
      "3220  573  558  550  623  523  604  574  620  669  575  591  617  624  703   \n",
      "\n",
      "       56   57   58   59   60   61   62   63   64   65   66   67   68   69  \\\n",
      "0     626  614  588  579  536  565  580  503  480  469  477  424  373  411   \n",
      "1     102  105   86   78   77   80   94   96   81   78   90   77   80   70   \n",
      "2      74  101  102  108   97   61   94   83   87   94   79   88   80   74   \n",
      "3     191  239  245  228  233  207  194  233  189  234  212  197  217  194   \n",
      "4      71   95  117   55   96   91  103   75   66   86   93   73   68   73   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "3216  123  129  143  128  145  105  132  120  135  148  125  130  109   98   \n",
      "3217  190  219  198  227  192  156  181  215  179  133  201  146  157  142   \n",
      "3218  264  251  243  244  263  217  277  182  193  260  175  198  124  153   \n",
      "3219   24   11   19   28   21   17   17   17   15   18   19    6   14   20   \n",
      "3220  682  682  655  703  713  623  605  590  642  611  586  504  472  405   \n",
      "\n",
      "       70   71   72   73   74   75   76   77   78   79   80   81   82   83  \\\n",
      "0     363  380  363  383  248  285  272  272  166  191  146  143  115   91   \n",
      "1      56   42   59   54   66   58   40   39   34   43   24   37   16   14   \n",
      "2      71   67   83   86   41   55   39   45   52   30   34   19   25   27   \n",
      "3     157  193  178  186  155  152  141  139  109   93   92   66   79   61   \n",
      "4      78   54   68   50   35   44   32   43   26   18   18   26   11   15   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "3216   89   88   77   71   78   47   46   64   32   50   33   42   11   17   \n",
      "3217  178  146  136  128   87  123   76  103   64   67   42   59   76   30   \n",
      "3218  130  120  115  167   79  122   66   55   62   67   42   37   49   33   \n",
      "3219    8   14   12   17    9   26    4    6   11    4   15    4    5    0   \n",
      "3220  489  387  410  392  268  321  274  261  264  272  196  206  161  168   \n",
      "\n",
      "       84   85  86  87  88  89  90  91  92  93  94  95  96  97  98  99  102  \\\n",
      "0      98   88  88  44  39  24  24  28  26   5   6   8   3   3   1   0    0   \n",
      "1      16   12  13   4  12   7   8  13   3   0   0   2   0   0   0   0    0   \n",
      "2      24   12   5   3  18  18  15   1   6   6   3   1   4   3   1   0    1   \n",
      "3      62   31  36  41  35  38  34  14   5   6   4   7   0   4   0   0    0   \n",
      "4      12   17   2   5  13  14   9   1   2   6   2   0   2   0   0   0    1   \n",
      "...   ...  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...   \n",
      "3216   32   17   7  12  24   8   1   0  13  10   3   2   4   0   3   1    1   \n",
      "3217   46   42  30  23  14  26  26  10   5   5   5   5   2   1   1   0    1   \n",
      "3218   52   36  34  28  24  49  25   5   8   6  26   6   3   6   4   2    5   \n",
      "3219    6    2   1   1   1   6   0   1   3   1   0   0   0   0   0   0    1   \n",
      "3220  138  102  61  77  74  60  39  32  15  25  13   5   3   9   1   0    4   \n",
      "\n",
      "      107  110  Average_Age  Under 1 Year_perc  1 Year_perc  2 Years_perc  \\\n",
      "0       0    0    38.518476           0.010715     0.011034      0.012530   \n",
      "1       0    0    39.192103           0.011281     0.011281      0.013537   \n",
      "2       2    0    40.734192           0.011734     0.013038      0.013527   \n",
      "3       0    0    38.858371           0.008768     0.011337      0.010164   \n",
      "4       1    0    40.306536           0.011185     0.008913      0.011360   \n",
      "...   ...  ...          ...                ...          ...           ...   \n",
      "3216    0    1    39.908089           0.011744     0.010306      0.014380   \n",
      "3217    0    0    39.505269           0.013487     0.009138      0.012529   \n",
      "3218    0    0    37.824757           0.009651     0.011073      0.011327   \n",
      "3219    0    0    37.842043           0.011876     0.005938      0.002375   \n",
      "3220    0    0    37.557007           0.012026     0.011803      0.013567   \n",
      "\n",
      "      3 Years_perc  4 Years_perc  5 Years_perc  6 Years_perc  7 Years_perc  \\\n",
      "0         0.011868      0.012579      0.012873      0.014124      0.013707   \n",
      "1         0.014666      0.012893      0.014504      0.018695      0.010798   \n",
      "2         0.009778      0.013364      0.012712      0.011245      0.013690   \n",
      "3         0.009550      0.010723      0.008991      0.011281      0.010388   \n",
      "4         0.010486      0.010835      0.013806      0.014855      0.012408   \n",
      "...            ...           ...           ...           ...           ...   \n",
      "3216      0.011983      0.013062      0.014380      0.013781      0.011504   \n",
      "3217      0.013560      0.012897      0.013634      0.013634      0.011792   \n",
      "3218      0.009905      0.014578      0.012546      0.010718      0.011327   \n",
      "3219      0.008314      0.005344      0.005938      0.009501      0.010095   \n",
      "3220      0.012959      0.014013      0.014277      0.013344      0.013182   \n",
      "\n",
      "      8 Years_perc  9 Years_perc  10 Years_perc  11 Years_perc  12 Years_perc  \\\n",
      "0         0.013461      0.013829       0.014050       0.014589       0.014565   \n",
      "1         0.015633      0.013054       0.015633       0.013376       0.013699   \n",
      "2         0.010919      0.014668       0.013364       0.012875       0.013690   \n",
      "3         0.008824      0.010276       0.011784       0.012286       0.011616   \n",
      "4         0.013282      0.012408       0.013632       0.014855       0.009612   \n",
      "...            ...           ...            ...            ...            ...   \n",
      "3216      0.013661      0.011504       0.013661       0.013541       0.015219   \n",
      "3217      0.013855      0.014518       0.013929       0.013339       0.016729   \n",
      "3218      0.012038      0.009397       0.011581       0.012394       0.011784   \n",
      "3219      0.010689      0.006532       0.007126       0.010689       0.010689   \n",
      "3220      0.013932      0.012533       0.013588       0.014196       0.015311   \n",
      "\n",
      "      13 Years_perc  14 Years_perc  15 Years_perc  16 Years_perc  \\\n",
      "0          0.014638       0.013854       0.014540       0.014393   \n",
      "1          0.018211       0.014343       0.013699       0.017405   \n",
      "2          0.016623       0.014342       0.012223       0.014342   \n",
      "3          0.011895       0.011002       0.010443       0.011002   \n",
      "4          0.016078       0.013107       0.013457       0.014855   \n",
      "...             ...            ...            ...            ...   \n",
      "3216       0.014020       0.013541       0.016058       0.012223   \n",
      "3217       0.013339       0.013487       0.013708       0.014224   \n",
      "3218       0.012597       0.012953       0.012648       0.010769   \n",
      "3219       0.011283       0.010689       0.014252       0.005344   \n",
      "3220       0.014602       0.014926       0.014642       0.014642   \n",
      "\n",
      "      17 Years_perc  18 Years_perc  19 Years_perc  20 Years_perc  \\\n",
      "0          0.015055       0.014222       0.011917       0.011622   \n",
      "1          0.014827       0.011442       0.011442       0.014021   \n",
      "2          0.010593       0.007986       0.011571       0.012549   \n",
      "3          0.011672       0.022339       0.029990       0.029152   \n",
      "4          0.011360       0.016078       0.011534       0.013632   \n",
      "...             ...            ...            ...            ...   \n",
      "3216       0.013781       0.013661       0.013781       0.011863   \n",
      "3217       0.013560       0.014224       0.011644       0.012897   \n",
      "3218       0.012445       0.010769       0.011734       0.010159   \n",
      "3219       0.010689       0.010095       0.030879       0.025534   \n",
      "3220       0.014358       0.016406       0.018049       0.016609   \n",
      "\n",
      "      21 Years_perc  22 Years_perc  23 Years_perc  24 Years_perc  \\\n",
      "0          0.011917       0.010151       0.011206       0.010764   \n",
      "1          0.005802       0.006446       0.012571       0.009186   \n",
      "2          0.007823       0.012875       0.009452       0.009778   \n",
      "3          0.028929       0.022283       0.016140       0.013236   \n",
      "4          0.008389       0.004369       0.011884       0.010661   \n",
      "...             ...            ...            ...            ...   \n",
      "3216       0.013661       0.007430       0.010306       0.010425   \n",
      "3217       0.011644       0.012086       0.010244       0.010981   \n",
      "3218       0.010616       0.010362       0.010311       0.011023   \n",
      "3219       0.029097       0.024347       0.024941       0.014252   \n",
      "3220       0.015271       0.014804       0.013385       0.013040   \n",
      "\n",
      "      25 Years_perc  26 Years_perc  27 Years_perc  28 Years_perc  \\\n",
      "0          0.011059       0.011230       0.012481       0.011770   \n",
      "1          0.004351       0.010314       0.009670       0.006769   \n",
      "2          0.012549       0.013690       0.014016       0.011897   \n",
      "3          0.013403       0.015358       0.012957       0.010052   \n",
      "4          0.011534       0.009437       0.008738       0.015030   \n",
      "...             ...            ...            ...            ...   \n",
      "3216       0.011863       0.008508       0.011264       0.011744   \n",
      "3217       0.012381       0.009360       0.009875       0.010244   \n",
      "3218       0.013511       0.012648       0.017067       0.015188   \n",
      "3219       0.013064       0.031473       0.017815       0.023753   \n",
      "3220       0.011661       0.012046       0.012533       0.012999   \n",
      "\n",
      "      29 Years_perc  30 Years_perc  31 Years_perc  32 Years_perc  \\\n",
      "0          0.012015       0.013216       0.012677       0.011990   \n",
      "1          0.015471       0.012571       0.014988       0.007575   \n",
      "2          0.008801       0.013364       0.010593       0.009452   \n",
      "3          0.013012       0.013068       0.011672       0.013012   \n",
      "4          0.011884       0.010311       0.008563       0.011010   \n",
      "...             ...            ...            ...            ...   \n",
      "3216       0.011504       0.007909       0.010905       0.011264   \n",
      "3217       0.010391       0.011276       0.011718       0.011055   \n",
      "3218       0.016305       0.017727       0.018286       0.019251   \n",
      "3219       0.016627       0.020784       0.016627       0.013658   \n",
      "3220       0.011093       0.012553       0.011377       0.012127   \n",
      "\n",
      "      33 Years_perc  34 Years_perc  35 Years_perc  36 Years_perc  \\\n",
      "0          0.012407       0.011721       0.011279       0.012039   \n",
      "1          0.011281       0.011281       0.011604       0.012893   \n",
      "2          0.011897       0.006519       0.012223       0.009126   \n",
      "3          0.009662       0.011616       0.012342       0.012007   \n",
      "4          0.005942       0.012408       0.013806       0.006991   \n",
      "...             ...            ...            ...            ...   \n",
      "3216       0.008628       0.014260       0.012582       0.010425   \n",
      "3217       0.009360       0.010391       0.011792       0.009360   \n",
      "3218       0.017677       0.017219       0.018337       0.016508   \n",
      "3219       0.019596       0.013064       0.011876       0.007126   \n",
      "3220       0.011945       0.012594       0.012208       0.012087   \n",
      "\n",
      "      37 Years_perc  38 Years_perc  39 Years_perc  40 Years_perc  \\\n",
      "0          0.012285       0.012873       0.014197       0.013731   \n",
      "1          0.012248       0.013376       0.011926       0.010153   \n",
      "2          0.010593       0.012549       0.012875       0.012060   \n",
      "3          0.010667       0.011560       0.011840       0.010108   \n",
      "4          0.009787       0.012758       0.018350       0.009262   \n",
      "...             ...            ...            ...            ...   \n",
      "3216       0.012702       0.010066       0.009107       0.011384   \n",
      "3217       0.012529       0.012529       0.014297       0.012381   \n",
      "3218       0.019454       0.020623       0.014934       0.019658   \n",
      "3219       0.012470       0.027316       0.016033       0.016033   \n",
      "3220       0.011925       0.013283       0.012411       0.012269   \n",
      "\n",
      "      41 Years_perc  42 Years_perc  43 Years_perc  44 Years_perc  \\\n",
      "0          0.012481       0.012824       0.013094       0.012015   \n",
      "1          0.015955       0.009831       0.013537       0.014988   \n",
      "2          0.008638       0.009126       0.009615       0.009615   \n",
      "3          0.011002       0.012231       0.011505       0.010946   \n",
      "4          0.013981       0.010486       0.015379       0.013632   \n",
      "...             ...            ...            ...            ...   \n",
      "3216       0.011744       0.011983       0.014500       0.008388   \n",
      "3217       0.014076       0.010907       0.014371       0.011128   \n",
      "3218       0.017016       0.017727       0.014477       0.013257   \n",
      "3219       0.009501       0.013658       0.012470       0.019596   \n",
      "3220       0.011296       0.011620       0.011316       0.011154   \n",
      "\n",
      "      45 Years_perc  46 Years_perc  47 Years_perc  48 Years_perc  \\\n",
      "0          0.014246       0.013094       0.012162       0.014786   \n",
      "1          0.013376       0.011120       0.009992       0.016922   \n",
      "2          0.011571       0.016786       0.014831       0.013853   \n",
      "3          0.010555       0.010220       0.009103       0.012007   \n",
      "4          0.013457       0.011709       0.015379       0.012933   \n",
      "...             ...            ...            ...            ...   \n",
      "3216       0.012343       0.013901       0.007310       0.011144   \n",
      "3217       0.012013       0.012013       0.011349       0.015108   \n",
      "3218       0.017473       0.015797       0.014070       0.014883   \n",
      "3219       0.014846       0.014252       0.002969       0.010095   \n",
      "3220       0.012634       0.010606       0.012249       0.011641   \n",
      "\n",
      "      49 Years_perc  50 Years_perc  51 Years_perc  52 Years_perc  \\\n",
      "0          0.015497       0.015178       0.014320       0.015350   \n",
      "1          0.010475       0.017244       0.011442       0.011281   \n",
      "2          0.014668       0.013527       0.015156       0.013201   \n",
      "3          0.010890       0.010388       0.010890       0.011616   \n",
      "4          0.017651       0.012408       0.015204       0.017302   \n",
      "...             ...            ...            ...            ...   \n",
      "3216       0.014140       0.011863       0.012582       0.015458   \n",
      "3217       0.013855       0.011202       0.013413       0.012676   \n",
      "3218       0.012191       0.013410       0.014934       0.011429   \n",
      "3219       0.007720       0.011283       0.010689       0.016627   \n",
      "3220       0.012574       0.013567       0.011661       0.011985   \n",
      "\n",
      "      53 Years_perc  54 Years_perc  55 Years_perc  56 Years_perc  \\\n",
      "0          0.013118       0.013069       0.014737       0.015350   \n",
      "1          0.012248       0.009992       0.015955       0.016438   \n",
      "2          0.010756       0.014179       0.008475       0.012060   \n",
      "3          0.011449       0.012063       0.012175       0.010667   \n",
      "4          0.015554       0.015729       0.011534       0.012408   \n",
      "...             ...            ...            ...            ...   \n",
      "3216       0.018095       0.011504       0.013421       0.014739   \n",
      "3217       0.011718       0.015550       0.014961       0.014003   \n",
      "3218       0.011835       0.010972       0.012496       0.013410   \n",
      "3219       0.010689       0.009501       0.002375       0.014252   \n",
      "3220       0.012513       0.012655       0.014257       0.013831   \n",
      "\n",
      "      57 Years_perc  58 Years_perc  59 Years_perc  60 Years_perc  \\\n",
      "0          0.015055       0.014418       0.014197       0.013143   \n",
      "1          0.016922       0.013860       0.012571       0.012409   \n",
      "2          0.016460       0.016623       0.017601       0.015808   \n",
      "3          0.013347       0.013683       0.012733       0.013012   \n",
      "4          0.016603       0.020447       0.009612       0.016777   \n",
      "...             ...            ...            ...            ...   \n",
      "3216       0.015458       0.017136       0.015339       0.017376   \n",
      "3217       0.016140       0.014592       0.016729       0.014150   \n",
      "3218       0.012750       0.012343       0.012394       0.013359   \n",
      "3219       0.006532       0.011283       0.016627       0.012470   \n",
      "3220       0.013831       0.013283       0.014257       0.014460   \n",
      "\n",
      "      61 Years_perc  62 Years_perc  63 Years_perc  64 Years_perc  \\\n",
      "0          0.013854       0.014222       0.012334       0.011770   \n",
      "1          0.012893       0.015149       0.015471       0.013054   \n",
      "2          0.009941       0.015319       0.013527       0.014179   \n",
      "3          0.011560       0.010834       0.013012       0.010555   \n",
      "4          0.015904       0.018001       0.013107       0.011534   \n",
      "...             ...            ...            ...            ...   \n",
      "3216       0.012582       0.015818       0.014380       0.016177   \n",
      "3217       0.011497       0.013339       0.015845       0.013192   \n",
      "3218       0.011023       0.014070       0.009245       0.009803   \n",
      "3219       0.010095       0.010095       0.010095       0.008907   \n",
      "3220       0.012634       0.012269       0.011965       0.013020   \n",
      "\n",
      "      65 Years_perc  66 Years_perc  67 Years_perc  68 Years_perc  \\\n",
      "0          0.011500       0.011696       0.010396       0.009146   \n",
      "1          0.012571       0.014504       0.012409       0.012893   \n",
      "2          0.015319       0.012875       0.014342       0.013038   \n",
      "3          0.013068       0.011840       0.011002       0.012119   \n",
      "4          0.015030       0.016253       0.012758       0.011884   \n",
      "...             ...            ...            ...            ...   \n",
      "3216       0.017735       0.014979       0.015578       0.013062   \n",
      "3217       0.009802       0.014813       0.010760       0.011570   \n",
      "3218       0.013207       0.008889       0.010057       0.006299   \n",
      "3219       0.010689       0.011283       0.003563       0.008314   \n",
      "3220       0.012391       0.011884       0.010221       0.009572   \n",
      "\n",
      "      69 Years_perc  70 Years_perc  71 Years_perc  72 Years_perc  \\\n",
      "0          0.010078       0.008901       0.009318       0.008901   \n",
      "1          0.011281       0.009025       0.006769       0.009508   \n",
      "2          0.012060       0.011571       0.010919       0.013527   \n",
      "3          0.010834       0.008768       0.010779       0.009941   \n",
      "4          0.012758       0.013632       0.009437       0.011884   \n",
      "...             ...            ...            ...            ...   \n",
      "3216       0.011744       0.010665       0.010545       0.009227   \n",
      "3217       0.010465       0.013118       0.010760       0.010023   \n",
      "3218       0.007772       0.006603       0.006095       0.005841   \n",
      "3219       0.011876       0.004751       0.008314       0.007126   \n",
      "3220       0.008213       0.009917       0.007848       0.008315   \n",
      "\n",
      "      73 Years_perc  74 Years_perc  75 Years_perc  76 Years_perc  \\\n",
      "0          0.009391       0.006081       0.006988       0.006669   \n",
      "1          0.008703       0.010637       0.009347       0.006446   \n",
      "2          0.014016       0.006682       0.008963       0.006356   \n",
      "3          0.010388       0.008656       0.008489       0.007874   \n",
      "4          0.008738       0.006117       0.007690       0.005592   \n",
      "...             ...            ...            ...            ...   \n",
      "3216       0.008508       0.009347       0.005632       0.005512   \n",
      "3217       0.009433       0.006412       0.009065       0.005601   \n",
      "3218       0.008483       0.004013       0.006197       0.003352   \n",
      "3219       0.010095       0.005344       0.015439       0.002375   \n",
      "3220       0.007950       0.005435       0.006510       0.005557   \n",
      "\n",
      "      77 Years_perc  78 Years_perc  79 Years_perc  80 Years_perc  \\\n",
      "0          0.006669       0.004070       0.004683       0.003580   \n",
      "1          0.006285       0.005479       0.006930       0.003868   \n",
      "2          0.007334       0.008475       0.004889       0.005541   \n",
      "3          0.007763       0.006087       0.005194       0.005138   \n",
      "4          0.007515       0.004544       0.003146       0.003146   \n",
      "...             ...            ...            ...            ...   \n",
      "3216       0.007669       0.003835       0.005992       0.003954   \n",
      "3217       0.007591       0.004717       0.004938       0.003095   \n",
      "3218       0.002794       0.003149       0.003403       0.002133   \n",
      "3219       0.003563       0.006532       0.002375       0.008907   \n",
      "3220       0.005293       0.005354       0.005516       0.003975   \n",
      "\n",
      "      81 Years_perc  82 Years_perc  83 Years_perc  84 Years_perc  \\\n",
      "0          0.003506       0.002820       0.002231       0.002403   \n",
      "1          0.005963       0.002579       0.002256       0.002579   \n",
      "2          0.003096       0.004074       0.004400       0.003911   \n",
      "3          0.003686       0.004412       0.003407       0.003463   \n",
      "4          0.004544       0.001922       0.002621       0.002097   \n",
      "...             ...            ...            ...            ...   \n",
      "3216       0.005033       0.001318       0.002037       0.003835   \n",
      "3217       0.004348       0.005601       0.002211       0.003390   \n",
      "3218       0.001879       0.002489       0.001676       0.002641   \n",
      "3219       0.002375       0.002969       0.000000       0.003563   \n",
      "3220       0.004178       0.003265       0.003407       0.002799   \n",
      "\n",
      "      85 Years_perc  86 Years_perc  87 Years_perc  88 Years_perc  \\\n",
      "0          0.002158       0.002158       0.001079       0.000956   \n",
      "1          0.001934       0.002095       0.000645       0.001934   \n",
      "2          0.001956       0.000815       0.000489       0.002934   \n",
      "3          0.001731       0.002010       0.002290       0.001955   \n",
      "4          0.002971       0.000350       0.000874       0.002272   \n",
      "...             ...            ...            ...            ...   \n",
      "3216       0.002037       0.000839       0.001438       0.002876   \n",
      "3217       0.003095       0.002211       0.001695       0.001032   \n",
      "3218       0.001829       0.001727       0.001422       0.001219   \n",
      "3219       0.001188       0.000594       0.000594       0.000594   \n",
      "3220       0.002069       0.001237       0.001562       0.001501   \n",
      "\n",
      "      89 Years_perc  90 Years_perc  91 Years_perc  92 Years_perc  \\\n",
      "0          0.000588       0.000588       0.000687       0.000638   \n",
      "1          0.001128       0.001289       0.002095       0.000483   \n",
      "2          0.002934       0.002445       0.000163       0.000978   \n",
      "3          0.002122       0.001899       0.000782       0.000279   \n",
      "4          0.002447       0.001573       0.000175       0.000350   \n",
      "...             ...            ...            ...            ...   \n",
      "3216       0.000959       0.000120       0.000000       0.001558   \n",
      "3217       0.001916       0.001916       0.000737       0.000368   \n",
      "3218       0.002489       0.001270       0.000254       0.000406   \n",
      "3219       0.003563       0.000000       0.000594       0.001781   \n",
      "3220       0.001217       0.000791       0.000649       0.000304   \n",
      "\n",
      "      93 Years_perc  94 Years_perc  95 Years_perc  96 Years_perc  \\\n",
      "0          0.000123       0.000147       0.000196       0.000074   \n",
      "1          0.000000       0.000000       0.000322       0.000000   \n",
      "2          0.000978       0.000489       0.000163       0.000652   \n",
      "3          0.000335       0.000223       0.000391       0.000000   \n",
      "4          0.001049       0.000350       0.000000       0.000350   \n",
      "...             ...            ...            ...            ...   \n",
      "3216       0.001198       0.000359       0.000240       0.000479   \n",
      "3217       0.000368       0.000368       0.000368       0.000147   \n",
      "3218       0.000305       0.001321       0.000305       0.000152   \n",
      "3219       0.000594       0.000000       0.000000       0.000000   \n",
      "3220       0.000507       0.000264       0.000101       0.000061   \n",
      "\n",
      "      97  Years_perc  98  Years_perc  99  Years_perc  100 to 104  Years_perc  \\\n",
      "0           0.000074        0.000025        0.000000                0.000000   \n",
      "1           0.000000        0.000000        0.000000                0.000000   \n",
      "2           0.000489        0.000163        0.000000                0.000163   \n",
      "3           0.000223        0.000000        0.000000                0.000000   \n",
      "4           0.000000        0.000000        0.000000                0.000175   \n",
      "...              ...             ...             ...                     ...   \n",
      "3216        0.000000        0.000359        0.000120                0.000120   \n",
      "3217        0.000074        0.000074        0.000000                0.000074   \n",
      "3218        0.000305        0.000203        0.000102                0.000254   \n",
      "3219        0.000000        0.000000        0.000000                0.000594   \n",
      "3220        0.000183        0.000020        0.000000                0.000081   \n",
      "\n",
      "      105 to 109  Years_perc  110  Years and Over_perc  Total  \\\n",
      "0                   0.000000                   0.00000  40783   \n",
      "1                   0.000000                   0.00000   6205   \n",
      "2                   0.000326                   0.00000   6136   \n",
      "3                   0.000000                   0.00000  17906   \n",
      "4                   0.000175                   0.00000   5722   \n",
      "...                      ...                       ...    ...   \n",
      "3216                0.000000                   0.00012   8345   \n",
      "3217                0.000000                   0.00000  13569   \n",
      "3218                0.000000                   0.00000  19687   \n",
      "3219                0.000000                   0.00000   1684   \n",
      "3220                0.000000                   0.00000  49310   \n",
      "\n",
      "                         Location State County   FIPS  \n",
      "0        Bullitt County, Kentucky    21    029  21029  \n",
      "1         Butler County, Kentucky    21    031  21031  \n",
      "2       Caldwell County, Kentucky    21    033  21033  \n",
      "3       Calloway County, Kentucky    21    035  21035  \n",
      "4       Magoffin County, Kentucky    21    153  21153  \n",
      "...                           ...   ...    ...    ...  \n",
      "3216    Haywood County, Tennessee    47    075  47075  \n",
      "3217  Henderson County, Tennessee    47    077  47077  \n",
      "3218         Howard County, Texas    48    227  48227  \n",
      "3219       Hudspeth County, Texas    48    229  48229  \n",
      "3220           Hunt County, Texas    48    231  48231  \n",
      "\n",
      "[3221 rows x 212 columns]\n"
     ]
    }
   ],
   "source": [
    "# Temp option to see all columns\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    print(dfs_perc['DF_male_all'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dictionaries 'dfs' and 'dfs_perc' into 'dfs' in the order of 'df_names'\n",
    "for df_name in df_names:\n",
    "    if df_name in dfs_perc:\n",
    "        if df_name in dfs:\n",
    "            df_merged = pd.concat([dfs[df_name], dfs_perc[df_name]], axis=1)\n",
    "            dfs[df_name] = df_merged\n",
    "        else:\n",
    "            dfs[df_name] = dfs_perc[df_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all the count,name,shape,# of cols, col names of the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Dataframes in 'dfs': 27\n",
      "Data Frames in 'dfs':\n",
      "Dataframe Name: DF_total_all\n",
      "Shape: (3221, 5)\n",
      "Number of Columns: 5\n",
      "Columns: ['Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_whi\n",
      "Shape: (3221, 5)\n",
      "Number of Columns: 5\n",
      "Columns: ['Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_baa\n",
      "Shape: (3221, 5)\n",
      "Number of Columns: 5\n",
      "Columns: ['Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_aian\n",
      "Shape: (3221, 5)\n",
      "Number of Columns: 5\n",
      "Columns: ['Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_aa\n",
      "Shape: (3221, 5)\n",
      "Number of Columns: 5\n",
      "Columns: ['Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_nhop\n",
      "Shape: (3221, 5)\n",
      "Number of Columns: 5\n",
      "Columns: ['Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_sor\n",
      "Shape: (3221, 5)\n",
      "Number of Columns: 5\n",
      "Columns: ['Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_tom\n",
      "Shape: (3221, 5)\n",
      "Number of Columns: 5\n",
      "Columns: ['Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_hol\n",
      "Shape: (3221, 5)\n",
      "Number of Columns: 5\n",
      "Columns: ['Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_male_all\n",
      "Shape: (3221, 212)\n",
      "Number of Columns: 212\n",
      "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age', 'Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_female_all\n",
      "Shape: (3221, 212)\n",
      "Number of Columns: 212\n",
      "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age', 'Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_male_whi\n",
      "Shape: (3221, 212)\n",
      "Number of Columns: 212\n",
      "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age', 'Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_female_whi\n",
      "Shape: (3221, 212)\n",
      "Number of Columns: 212\n",
      "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age', 'Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_male_baa\n",
      "Shape: (3221, 212)\n",
      "Number of Columns: 212\n",
      "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age', 'Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_female_baa\n",
      "Shape: (3221, 212)\n",
      "Number of Columns: 212\n",
      "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age', 'Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_male_aian\n",
      "Shape: (3221, 212)\n",
      "Number of Columns: 212\n",
      "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age', 'Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_female_aian\n",
      "Shape: (3221, 212)\n",
      "Number of Columns: 212\n",
      "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age', 'Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_male_aa\n",
      "Shape: (3221, 212)\n",
      "Number of Columns: 212\n",
      "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age', 'Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_female_aa\n",
      "Shape: (3221, 212)\n",
      "Number of Columns: 212\n",
      "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age', 'Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_male_nhop\n",
      "Shape: (3221, 212)\n",
      "Number of Columns: 212\n",
      "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age', 'Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_female_nhop\n",
      "Shape: (3221, 212)\n",
      "Number of Columns: 212\n",
      "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age', 'Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_male_sor\n",
      "Shape: (3221, 212)\n",
      "Number of Columns: 212\n",
      "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age', 'Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_female_sor\n",
      "Shape: (3221, 212)\n",
      "Number of Columns: 212\n",
      "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age', 'Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_male_tom\n",
      "Shape: (3221, 212)\n",
      "Number of Columns: 212\n",
      "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age', 'Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_female_tom\n",
      "Shape: (3221, 212)\n",
      "Number of Columns: 212\n",
      "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age', 'Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_male_hol\n",
      "Shape: (3221, 212)\n",
      "Number of Columns: 212\n",
      "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age', 'Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n",
      "Dataframe Name: DF_total_female_hol\n",
      "Shape: (3221, 212)\n",
      "Number of Columns: 212\n",
      "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 107, 110, 'Average_Age', 'Under 1 Year_perc', '1 Year_perc', '2 Years_perc', '3 Years_perc', '4 Years_perc', '5 Years_perc', '6 Years_perc', '7 Years_perc', '8 Years_perc', '9 Years_perc', '10 Years_perc', '11 Years_perc', '12 Years_perc', '13 Years_perc', '14 Years_perc', '15 Years_perc', '16 Years_perc', '17 Years_perc', '18 Years_perc', '19 Years_perc', '20 Years_perc', '21 Years_perc', '22 Years_perc', '23 Years_perc', '24 Years_perc', '25 Years_perc', '26 Years_perc', '27 Years_perc', '28 Years_perc', '29 Years_perc', '30 Years_perc', '31 Years_perc', '32 Years_perc', '33 Years_perc', '34 Years_perc', '35 Years_perc', '36 Years_perc', '37 Years_perc', '38 Years_perc', '39 Years_perc', '40 Years_perc', '41 Years_perc', '42 Years_perc', '43 Years_perc', '44 Years_perc', '45 Years_perc', '46 Years_perc', '47 Years_perc', '48 Years_perc', '49 Years_perc', '50 Years_perc', '51 Years_perc', '52 Years_perc', '53 Years_perc', '54 Years_perc', '55 Years_perc', '56 Years_perc', '57 Years_perc', '58 Years_perc', '59 Years_perc', '60 Years_perc', '61 Years_perc', '62 Years_perc', '63 Years_perc', '64 Years_perc', '65 Years_perc', '66 Years_perc', '67 Years_perc', '68 Years_perc', '69 Years_perc', '70 Years_perc', '71 Years_perc', '72 Years_perc', '73 Years_perc', '74 Years_perc', '75 Years_perc', '76 Years_perc', '77 Years_perc', '78 Years_perc', '79 Years_perc', '80 Years_perc', '81 Years_perc', '82 Years_perc', '83 Years_perc', '84 Years_perc', '85 Years_perc', '86 Years_perc', '87 Years_perc', '88 Years_perc', '89 Years_perc', '90 Years_perc', '91 Years_perc', '92 Years_perc', '93 Years_perc', '94 Years_perc', '95 Years_perc', '96 Years_perc', '97  Years_perc', '98  Years_perc', '99  Years_perc', '100 to 104  Years_perc', '105 to 109  Years_perc', '110  Years and Over_perc', 'Total', 'Location', 'State', 'County', 'FIPS']\n"
     ]
    }
   ],
   "source": [
    "# Print the number of dataframes in the 'dfs' dictionary\n",
    "print(\"Number of Dataframes in 'dfs':\", len(dfs))\n",
    "\n",
    "# Print the shape of the dataframes in 'dfs'\n",
    "print(\"Data Frames in 'dfs':\")\n",
    "for df_name, df in dfs.items():\n",
    "    print(\"Dataframe Name:\", df_name)\n",
    "    print(\"Shape:\", df.shape)\n",
    "    print(f\"Number of Columns: {len(df.columns)}\")\n",
    "    print(\"Columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy needed cols from sex dfs to race df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map the column prefixes to the corresponding dataframes\n",
    "column_map = {\n",
    "    'DF_total_all': ['DF_male_all', 'DF_female_all'],\n",
    "    'DF_total_whi': ['DF_total_male_whi', 'DF_total_female_whi'],\n",
    "    'DF_total_baa': ['DF_total_male_baa', 'DF_total_female_baa'],\n",
    "    'DF_total_aian': ['DF_total_male_aian', 'DF_total_female_aian'],\n",
    "    'DF_total_aa': ['DF_total_male_aa', 'DF_total_female_aa'],\n",
    "    'DF_total_nhop': ['DF_total_male_nhop', 'DF_total_female_nhop'],\n",
    "    'DF_total_sor': ['DF_total_male_sor', 'DF_total_female_sor'],\n",
    "    'DF_total_tom': ['DF_total_male_tom', 'DF_total_female_tom'],\n",
    "    'DF_total_hol': ['DF_total_male_hol', 'DF_total_female_hol']\n",
    "}\n",
    "\n",
    "# Copy 'Total' column to the correct dataframes\n",
    "for key, value in column_map.items():\n",
    "    # Slicing exclude the first three characters\n",
    "    dfs[key][f'{value[0][3:]}'] = dfs_perc[value[0]]['Total'].copy()\n",
    "    dfs[key][f'{value[1][3:]}'] = dfs_perc[value[1]]['Total'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'DF_total_all' column names:\n",
      "Index(['Total', 'Location', 'State', 'County', 'FIPS', 'male_all',\n",
      "       'female_all'],\n",
      "      dtype='object', name=0)\n",
      "DataFrame 'DF_total_whi' column names:\n",
      "Index(['Total', 'Location', 'State', 'County', 'FIPS', 'total_male_whi',\n",
      "       'total_female_whi'],\n",
      "      dtype='object', name=0)\n",
      "DataFrame 'DF_total_baa' column names:\n",
      "Index(['Total', 'Location', 'State', 'County', 'FIPS', 'total_male_baa',\n",
      "       'total_female_baa'],\n",
      "      dtype='object', name=0)\n",
      "DataFrame 'DF_total_aian' column names:\n",
      "Index(['Total', 'Location', 'State', 'County', 'FIPS', 'total_male_aian',\n",
      "       'total_female_aian'],\n",
      "      dtype='object', name=0)\n",
      "DataFrame 'DF_total_aa' column names:\n",
      "Index(['Total', 'Location', 'State', 'County', 'FIPS', 'total_male_aa',\n",
      "       'total_female_aa'],\n",
      "      dtype='object', name=0)\n",
      "DataFrame 'DF_total_nhop' column names:\n",
      "Index(['Total', 'Location', 'State', 'County', 'FIPS', 'total_male_nhop',\n",
      "       'total_female_nhop'],\n",
      "      dtype='object', name=0)\n",
      "DataFrame 'DF_total_sor' column names:\n",
      "Index(['Total', 'Location', 'State', 'County', 'FIPS', 'total_male_sor',\n",
      "       'total_female_sor'],\n",
      "      dtype='object', name=0)\n",
      "DataFrame 'DF_total_tom' column names:\n",
      "Index(['Total', 'Location', 'State', 'County', 'FIPS', 'total_male_tom',\n",
      "       'total_female_tom'],\n",
      "      dtype='object', name=0)\n",
      "DataFrame 'DF_total_hol' column names:\n",
      "Index(['Total', 'Location', 'State', 'County', 'FIPS', 'total_male_hol',\n",
      "       'total_female_hol'],\n",
      "      dtype='object', name=0)\n",
      "DataFrame 'DF_male_all' column names:\n",
      "Index([                         0,                          1,\n",
      "                                2,                          3,\n",
      "                                4,                          5,\n",
      "                                6,                          7,\n",
      "                                8,                          9,\n",
      "       ...\n",
      "                 '98  Years_perc',           '99  Years_perc',\n",
      "         '100 to 104  Years_perc',   '105 to 109  Years_perc',\n",
      "       '110  Years and Over_perc',                    'Total',\n",
      "                       'Location',                    'State',\n",
      "                         'County',                     'FIPS'],\n",
      "      dtype='object', length=212)\n",
      "DataFrame 'DF_female_all' column names:\n",
      "Index([                         0,                          1,\n",
      "                                2,                          3,\n",
      "                                4,                          5,\n",
      "                                6,                          7,\n",
      "                                8,                          9,\n",
      "       ...\n",
      "                 '98  Years_perc',           '99  Years_perc',\n",
      "         '100 to 104  Years_perc',   '105 to 109  Years_perc',\n",
      "       '110  Years and Over_perc',                    'Total',\n",
      "                       'Location',                    'State',\n",
      "                         'County',                     'FIPS'],\n",
      "      dtype='object', length=212)\n",
      "DataFrame 'DF_total_male_whi' column names:\n",
      "Index([                         0,                          1,\n",
      "                                2,                          3,\n",
      "                                4,                          5,\n",
      "                                6,                          7,\n",
      "                                8,                          9,\n",
      "       ...\n",
      "                 '98  Years_perc',           '99  Years_perc',\n",
      "         '100 to 104  Years_perc',   '105 to 109  Years_perc',\n",
      "       '110  Years and Over_perc',                    'Total',\n",
      "                       'Location',                    'State',\n",
      "                         'County',                     'FIPS'],\n",
      "      dtype='object', length=212)\n",
      "DataFrame 'DF_total_female_whi' column names:\n",
      "Index([                         0,                          1,\n",
      "                                2,                          3,\n",
      "                                4,                          5,\n",
      "                                6,                          7,\n",
      "                                8,                          9,\n",
      "       ...\n",
      "                 '98  Years_perc',           '99  Years_perc',\n",
      "         '100 to 104  Years_perc',   '105 to 109  Years_perc',\n",
      "       '110  Years and Over_perc',                    'Total',\n",
      "                       'Location',                    'State',\n",
      "                         'County',                     'FIPS'],\n",
      "      dtype='object', length=212)\n",
      "DataFrame 'DF_total_male_baa' column names:\n",
      "Index([                         0,                          1,\n",
      "                                2,                          3,\n",
      "                                4,                          5,\n",
      "                                6,                          7,\n",
      "                                8,                          9,\n",
      "       ...\n",
      "                 '98  Years_perc',           '99  Years_perc',\n",
      "         '100 to 104  Years_perc',   '105 to 109  Years_perc',\n",
      "       '110  Years and Over_perc',                    'Total',\n",
      "                       'Location',                    'State',\n",
      "                         'County',                     'FIPS'],\n",
      "      dtype='object', length=212)\n",
      "DataFrame 'DF_total_female_baa' column names:\n",
      "Index([                         0,                          1,\n",
      "                                2,                          3,\n",
      "                                4,                          5,\n",
      "                                6,                          7,\n",
      "                                8,                          9,\n",
      "       ...\n",
      "                 '98  Years_perc',           '99  Years_perc',\n",
      "         '100 to 104  Years_perc',   '105 to 109  Years_perc',\n",
      "       '110  Years and Over_perc',                    'Total',\n",
      "                       'Location',                    'State',\n",
      "                         'County',                     'FIPS'],\n",
      "      dtype='object', length=212)\n",
      "DataFrame 'DF_total_male_aian' column names:\n",
      "Index([                         0,                          1,\n",
      "                                2,                          3,\n",
      "                                4,                          5,\n",
      "                                6,                          7,\n",
      "                                8,                          9,\n",
      "       ...\n",
      "                 '98  Years_perc',           '99  Years_perc',\n",
      "         '100 to 104  Years_perc',   '105 to 109  Years_perc',\n",
      "       '110  Years and Over_perc',                    'Total',\n",
      "                       'Location',                    'State',\n",
      "                         'County',                     'FIPS'],\n",
      "      dtype='object', length=212)\n",
      "DataFrame 'DF_total_female_aian' column names:\n",
      "Index([                         0,                          1,\n",
      "                                2,                          3,\n",
      "                                4,                          5,\n",
      "                                6,                          7,\n",
      "                                8,                          9,\n",
      "       ...\n",
      "                 '98  Years_perc',           '99  Years_perc',\n",
      "         '100 to 104  Years_perc',   '105 to 109  Years_perc',\n",
      "       '110  Years and Over_perc',                    'Total',\n",
      "                       'Location',                    'State',\n",
      "                         'County',                     'FIPS'],\n",
      "      dtype='object', length=212)\n",
      "DataFrame 'DF_total_male_aa' column names:\n",
      "Index([                         0,                          1,\n",
      "                                2,                          3,\n",
      "                                4,                          5,\n",
      "                                6,                          7,\n",
      "                                8,                          9,\n",
      "       ...\n",
      "                 '98  Years_perc',           '99  Years_perc',\n",
      "         '100 to 104  Years_perc',   '105 to 109  Years_perc',\n",
      "       '110  Years and Over_perc',                    'Total',\n",
      "                       'Location',                    'State',\n",
      "                         'County',                     'FIPS'],\n",
      "      dtype='object', length=212)\n",
      "DataFrame 'DF_total_female_aa' column names:\n",
      "Index([                         0,                          1,\n",
      "                                2,                          3,\n",
      "                                4,                          5,\n",
      "                                6,                          7,\n",
      "                                8,                          9,\n",
      "       ...\n",
      "                 '98  Years_perc',           '99  Years_perc',\n",
      "         '100 to 104  Years_perc',   '105 to 109  Years_perc',\n",
      "       '110  Years and Over_perc',                    'Total',\n",
      "                       'Location',                    'State',\n",
      "                         'County',                     'FIPS'],\n",
      "      dtype='object', length=212)\n",
      "DataFrame 'DF_total_male_nhop' column names:\n",
      "Index([                         0,                          1,\n",
      "                                2,                          3,\n",
      "                                4,                          5,\n",
      "                                6,                          7,\n",
      "                                8,                          9,\n",
      "       ...\n",
      "                 '98  Years_perc',           '99  Years_perc',\n",
      "         '100 to 104  Years_perc',   '105 to 109  Years_perc',\n",
      "       '110  Years and Over_perc',                    'Total',\n",
      "                       'Location',                    'State',\n",
      "                         'County',                     'FIPS'],\n",
      "      dtype='object', length=212)\n",
      "DataFrame 'DF_total_female_nhop' column names:\n",
      "Index([                         0,                          1,\n",
      "                                2,                          3,\n",
      "                                4,                          5,\n",
      "                                6,                          7,\n",
      "                                8,                          9,\n",
      "       ...\n",
      "                 '98  Years_perc',           '99  Years_perc',\n",
      "         '100 to 104  Years_perc',   '105 to 109  Years_perc',\n",
      "       '110  Years and Over_perc',                    'Total',\n",
      "                       'Location',                    'State',\n",
      "                         'County',                     'FIPS'],\n",
      "      dtype='object', length=212)\n",
      "DataFrame 'DF_total_male_sor' column names:\n",
      "Index([                         0,                          1,\n",
      "                                2,                          3,\n",
      "                                4,                          5,\n",
      "                                6,                          7,\n",
      "                                8,                          9,\n",
      "       ...\n",
      "                 '98  Years_perc',           '99  Years_perc',\n",
      "         '100 to 104  Years_perc',   '105 to 109  Years_perc',\n",
      "       '110  Years and Over_perc',                    'Total',\n",
      "                       'Location',                    'State',\n",
      "                         'County',                     'FIPS'],\n",
      "      dtype='object', length=212)\n",
      "DataFrame 'DF_total_female_sor' column names:\n",
      "Index([                         0,                          1,\n",
      "                                2,                          3,\n",
      "                                4,                          5,\n",
      "                                6,                          7,\n",
      "                                8,                          9,\n",
      "       ...\n",
      "                 '98  Years_perc',           '99  Years_perc',\n",
      "         '100 to 104  Years_perc',   '105 to 109  Years_perc',\n",
      "       '110  Years and Over_perc',                    'Total',\n",
      "                       'Location',                    'State',\n",
      "                         'County',                     'FIPS'],\n",
      "      dtype='object', length=212)\n",
      "DataFrame 'DF_total_male_tom' column names:\n",
      "Index([                         0,                          1,\n",
      "                                2,                          3,\n",
      "                                4,                          5,\n",
      "                                6,                          7,\n",
      "                                8,                          9,\n",
      "       ...\n",
      "                 '98  Years_perc',           '99  Years_perc',\n",
      "         '100 to 104  Years_perc',   '105 to 109  Years_perc',\n",
      "       '110  Years and Over_perc',                    'Total',\n",
      "                       'Location',                    'State',\n",
      "                         'County',                     'FIPS'],\n",
      "      dtype='object', length=212)\n",
      "DataFrame 'DF_total_female_tom' column names:\n",
      "Index([                         0,                          1,\n",
      "                                2,                          3,\n",
      "                                4,                          5,\n",
      "                                6,                          7,\n",
      "                                8,                          9,\n",
      "       ...\n",
      "                 '98  Years_perc',           '99  Years_perc',\n",
      "         '100 to 104  Years_perc',   '105 to 109  Years_perc',\n",
      "       '110  Years and Over_perc',                    'Total',\n",
      "                       'Location',                    'State',\n",
      "                         'County',                     'FIPS'],\n",
      "      dtype='object', length=212)\n",
      "DataFrame 'DF_total_male_hol' column names:\n",
      "Index([                         0,                          1,\n",
      "                                2,                          3,\n",
      "                                4,                          5,\n",
      "                                6,                          7,\n",
      "                                8,                          9,\n",
      "       ...\n",
      "                 '98  Years_perc',           '99  Years_perc',\n",
      "         '100 to 104  Years_perc',   '105 to 109  Years_perc',\n",
      "       '110  Years and Over_perc',                    'Total',\n",
      "                       'Location',                    'State',\n",
      "                         'County',                     'FIPS'],\n",
      "      dtype='object', length=212)\n",
      "DataFrame 'DF_total_female_hol' column names:\n",
      "Index([                         0,                          1,\n",
      "                                2,                          3,\n",
      "                                4,                          5,\n",
      "                                6,                          7,\n",
      "                                8,                          9,\n",
      "       ...\n",
      "                 '98  Years_perc',           '99  Years_perc',\n",
      "         '100 to 104  Years_perc',   '105 to 109  Years_perc',\n",
      "       '110  Years and Over_perc',                    'Total',\n",
      "                       'Location',                    'State',\n",
      "                         'County',                     'FIPS'],\n",
      "      dtype='object', length=212)\n"
     ]
    }
   ],
   "source": [
    "# Verify the outcome\n",
    "for key, df in dfs.items():\n",
    "    print(f\"DataFrame '{key}' column names:\")\n",
    "    print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy needed cols from race df to total df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map the column prefixes to the corresponding dataframes\n",
    "column_map = {\n",
    "    'DF_total_all': ['DF_total_whi', 'DF_total_baa', 'DF_total_aian',\n",
    "                     'DF_total_aa', 'DF_total_nhop', 'DF_total_sor',\n",
    "                     'DF_total_tom', 'DF_total_hol'\n",
    "                     ]\n",
    "                }\n",
    "\n",
    "# Copy 'Total' column to the correct dataframes\n",
    "for key, value in column_map.items():\n",
    "    for df_name in value:\n",
    "        dfs[key][df_name[3:]] = dfs[df_name]['Total'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'DF_total_all' column names:\n",
      "Index(['Total', 'Location', 'State', 'County', 'FIPS', 'male_all',\n",
      "       'female_all', 'total_whi', 'total_baa', 'total_aian', 'total_aa',\n",
      "       'total_nhop', 'total_sor', 'total_tom', 'total_hol'],\n",
      "      dtype='object', name=0)\n"
     ]
    }
   ],
   "source": [
    "# Verify the outcome\n",
    "print(f\"DataFrame 'DF_total_all' column names:\")\n",
    "print(dfs['DF_total_all'].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Age totals for races from age DF to race DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs['DF_total_all'][column] = dfs['DF_male_all'][column] + dfs['DF_female_all'][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs['DF_total_all'][column] = dfs['DF_male_all'][column] + dfs['DF_female_all'][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs['DF_total_all'][column] = dfs['DF_male_all'][column] + dfs['DF_female_all'][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs['DF_total_all'][column] = dfs['DF_male_all'][column] + dfs['DF_female_all'][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs['DF_total_all'][column] = dfs['DF_male_all'][column] + dfs['DF_female_all'][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs['DF_total_all'][column] = dfs['DF_male_all'][column] + dfs['DF_female_all'][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs['DF_total_all'][column] = dfs['DF_male_all'][column] + dfs['DF_female_all'][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs['DF_total_all'][column] = dfs['DF_male_all'][column] + dfs['DF_female_all'][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs['DF_total_all'][column] = dfs['DF_male_all'][column] + dfs['DF_female_all'][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs['DF_total_all'][column] = dfs['DF_male_all'][column] + dfs['DF_female_all'][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs['DF_total_all'][column] = dfs['DF_male_all'][column] + dfs['DF_female_all'][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs['DF_total_all'][column] = dfs['DF_male_all'][column] + dfs['DF_female_all'][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs['DF_total_all'][column] = dfs['DF_male_all'][column] + dfs['DF_female_all'][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs['DF_total_all'][column] = dfs['DF_male_all'][column] + dfs['DF_female_all'][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs['DF_total_all'][column] = dfs['DF_male_all'][column] + dfs['DF_female_all'][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs['DF_total_all'][column] = dfs['DF_male_all'][column] + dfs['DF_female_all'][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs['DF_total_all'][column] = dfs['DF_male_all'][column] + dfs['DF_female_all'][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs['DF_total_all'][column] = dfs['DF_male_all'][column] + dfs['DF_female_all'][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\2186905214.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to map the column prefixes to the corresponding dataframes\n",
    "column_map = {\n",
    "    'DF_total_all': ['DF_male_all', 'DF_female_all'],\n",
    "    'DF_total_whi': ['DF_total_male_whi', 'DF_total_female_whi'],\n",
    "    'DF_total_baa': ['DF_total_male_baa', 'DF_total_female_baa'],\n",
    "    'DF_total_aian': ['DF_total_male_aian', 'DF_total_female_aian'],\n",
    "    'DF_total_aa': ['DF_total_male_aa', 'DF_total_female_aa'],\n",
    "    'DF_total_nhop': ['DF_total_male_nhop', 'DF_total_female_nhop'],\n",
    "    'DF_total_sor': ['DF_total_male_sor', 'DF_total_female_sor'],\n",
    "    'DF_total_tom': ['DF_total_male_tom', 'DF_total_female_tom'],\n",
    "    'DF_total_hol': ['DF_total_male_hol', 'DF_total_female_hol']\n",
    "}\n",
    "\n",
    "# Iterate through the columns and update the 'DF_total_all' dataframe using the column_map\n",
    "for column in cols_mod:\n",
    "    dfs['DF_total_all'][column] = dfs['DF_male_all'][column] + dfs['DF_female_all'][column]\n",
    "\n",
    "# Iterate through the column_map to update other dataframes\n",
    "for key, value in column_map.items():\n",
    "    for column in cols_mod:\n",
    "        dfs[key][column] = dfs[value[0]][column] + dfs[value[1]][column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'DF_total_all' after modification:\n",
      "0     Total                     Location State County   FIPS male_all  \\\n",
      "0     82217     Bullitt County, Kentucky    21    029  21029    40783   \n",
      "1     12371      Butler County, Kentucky    21    031  21031     6205   \n",
      "2     12649    Caldwell County, Kentucky    21    033  21033     6136   \n",
      "3     37103    Calloway County, Kentucky    21    035  21035    17906   \n",
      "4     11637    Magoffin County, Kentucky    21    153  21153     5722   \n",
      "...     ...                          ...   ...    ...    ...      ...   \n",
      "3216  17864    Haywood County, Tennessee    47    075  47075     8345   \n",
      "3217  27842  Henderson County, Tennessee    47    077  47077    13569   \n",
      "3218  34860         Howard County, Texas    48    227  48227    19687   \n",
      "3219   3202       Hudspeth County, Texas    48    229  48229     1684   \n",
      "3220  99956           Hunt County, Texas    48    231  48231    49310   \n",
      "\n",
      "0    female_all total_whi total_baa total_aian  ...  93  94  95  96  97  98  \\\n",
      "0         41434     75417      1045        212  ...  28  44  23  14   7   1   \n",
      "1          6166     11464        15         32  ...   3  13   5   0   1   1   \n",
      "2          6513     11244       674         25  ...  25  13  11   9  10   2   \n",
      "3         19197     32626      1313         64  ...  31  15  24  14   7   6   \n",
      "4          5915     11360        14         14  ...   8   3   5   3   1   0   \n",
      "...         ...       ...       ...        ...  ...  ..  ..  ..  ..  ..  ..   \n",
      "3216       9519      7695      9032         59  ...  15  24   7  11   3   4   \n",
      "3217      14273     24079      1950         70  ...  14  21  21  12   2   9   \n",
      "3218      15173     23664      1721        404  ...  25  35   8  12  16   8   \n",
      "3219       1518      1874        16         39  ...   2   2   0   0   0   0   \n",
      "3220      50646     70576      8014       1263  ...  61  43  29  22  16  13   \n",
      "\n",
      "0     99  102  107  110  \n",
      "0      8    7    1    0  \n",
      "1      0    0    0    0  \n",
      "2      0    2    6    0  \n",
      "3      8    3    0    1  \n",
      "4      0    3    1    0  \n",
      "...   ..  ...  ...  ...  \n",
      "3216   1    9    0    1  \n",
      "3217   1    3    2    0  \n",
      "3218   3    9    0    0  \n",
      "3219   0    2    0    0  \n",
      "3220  12    8    4    2  \n",
      "\n",
      "[3221 rows x 118 columns]\n",
      "\n",
      "DataFrame 'DF_total_whi' after modification:\n",
      "0     Total                     Location State County   FIPS total_male_whi  \\\n",
      "0     75417     Bullitt County, Kentucky    21    029  21029          37372   \n",
      "1     11464      Butler County, Kentucky    21    031  21031           5713   \n",
      "2     11244    Caldwell County, Kentucky    21    033  21033           5411   \n",
      "3     32626    Calloway County, Kentucky    21    035  21035          15632   \n",
      "4     11360    Magoffin County, Kentucky    21    153  21153           5588   \n",
      "...     ...                          ...   ...    ...    ...            ...   \n",
      "3216   7695    Haywood County, Tennessee    47    075  47075           3713   \n",
      "3217  24079  Henderson County, Tennessee    47    077  47077          11649   \n",
      "3218  23664         Howard County, Texas    48    227  48227          13750   \n",
      "3219   1874       Hudspeth County, Texas    48    229  48229           1021   \n",
      "3220  70576           Hunt County, Texas    48    231  48231          34834   \n",
      "\n",
      "0    total_female_whi    0    1    2  ...  93  94  95  96  97  98  99  102  \\\n",
      "0               38045  783  745  853  ...  27  42  23  13   7   1   8    7   \n",
      "1                5751  111  125  127  ...   3  12   5   0   0   1   0    0   \n",
      "2                5833  119  114  137  ...  23  13  11   9  10   2   0    2   \n",
      "3               16994  256  304  273  ...  31  15  24  14   7   6   8    3   \n",
      "4                5772  127  100  112  ...   8   3   5   3   1   0   0    3   \n",
      "...               ...  ...  ...  ...  ...  ..  ..  ..  ..  ..  ..  ..  ...   \n",
      "3216             3982   83   70   90  ...  13  14   3   7   2   4   1    1   \n",
      "3217            12430  273  228  248  ...  14  19  21   7   2   9   0    3   \n",
      "3218             9914  217  211  237  ...  25  28   3   5  13   3   3    8   \n",
      "3219              853   17   16    2  ...   2   2   0   0   0   0   0    1   \n",
      "3220            35742  710  687  782  ...  56  36  21  13  12  11   9    7   \n",
      "\n",
      "0     107  110  \n",
      "0       1    0  \n",
      "1       0    0  \n",
      "2       3    0  \n",
      "3       0    1  \n",
      "4       0    0  \n",
      "...   ...  ...  \n",
      "3216    0    0  \n",
      "3217    1    0  \n",
      "3218    0    0  \n",
      "3219    0    0  \n",
      "3220    2    0  \n",
      "\n",
      "[3221 rows x 110 columns]\n",
      "\n",
      "DataFrame 'DF_total_baa' after modification:\n",
      "0    Total                     Location State County   FIPS total_male_baa  \\\n",
      "0     1045     Bullitt County, Kentucky    21    029  21029            579   \n",
      "1       15      Butler County, Kentucky    21    031  21031             13   \n",
      "2      674    Caldwell County, Kentucky    21    033  21033            334   \n",
      "3     1313    Calloway County, Kentucky    21    035  21035            687   \n",
      "4       14    Magoffin County, Kentucky    21    153  21153              9   \n",
      "...    ...                          ...   ...    ...    ...            ...   \n",
      "3216  9032    Haywood County, Tennessee    47    075  47075           4074   \n",
      "3217  1950  Henderson County, Tennessee    47    077  47077            975   \n",
      "3218  1721         Howard County, Texas    48    227  48227           1040   \n",
      "3219    16       Hudspeth County, Texas    48    229  48229             10   \n",
      "3220  8014           Hunt County, Texas    48    231  48231           3866   \n",
      "\n",
      "0    total_female_baa   0   1    2  ...  93  94  95  96  97  98  99  102  107  \\\n",
      "0                 466  24  14   22  ...   0   0   0   0   0   0   0    0    0   \n",
      "1                   2   0   0    0  ...   0   0   0   0   0   0   0    0    0   \n",
      "2                 340   4  10    3  ...   0   0   0   0   0   0   0    0    3   \n",
      "3                 626  15  12   23  ...   0   0   0   0   0   0   0    0    0   \n",
      "4                   5   0   0    0  ...   0   0   0   0   0   0   0    0    1   \n",
      "...               ...  ..  ..  ...  ...  ..  ..  ..  ..  ..  ..  ..  ...  ...   \n",
      "3216             4958  98  86  122  ...   2  10   4   4   1   0   0    8    0   \n",
      "3217              975  26   9   28  ...   0   2   0   5   0   0   1    0    1   \n",
      "3218              681  27  41   27  ...   0   0   0   0   2   0   0    1    0   \n",
      "3219                6   0   2    0  ...   0   0   0   0   0   0   0    0    0   \n",
      "3220             4148  75  99   93  ...   0   5   7   2   2   1   0    0    0   \n",
      "\n",
      "0     110  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "...   ...  \n",
      "3216    0  \n",
      "3217    0  \n",
      "3218    0  \n",
      "3219    0  \n",
      "3220    0  \n",
      "\n",
      "[3221 rows x 110 columns]\n",
      "\n",
      "DataFrame 'DF_total_aian' after modification:\n",
      "0    Total                     Location State County   FIPS total_male_aian  \\\n",
      "0      212     Bullitt County, Kentucky    21    029  21029             119   \n",
      "1       32      Butler County, Kentucky    21    031  21031              16   \n",
      "2       25    Caldwell County, Kentucky    21    033  21033              15   \n",
      "3       64    Calloway County, Kentucky    21    035  21035              36   \n",
      "4       14    Magoffin County, Kentucky    21    153  21153               7   \n",
      "...    ...                          ...   ...    ...    ...             ...   \n",
      "3216    59    Haywood County, Tennessee    47    075  47075              15   \n",
      "3217    70  Henderson County, Tennessee    47    077  47077              45   \n",
      "3218   404         Howard County, Texas    48    227  48227             210   \n",
      "3219    39       Hudspeth County, Texas    48    229  48229              26   \n",
      "3220  1263           Hunt County, Texas    48    231  48231             637   \n",
      "\n",
      "0    total_female_aian  0   1   2  ...  93  94  95  96  97  98  99  102  107  \\\n",
      "0                   93  0   0   6  ...   0   0   0   0   0   0   0    0    0   \n",
      "1                   16  0   0   0  ...   0   0   0   0   0   0   0    0    0   \n",
      "2                   10  0   1   0  ...   0   0   0   0   0   0   0    0    0   \n",
      "3                   28  0   0   0  ...   0   0   0   0   0   0   0    0    0   \n",
      "4                    7  0   0   0  ...   0   0   0   0   0   0   0    0    0   \n",
      "...                ... ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..  ...  ...   \n",
      "3216                44  3   0   0  ...   0   0   0   0   0   0   0    0    0   \n",
      "3217                25  0   0   0  ...   0   0   0   0   0   0   0    0    0   \n",
      "3218               194  0   1   3  ...   0   0   0   0   0   0   0    0    0   \n",
      "3219                13  1   0   0  ...   0   0   0   0   0   0   0    0    0   \n",
      "3220               626  4  11  18  ...   0   0   0   0   0   1   0    0    0   \n",
      "\n",
      "0     110  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "...   ...  \n",
      "3216    0  \n",
      "3217    0  \n",
      "3218    0  \n",
      "3219    0  \n",
      "3220    0  \n",
      "\n",
      "[3221 rows x 110 columns]\n",
      "\n",
      "DataFrame 'DF_total_aa' after modification:\n",
      "0    Total                     Location State County   FIPS total_male_aa  \\\n",
      "0      451     Bullitt County, Kentucky    21    029  21029           188   \n",
      "1       23      Butler County, Kentucky    21    031  21031             8   \n",
      "2       56    Caldwell County, Kentucky    21    033  21033            24   \n",
      "3      435    Calloway County, Kentucky    21    035  21035           205   \n",
      "4        5    Magoffin County, Kentucky    21    153  21153             3   \n",
      "...    ...                          ...   ...    ...    ...           ...   \n",
      "3216    26    Haywood County, Tennessee    47    075  47075            10   \n",
      "3217    93  Henderson County, Tennessee    47    077  47077            34   \n",
      "3218   407         Howard County, Texas    48    227  48227           223   \n",
      "3219    10       Hudspeth County, Texas    48    229  48229             5   \n",
      "3220  1016           Hunt County, Texas    48    231  48231           422   \n",
      "\n",
      "0    total_female_aa  0  1   2  ...  93  94  95  96  97  98  99  102  107  110  \n",
      "0                263  0  1   3  ...   0   0   0   0   0   0   0    0    0    0  \n",
      "1                 15  0  0   4  ...   0   0   0   0   0   0   0    0    0    0  \n",
      "2                 32  2  1   0  ...   0   0   0   0   0   0   0    0    0    0  \n",
      "3                230  0  4   0  ...   0   0   0   0   0   0   0    0    0    0  \n",
      "4                  2  0  0   0  ...   0   0   0   0   0   0   0    0    0    0  \n",
      "...              ... .. ..  ..  ...  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  \n",
      "3216              16  0  0   0  ...   0   0   0   0   0   0   0    0    0    0  \n",
      "3217              59  4  0   0  ...   0   0   0   0   0   0   0    0    0    0  \n",
      "3218             184  0  8   0  ...   0   0   0   0   0   0   0    0    0    0  \n",
      "3219               5  0  0   0  ...   0   0   0   0   0   0   0    0    0    0  \n",
      "3220             594  2  7  13  ...   1   1   0   2   0   0   0    0    0    0  \n",
      "\n",
      "[3221 rows x 110 columns]\n",
      "\n",
      "DataFrame 'DF_total_nhop' after modification:\n",
      "0    Total                     Location State County   FIPS total_male_nhop  \\\n",
      "0       25     Bullitt County, Kentucky    21    029  21029               8   \n",
      "1        3      Butler County, Kentucky    21    031  21031               0   \n",
      "2        2    Caldwell County, Kentucky    21    033  21033               1   \n",
      "3       11    Calloway County, Kentucky    21    035  21035               6   \n",
      "4        6    Magoffin County, Kentucky    21    153  21153               1   \n",
      "...    ...                          ...   ...    ...    ...             ...   \n",
      "3216     9    Haywood County, Tennessee    47    075  47075               6   \n",
      "3217     2  Henderson County, Tennessee    47    077  47077               0   \n",
      "3218    24         Howard County, Texas    48    227  48227               9   \n",
      "3219     0       Hudspeth County, Texas    48    229  48229               0   \n",
      "3220   157           Hunt County, Texas    48    231  48231              88   \n",
      "\n",
      "0    total_female_nhop  0  1  2  ...  93  94  95  96  97  98  99  102  107  \\\n",
      "0                   17  0  0  1  ...   0   0   0   0   0   0   0    0    0   \n",
      "1                    3  0  0  0  ...   0   0   0   0   0   0   0    0    0   \n",
      "2                    1  0  0  0  ...   0   0   0   0   0   0   0    0    0   \n",
      "3                    5  0  0  0  ...   0   0   0   0   0   0   0    0    0   \n",
      "4                    5  0  0  0  ...   0   0   0   0   0   0   0    0    0   \n",
      "...                ... .. .. ..  ...  ..  ..  ..  ..  ..  ..  ..  ...  ...   \n",
      "3216                 3  0  0  0  ...   0   0   0   0   0   0   0    0    0   \n",
      "3217                 2  0  0  0  ...   0   0   0   0   0   0   0    0    0   \n",
      "3218                15  0  0  0  ...   0   0   0   0   0   0   0    0    0   \n",
      "3219                 0  0  0  0  ...   0   0   0   0   0   0   0    0    0   \n",
      "3220                69  5  5  1  ...   0   0   0   0   0   0   0    0    0   \n",
      "\n",
      "0     110  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "...   ...  \n",
      "3216    0  \n",
      "3217    0  \n",
      "3218    0  \n",
      "3219    0  \n",
      "3220    0  \n",
      "\n",
      "[3221 rows x 110 columns]\n",
      "\n",
      "DataFrame 'DF_total_sor' after modification:\n",
      "0    Total                     Location State County   FIPS total_male_sor  \\\n",
      "0      738     Bullitt County, Kentucky    21    029  21029            403   \n",
      "1      407      Butler County, Kentucky    21    031  21031            241   \n",
      "2       70    Caldwell County, Kentucky    21    033  21033             36   \n",
      "3      547    Calloway County, Kentucky    21    035  21035            326   \n",
      "4       32    Magoffin County, Kentucky    21    153  21153             17   \n",
      "...    ...                          ...   ...    ...    ...            ...   \n",
      "3216   524    Haywood County, Tennessee    47    075  47075            267   \n",
      "3217   354  Henderson County, Tennessee    47    077  47077            194   \n",
      "3218  3770         Howard County, Texas    48    227  48227           1926   \n",
      "3219   622       Hudspeth County, Texas    48    229  48229            308   \n",
      "3220  7398           Hunt County, Texas    48    231  48231           3853   \n",
      "\n",
      "0    total_female_sor    0    1    2  ...  93  94  95  96  97  98  99  102  \\\n",
      "0                 335   12   10   22  ...   0   0   0   0   0   0   0    0   \n",
      "1                 166   13   15   14  ...   0   0   0   0   1   0   0    0   \n",
      "2                  34    0    0    0  ...   0   0   0   0   0   0   0    0   \n",
      "3                 221    5   12   11  ...   0   0   0   0   0   0   0    0   \n",
      "4                  15    0    0    1  ...   0   0   0   0   0   0   0    0   \n",
      "...               ...  ...  ...  ...  ...  ..  ..  ..  ..  ..  ..  ..  ...   \n",
      "3216              257    6   12    2  ...   0   0   0   0   0   0   0    0   \n",
      "3217              160    2    9    4  ...   0   0   0   0   0   0   0    0   \n",
      "3218             1844   58   55   56  ...   0   6   1   2   0   0   0    0   \n",
      "3219              314    7    4    4  ...   0   0   0   0   0   0   0    0   \n",
      "3220             3545  110  115  132  ...   0   0   0   0   0   0   0    0   \n",
      "\n",
      "0     107  110  \n",
      "0       0    0  \n",
      "1       0    0  \n",
      "2       0    0  \n",
      "3       0    0  \n",
      "4       0    0  \n",
      "...   ...  ...  \n",
      "3216    0    0  \n",
      "3217    0    0  \n",
      "3218    0    0  \n",
      "3219    0    0  \n",
      "3220    0    1  \n",
      "\n",
      "[3221 rows x 110 columns]\n",
      "\n",
      "DataFrame 'DF_total_tom' after modification:\n",
      "0     Total                     Location State County   FIPS total_male_tom  \\\n",
      "0      4329     Bullitt County, Kentucky    21    029  21029           2114   \n",
      "1       427      Butler County, Kentucky    21    031  21031            214   \n",
      "2       578    Caldwell County, Kentucky    21    033  21033            315   \n",
      "3      2107    Calloway County, Kentucky    21    035  21035           1014   \n",
      "4       206    Magoffin County, Kentucky    21    153  21153             97   \n",
      "...     ...                          ...   ...    ...    ...            ...   \n",
      "3216    519    Haywood County, Tennessee    47    075  47075            260   \n",
      "3217   1294  Henderson County, Tennessee    47    077  47077            672   \n",
      "3218   4870         Howard County, Texas    48    227  48227           2529   \n",
      "3219    641       Hudspeth County, Texas    48    229  48229            314   \n",
      "3220  11532           Hunt County, Texas    48    231  48231           5610   \n",
      "\n",
      "0    total_female_tom    0    1    2  ...  93  94  95  96  97  98  99  102  \\\n",
      "0                2215   64   80   92  ...   1   2   0   1   0   0   0    0   \n",
      "1                 213    8    3    4  ...   0   1   0   0   0   0   0    0   \n",
      "2                 263   10   18    5  ...   2   0   0   0   0   0   0    0   \n",
      "3                1093   34   54   53  ...   0   0   0   0   0   0   0    0   \n",
      "4                 109    2    1    0  ...   0   0   0   0   0   0   0    0   \n",
      "...               ...  ...  ...  ...  ...  ..  ..  ..  ..  ..  ..  ..  ...   \n",
      "3216              259   15   12   11  ...   0   0   0   0   0   0   0    0   \n",
      "3217              622   28   32   30  ...   0   0   0   0   0   0   0    0   \n",
      "3218             2341   67   85   93  ...   0   1   4   5   1   5   0    0   \n",
      "3219              327    5    5    3  ...   0   0   0   0   0   0   0    1   \n",
      "3220             5922  226  182  237  ...   4   1   1   5   2   0   3    1   \n",
      "\n",
      "0     107  110  \n",
      "0       0    0  \n",
      "1       0    0  \n",
      "2       0    0  \n",
      "3       0    0  \n",
      "4       0    0  \n",
      "...   ...  ...  \n",
      "3216    0    1  \n",
      "3217    0    0  \n",
      "3218    0    0  \n",
      "3219    0    0  \n",
      "3220    2    1  \n",
      "\n",
      "[3221 rows x 110 columns]\n",
      "\n",
      "DataFrame 'DF_total_hol' after modification:\n",
      "0     Total                     Location State County   FIPS total_male_hol  \\\n",
      "0      2117     Bullitt County, Kentucky    21    029  21029           1100   \n",
      "1       592      Butler County, Kentucky    21    031  21031            326   \n",
      "2       198    Caldwell County, Kentucky    21    033  21033            115   \n",
      "3      1353    Calloway County, Kentucky    21    035  21035            722   \n",
      "4        66    Magoffin County, Kentucky    21    153  21153             35   \n",
      "...     ...                          ...   ...    ...    ...            ...   \n",
      "3216    838    Haywood County, Tennessee    47    075  47075            427   \n",
      "3217    719  Henderson County, Tennessee    47    077  47077            408   \n",
      "3218  16174         Howard County, Texas    48    227  48227          10021   \n",
      "3219   2036       Hudspeth County, Texas    48    229  48229           1011   \n",
      "3220  19673           Hunt County, Texas    48    231  48231          10086   \n",
      "\n",
      "0    total_female_hol    0    1    2  ...  93  94  95  96  97  98  99  102  \\\n",
      "0                1017   31   44   57  ...   0   0   0   0   0   0   0    0   \n",
      "1                 266   21   15   20  ...   0   0   0   0   1   0   0    0   \n",
      "2                  83    2    5    4  ...   0   0   0   0   0   0   0    0   \n",
      "3                 631   29   37   40  ...   0   0   0   0   0   0   0    0   \n",
      "4                  31    0    3    0  ...   0   0   0   0   0   0   0    0   \n",
      "...               ...  ...  ...  ...  ...  ..  ..  ..  ..  ..  ..  ..  ...   \n",
      "3216              411   21   12    7  ...   0   0   0   0   0   0   0    0   \n",
      "3217              311   12   22   15  ...   0   0   0   0   0   0   0    0   \n",
      "3218             6153  209  208  230  ...   0   8   5   9   1   7   0    0   \n",
      "3219             1025   30   27    7  ...   0   0   0   0   0   0   0    1   \n",
      "3220             9587  345  332  402  ...   3   0   4   6   2   0   4    1   \n",
      "\n",
      "0     107  110  \n",
      "0       0    0  \n",
      "1       0    0  \n",
      "2       0    0  \n",
      "3       0    0  \n",
      "4       0    0  \n",
      "...   ...  ...  \n",
      "3216    0    0  \n",
      "3217    0    0  \n",
      "3218    0    0  \n",
      "3219    0    0  \n",
      "3220    0    2  \n",
      "\n",
      "[3221 rows x 110 columns]\n",
      "\n",
      "DataFrame 'DF_male_all' after modification:\n",
      "        0    1    2    3    4    5    6    7    8    9  ...  98  Years_perc  \\\n",
      "0     437  450  511  484  513  525  576  559  549  564  ...        0.000025   \n",
      "1      70   70   84   91   80   90  116   67   97   81  ...        0.000000   \n",
      "2      72   80   83   60   82   78   69   84   67   90  ...        0.000163   \n",
      "3     157  203  182  171  192  161  202  186  158  184  ...        0.000000   \n",
      "4      64   51   65   60   62   79   85   71   76   71  ...        0.000000   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...             ...   \n",
      "3216   98   86  120  100  109  120  115   96  114   96  ...        0.000359   \n",
      "3217  183  124  170  184  175  185  185  160  188  197  ...        0.000074   \n",
      "3218  190  218  223  195  287  247  211  223  237  185  ...        0.000203   \n",
      "3219   20   10    4   14    9   10   16   17   18   11  ...        0.000000   \n",
      "3220  593  582  669  639  691  704  658  650  687  618  ...        0.000020   \n",
      "\n",
      "      99  Years_perc  100 to 104  Years_perc  105 to 109  Years_perc  \\\n",
      "0           0.000000                0.000000                0.000000   \n",
      "1           0.000000                0.000000                0.000000   \n",
      "2           0.000000                0.000163                0.000326   \n",
      "3           0.000000                0.000000                0.000000   \n",
      "4           0.000000                0.000175                0.000175   \n",
      "...              ...                     ...                     ...   \n",
      "3216        0.000120                0.000120                0.000000   \n",
      "3217        0.000000                0.000074                0.000000   \n",
      "3218        0.000102                0.000254                0.000000   \n",
      "3219        0.000000                0.000594                0.000000   \n",
      "3220        0.000000                0.000081                0.000000   \n",
      "\n",
      "      110  Years and Over_perc  Total                     Location  State  \\\n",
      "0                      0.00000  40783     Bullitt County, Kentucky     21   \n",
      "1                      0.00000   6205      Butler County, Kentucky     21   \n",
      "2                      0.00000   6136    Caldwell County, Kentucky     21   \n",
      "3                      0.00000  17906    Calloway County, Kentucky     21   \n",
      "4                      0.00000   5722    Magoffin County, Kentucky     21   \n",
      "...                        ...    ...                          ...    ...   \n",
      "3216                   0.00012   8345    Haywood County, Tennessee     47   \n",
      "3217                   0.00000  13569  Henderson County, Tennessee     47   \n",
      "3218                   0.00000  19687         Howard County, Texas     48   \n",
      "3219                   0.00000   1684       Hudspeth County, Texas     48   \n",
      "3220                   0.00000  49310           Hunt County, Texas     48   \n",
      "\n",
      "      County   FIPS  \n",
      "0        029  21029  \n",
      "1        031  21031  \n",
      "2        033  21033  \n",
      "3        035  21035  \n",
      "4        153  21153  \n",
      "...      ...    ...  \n",
      "3216     075  47075  \n",
      "3217     077  47077  \n",
      "3218     227  48227  \n",
      "3219     229  48229  \n",
      "3220     231  48231  \n",
      "\n",
      "[3221 rows x 212 columns]\n",
      "\n",
      "DataFrame 'DF_female_all' after modification:\n",
      "        0    1    2    3    4    5    6    7    8    9  ...  98  Years_perc  \\\n",
      "0     446  400  488  471  514  517  492  470  464  549  ...        0.000000   \n",
      "1      62   73   65   71   87   70   84   76   77   87  ...        0.000162   \n",
      "2      63   64   62   69   44   89   78   77   74   71  ...        0.000154   \n",
      "3     153  183  178  190  217  193  173  181  195  199  ...        0.000313   \n",
      "4      65   50   48   54   79   46   63   69   58   58  ...        0.000000   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...             ...   \n",
      "3216  107   94  105  101  105  108  116  101  100  103  ...        0.000105   \n",
      "3217  150  154  140  148  149  160  172  155  136  145  ...        0.000560   \n",
      "3218  179  183  193  217  221  197  218  204  225  206  ...        0.000264   \n",
      "3219   10   17    5    8   30   21   10   23    8   10  ...        0.000000   \n",
      "3220  539  524  607  619  606  633  633  668  618  654  ...        0.000237   \n",
      "\n",
      "      99  Years_perc  100 to 104  Years_perc  105 to 109  Years_perc  \\\n",
      "0           0.000193                0.000169                0.000024   \n",
      "1           0.000000                0.000000                0.000000   \n",
      "2           0.000000                0.000154                0.000614   \n",
      "3           0.000417                0.000156                0.000000   \n",
      "4           0.000000                0.000338                0.000000   \n",
      "...              ...                     ...                     ...   \n",
      "3216        0.000000                0.000840                0.000000   \n",
      "3217        0.000070                0.000140                0.000140   \n",
      "3218        0.000066                0.000264                0.000000   \n",
      "3219        0.000000                0.000659                0.000000   \n",
      "3220        0.000237                0.000079                0.000079   \n",
      "\n",
      "      110  Years and Over_perc  Total                     Location  State  \\\n",
      "0                     0.000000  41434     Bullitt County, Kentucky     21   \n",
      "1                     0.000000   6166      Butler County, Kentucky     21   \n",
      "2                     0.000000   6513    Caldwell County, Kentucky     21   \n",
      "3                     0.000052  19197    Calloway County, Kentucky     21   \n",
      "4                     0.000000   5915    Magoffin County, Kentucky     21   \n",
      "...                        ...    ...                          ...    ...   \n",
      "3216                  0.000000   9519    Haywood County, Tennessee     47   \n",
      "3217                  0.000000  14273  Henderson County, Tennessee     47   \n",
      "3218                  0.000000  15173         Howard County, Texas     48   \n",
      "3219                  0.000000   1518       Hudspeth County, Texas     48   \n",
      "3220                  0.000039  50646           Hunt County, Texas     48   \n",
      "\n",
      "      County   FIPS  \n",
      "0        029  21029  \n",
      "1        031  21031  \n",
      "2        033  21033  \n",
      "3        035  21035  \n",
      "4        153  21153  \n",
      "...      ...    ...  \n",
      "3216     075  47075  \n",
      "3217     077  47077  \n",
      "3218     227  48227  \n",
      "3219     229  48229  \n",
      "3220     231  48231  \n",
      "\n",
      "[3221 rows x 212 columns]\n",
      "\n",
      "DataFrame 'DF_total_male_whi' after modification:\n",
      "        0    1    2    3    4    5    6    7    8    9  ...  98  Years_perc  \\\n",
      "0     395  391  442  418  440  444  490  499  493  501  ...        0.000027   \n",
      "1      66   63   69   81   65   82   94   56   88   80  ...        0.000000   \n",
      "2      63   66   77   45   69   68   60   68   45   80  ...        0.000185   \n",
      "3     124  155  150  141  162  141  181  157  130  158  ...        0.000000   \n",
      "4      64   50   65   57   59   79   84   71   76   71  ...        0.000000   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...             ...   \n",
      "3216   34   31   50   37   42   33   32   44   56   28  ...        0.000808   \n",
      "3217  154  101  126  147  138  161  152  136  161  169  ...        0.000086   \n",
      "3218  122  118  141  128  164  148  119  137  132  103  ...        0.000000   \n",
      "3219    9    9    0    9    8    7   11    3   13    4  ...        0.000000   \n",
      "3220  351  359  435  415  432  422  421  430  429  390  ...        0.000029   \n",
      "\n",
      "      99  Years_perc  100 to 104  Years_perc  105 to 109  Years_perc  \\\n",
      "0           0.000000                0.000000                 0.00000   \n",
      "1           0.000000                0.000000                 0.00000   \n",
      "2           0.000000                0.000185                 0.00037   \n",
      "3           0.000000                0.000000                 0.00000   \n",
      "4           0.000000                0.000179                 0.00000   \n",
      "...              ...                     ...                     ...   \n",
      "3216        0.000269                0.000269                 0.00000   \n",
      "3217        0.000000                0.000086                 0.00000   \n",
      "3218        0.000145                0.000364                 0.00000   \n",
      "3219        0.000000                0.000979                 0.00000   \n",
      "3220        0.000000                0.000086                 0.00000   \n",
      "\n",
      "      110  Years and Over_perc  Total                     Location  State  \\\n",
      "0                          0.0  37372     Bullitt County, Kentucky     21   \n",
      "1                          0.0   5713      Butler County, Kentucky     21   \n",
      "2                          0.0   5411    Caldwell County, Kentucky     21   \n",
      "3                          0.0  15632    Calloway County, Kentucky     21   \n",
      "4                          0.0   5588    Magoffin County, Kentucky     21   \n",
      "...                        ...    ...                          ...    ...   \n",
      "3216                       0.0   3713    Haywood County, Tennessee     47   \n",
      "3217                       0.0  11649  Henderson County, Tennessee     47   \n",
      "3218                       0.0  13750         Howard County, Texas     48   \n",
      "3219                       0.0   1021       Hudspeth County, Texas     48   \n",
      "3220                       0.0  34834           Hunt County, Texas     48   \n",
      "\n",
      "      County   FIPS  \n",
      "0        029  21029  \n",
      "1        031  21031  \n",
      "2        033  21033  \n",
      "3        035  21035  \n",
      "4        153  21153  \n",
      "...      ...    ...  \n",
      "3216     075  47075  \n",
      "3217     077  47077  \n",
      "3218     227  48227  \n",
      "3219     229  48229  \n",
      "3220     231  48231  \n",
      "\n",
      "[3221 rows x 212 columns]\n",
      "\n",
      "DataFrame 'DF_total_female_whi' after modification:\n",
      "        0    1    2    3    4    5    6    7    8    9  ...  98  Years_perc  \\\n",
      "0     388  354  411  415  440  473  437  407  414  466  ...        0.000000   \n",
      "1      45   62   58   54   75   60   77   73   67   77  ...        0.000174   \n",
      "2      56   48   60   58   41   70   70   68   73   48  ...        0.000171   \n",
      "3     132  149  123  154  171  157  143  145  151  185  ...        0.000353   \n",
      "4      63   50   47   50   73   41   59   65   58   56  ...        0.000000   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...             ...   \n",
      "3216   49   39   40   42   37   27   32   35   29   26  ...        0.000251   \n",
      "3217  119  127  122  134  132  141  141  119  112  119  ...        0.000644   \n",
      "3218   95   93   96  130  119   96  126  117  119  126  ...        0.000303   \n",
      "3219    8    7    2    4    5    3    2   12    2    0  ...        0.000000   \n",
      "3220  359  328  347  377  398  389  403  420  377  396  ...        0.000280   \n",
      "\n",
      "      99  Years_perc  100 to 104  Years_perc  105 to 109  Years_perc  \\\n",
      "0           0.000210                0.000184                0.000026   \n",
      "1           0.000000                0.000000                0.000000   \n",
      "2           0.000000                0.000171                0.000171   \n",
      "3           0.000471                0.000177                0.000000   \n",
      "4           0.000000                0.000347                0.000000   \n",
      "...              ...                     ...                     ...   \n",
      "3216        0.000000                0.000000                0.000000   \n",
      "3217        0.000000                0.000161                0.000080   \n",
      "3218        0.000101                0.000303                0.000000   \n",
      "3219        0.000000                0.000000                0.000000   \n",
      "3220        0.000252                0.000112                0.000056   \n",
      "\n",
      "      110  Years and Over_perc  Total                     Location  State  \\\n",
      "0                     0.000000  38045     Bullitt County, Kentucky     21   \n",
      "1                     0.000000   5751      Butler County, Kentucky     21   \n",
      "2                     0.000000   5833    Caldwell County, Kentucky     21   \n",
      "3                     0.000059  16994    Calloway County, Kentucky     21   \n",
      "4                     0.000000   5772    Magoffin County, Kentucky     21   \n",
      "...                        ...    ...                          ...    ...   \n",
      "3216                  0.000000   3982    Haywood County, Tennessee     47   \n",
      "3217                  0.000000  12430  Henderson County, Tennessee     47   \n",
      "3218                  0.000000   9914         Howard County, Texas     48   \n",
      "3219                  0.000000    853       Hudspeth County, Texas     48   \n",
      "3220                  0.000000  35742           Hunt County, Texas     48   \n",
      "\n",
      "      County   FIPS  \n",
      "0        029  21029  \n",
      "1        031  21031  \n",
      "2        033  21033  \n",
      "3        035  21035  \n",
      "4        153  21153  \n",
      "...      ...    ...  \n",
      "3216     075  47075  \n",
      "3217     077  47077  \n",
      "3218     227  48227  \n",
      "3219     229  48229  \n",
      "3220     231  48231  \n",
      "\n",
      "[3221 rows x 212 columns]\n",
      "\n",
      "DataFrame 'DF_total_male_baa' after modification:\n",
      "       0   1   2   3   4   5   6   7   8   9  ...  98  Years_perc  \\\n",
      "0     12   1   9   7  10   8  17  12  13   7  ...             0.0   \n",
      "1      0   0   0   0   0   0   0   0   0   0  ...             0.0   \n",
      "2      2   0   1   1   5   3   2   4   8   5  ...             0.0   \n",
      "3     12   3  13   0   6   1   1   0   1   8  ...             0.0   \n",
      "4      0   0   0   1   0   0   0   0   0   0  ...             0.0   \n",
      "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...             ...   \n",
      "3216  50  44  64  60  58  67  76  48  47  60  ...             0.0   \n",
      "3217  12   5  20   6  13   5  11  10   8   6  ...             0.0   \n",
      "3218  13  24  16   5  11  11  12  16  25  13  ...             0.0   \n",
      "3219   0   0   0   0   0   0   0   3   0   0  ...             0.0   \n",
      "3220  36  41  48  57  53  64  52  46  57  45  ...             0.0   \n",
      "\n",
      "      99  Years_perc  100 to 104  Years_perc  105 to 109  Years_perc  \\\n",
      "0                0.0                     0.0                0.000000   \n",
      "1                0.0                     0.0                0.000000   \n",
      "2                0.0                     0.0                0.000000   \n",
      "3                0.0                     0.0                0.000000   \n",
      "4                0.0                     0.0                0.111111   \n",
      "...              ...                     ...                     ...   \n",
      "3216             0.0                     0.0                0.000000   \n",
      "3217             0.0                     0.0                0.000000   \n",
      "3218             0.0                     0.0                0.000000   \n",
      "3219             0.0                     0.0                0.000000   \n",
      "3220             0.0                     0.0                0.000000   \n",
      "\n",
      "      110  Years and Over_perc  Total                     Location  State  \\\n",
      "0                          0.0    579     Bullitt County, Kentucky     21   \n",
      "1                          0.0     13      Butler County, Kentucky     21   \n",
      "2                          0.0    334    Caldwell County, Kentucky     21   \n",
      "3                          0.0    687    Calloway County, Kentucky     21   \n",
      "4                          0.0      9    Magoffin County, Kentucky     21   \n",
      "...                        ...    ...                          ...    ...   \n",
      "3216                       0.0   4074    Haywood County, Tennessee     47   \n",
      "3217                       0.0    975  Henderson County, Tennessee     47   \n",
      "3218                       0.0   1040         Howard County, Texas     48   \n",
      "3219                       0.0     10       Hudspeth County, Texas     48   \n",
      "3220                       0.0   3866           Hunt County, Texas     48   \n",
      "\n",
      "      County   FIPS  \n",
      "0        029  21029  \n",
      "1        031  21031  \n",
      "2        033  21033  \n",
      "3        035  21035  \n",
      "4        153  21153  \n",
      "...      ...    ...  \n",
      "3216     075  47075  \n",
      "3217     077  47077  \n",
      "3218     227  48227  \n",
      "3219     229  48229  \n",
      "3220     231  48231  \n",
      "\n",
      "[3221 rows x 212 columns]\n",
      "\n",
      "DataFrame 'DF_total_female_baa' after modification:\n",
      "       0   1   2   3   4   5   6   7   8   9  ...  98  Years_perc  \\\n",
      "0     12  13  13   2  10  13   1   2   5   7  ...        0.000000   \n",
      "1      0   0   0   0   0   0   0   0   0   0  ...        0.000000   \n",
      "2      2  10   2   5   1  13   1   2   0  10  ...        0.000000   \n",
      "3      3   9  10  10   0   0  12   8  15   0  ...        0.000000   \n",
      "4      0   0   0   0   0   0   0   0   0   0  ...        0.000000   \n",
      "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...             ...   \n",
      "3216  48  42  58  51  57  54  72  56  58  62  ...        0.000000   \n",
      "3217  14   4   8   3   2  12  12  11  13  14  ...        0.000000   \n",
      "3218  14  17  11  16  22  15  21  14  16  14  ...        0.000000   \n",
      "3219   0   2   0   0   0   0   0   0   0   0  ...        0.000000   \n",
      "3220  39  58  45  44  55  41  42  50  41  47  ...        0.000241   \n",
      "\n",
      "      99  Years_perc  100 to 104  Years_perc  105 to 109  Years_perc  \\\n",
      "0           0.000000                0.000000                0.000000   \n",
      "1           0.000000                0.000000                0.000000   \n",
      "2           0.000000                0.000000                0.008824   \n",
      "3           0.000000                0.000000                0.000000   \n",
      "4           0.000000                0.000000                0.000000   \n",
      "...              ...                     ...                     ...   \n",
      "3216        0.000000                0.001614                0.000000   \n",
      "3217        0.001026                0.000000                0.001026   \n",
      "3218        0.000000                0.001468                0.000000   \n",
      "3219        0.000000                0.000000                0.000000   \n",
      "3220        0.000000                0.000000                0.000000   \n",
      "\n",
      "      110  Years and Over_perc  Total                     Location  State  \\\n",
      "0                          0.0    466     Bullitt County, Kentucky     21   \n",
      "1                          0.0      2      Butler County, Kentucky     21   \n",
      "2                          0.0    340    Caldwell County, Kentucky     21   \n",
      "3                          0.0    626    Calloway County, Kentucky     21   \n",
      "4                          0.0      5    Magoffin County, Kentucky     21   \n",
      "...                        ...    ...                          ...    ...   \n",
      "3216                       0.0   4958    Haywood County, Tennessee     47   \n",
      "3217                       0.0    975  Henderson County, Tennessee     47   \n",
      "3218                       0.0    681         Howard County, Texas     48   \n",
      "3219                       0.0      6       Hudspeth County, Texas     48   \n",
      "3220                       0.0   4148           Hunt County, Texas     48   \n",
      "\n",
      "      County   FIPS  \n",
      "0        029  21029  \n",
      "1        031  21031  \n",
      "2        033  21033  \n",
      "3        035  21035  \n",
      "4        153  21153  \n",
      "...      ...    ...  \n",
      "3216     075  47075  \n",
      "3217     077  47077  \n",
      "3218     227  48227  \n",
      "3219     229  48229  \n",
      "3220     231  48231  \n",
      "\n",
      "[3221 rows x 212 columns]\n",
      "\n",
      "DataFrame 'DF_total_male_aian' after modification:\n",
      "      0  1  2  3  4  5  6  7  8  9  ...  98  Years_perc  99  Years_perc  \\\n",
      "0     0  0  2  2  1  2  0  4  2  0  ...             0.0             0.0   \n",
      "1     0  0  0  0  0  0  0  0  0  0  ...             0.0             0.0   \n",
      "2     0  1  0  0  0  0  0  0  0  0  ...             0.0             0.0   \n",
      "3     0  0  0  2  0  0  0  0  0  0  ...             0.0             0.0   \n",
      "4     0  0  0  0  0  0  0  0  0  0  ...             0.0             0.0   \n",
      "...  .. .. .. .. .. .. .. .. .. ..  ...             ...             ...   \n",
      "3216  0  0  0  0  0  0  0  0  0  0  ...             0.0             0.0   \n",
      "3217  0  0  0  0  0  0  0  1  0  0  ...             0.0             0.0   \n",
      "3218  0  1  0  0  0  3  1  0  0  1  ...             0.0             0.0   \n",
      "3219  1  0  0  0  0  1  1  0  0  2  ...             0.0             0.0   \n",
      "3220  4  8  5  5  4  7  9  0  1  7  ...             0.0             0.0   \n",
      "\n",
      "      100 to 104  Years_perc  105 to 109  Years_perc  \\\n",
      "0                        0.0                     0.0   \n",
      "1                        0.0                     0.0   \n",
      "2                        0.0                     0.0   \n",
      "3                        0.0                     0.0   \n",
      "4                        0.0                     0.0   \n",
      "...                      ...                     ...   \n",
      "3216                     0.0                     0.0   \n",
      "3217                     0.0                     0.0   \n",
      "3218                     0.0                     0.0   \n",
      "3219                     0.0                     0.0   \n",
      "3220                     0.0                     0.0   \n",
      "\n",
      "      110  Years and Over_perc  Total                     Location  State  \\\n",
      "0                          0.0    119     Bullitt County, Kentucky     21   \n",
      "1                          0.0     16      Butler County, Kentucky     21   \n",
      "2                          0.0     15    Caldwell County, Kentucky     21   \n",
      "3                          0.0     36    Calloway County, Kentucky     21   \n",
      "4                          0.0      7    Magoffin County, Kentucky     21   \n",
      "...                        ...    ...                          ...    ...   \n",
      "3216                       0.0     15    Haywood County, Tennessee     47   \n",
      "3217                       0.0     45  Henderson County, Tennessee     47   \n",
      "3218                       0.0    210         Howard County, Texas     48   \n",
      "3219                       0.0     26       Hudspeth County, Texas     48   \n",
      "3220                       0.0    637           Hunt County, Texas     48   \n",
      "\n",
      "      County   FIPS  \n",
      "0        029  21029  \n",
      "1        031  21031  \n",
      "2        033  21033  \n",
      "3        035  21035  \n",
      "4        153  21153  \n",
      "...      ...    ...  \n",
      "3216     075  47075  \n",
      "3217     077  47077  \n",
      "3218     227  48227  \n",
      "3219     229  48229  \n",
      "3220     231  48231  \n",
      "\n",
      "[3221 rows x 212 columns]\n",
      "\n",
      "DataFrame 'DF_total_female_aian' after modification:\n",
      "      0  1   2  3  4   5   6  7  8  9  ...  98  Years_perc  99  Years_perc  \\\n",
      "0     0  0   4  2  1   0   0  0  0  0  ...        0.000000             0.0   \n",
      "1     0  0   0  0  0   0   0  0  0  0  ...        0.000000             0.0   \n",
      "2     0  0   0  0  0   0   0  0  0  0  ...        0.000000             0.0   \n",
      "3     0  0   0  0  0   0   0  2  0  0  ...        0.000000             0.0   \n",
      "4     0  0   0  0  1   0   0  0  0  0  ...        0.000000             0.0   \n",
      "...  .. ..  .. .. ..  ..  .. .. .. ..  ...             ...             ...   \n",
      "3216  3  0   0  0  0   0   0  0  0  0  ...        0.000000             0.0   \n",
      "3217  0  0   0  0  0   0   0  0  0  1  ...        0.000000             0.0   \n",
      "3218  0  0   3  0  1  11   0  4  1  0  ...        0.000000             0.0   \n",
      "3219  0  0   0  0  0   0   0  0  0  0  ...        0.000000             0.0   \n",
      "3220  0  3  13  6  2   5  12  7  0  4  ...        0.001597             0.0   \n",
      "\n",
      "      100 to 104  Years_perc  105 to 109  Years_perc  \\\n",
      "0                        0.0                     0.0   \n",
      "1                        0.0                     0.0   \n",
      "2                        0.0                     0.0   \n",
      "3                        0.0                     0.0   \n",
      "4                        0.0                     0.0   \n",
      "...                      ...                     ...   \n",
      "3216                     0.0                     0.0   \n",
      "3217                     0.0                     0.0   \n",
      "3218                     0.0                     0.0   \n",
      "3219                     0.0                     0.0   \n",
      "3220                     0.0                     0.0   \n",
      "\n",
      "      110  Years and Over_perc  Total                     Location  State  \\\n",
      "0                          0.0     93     Bullitt County, Kentucky     21   \n",
      "1                          0.0     16      Butler County, Kentucky     21   \n",
      "2                          0.0     10    Caldwell County, Kentucky     21   \n",
      "3                          0.0     28    Calloway County, Kentucky     21   \n",
      "4                          0.0      7    Magoffin County, Kentucky     21   \n",
      "...                        ...    ...                          ...    ...   \n",
      "3216                       0.0     44    Haywood County, Tennessee     47   \n",
      "3217                       0.0     25  Henderson County, Tennessee     47   \n",
      "3218                       0.0    194         Howard County, Texas     48   \n",
      "3219                       0.0     13       Hudspeth County, Texas     48   \n",
      "3220                       0.0    626           Hunt County, Texas     48   \n",
      "\n",
      "      County   FIPS  \n",
      "0        029  21029  \n",
      "1        031  21031  \n",
      "2        033  21033  \n",
      "3        035  21035  \n",
      "4        153  21153  \n",
      "...      ...    ...  \n",
      "3216     075  47075  \n",
      "3217     077  47077  \n",
      "3218     227  48227  \n",
      "3219     229  48229  \n",
      "3220     231  48231  \n",
      "\n",
      "[3221 rows x 212 columns]\n",
      "\n",
      "DataFrame 'DF_total_male_aa' after modification:\n",
      "      0  1  2  3  4   5  6  7  8  9  ...  98  Years_perc  99  Years_perc  \\\n",
      "0     0  0  0  4  8   1  7  0  0  3  ...             0.0             0.0   \n",
      "1     0  0  0  0  0   0  0  0  0  0  ...             0.0             0.0   \n",
      "2     1  1  0  1  0   2  0  1  0  0  ...             0.0             0.0   \n",
      "3     0  3  0  0  3   2  0  0  8  5  ...             0.0             0.0   \n",
      "4     0  0  0  0  0   0  0  0  0  0  ...             0.0             0.0   \n",
      "...  .. .. .. .. ..  .. .. .. .. ..  ...             ...             ...   \n",
      "3216  0  0  0  0  0   0  0  0  0  0  ...             0.0             0.0   \n",
      "3217  3  0  0  1  0   0  0  0  0  2  ...             0.0             0.0   \n",
      "3218  0  0  0  0  6   1  0  5  0  6  ...             0.0             0.0   \n",
      "3219  0  0  0  0  0   0  0  0  0  0  ...             0.0             0.0   \n",
      "3220  2  4  3  0  0  11  9  0  6  1  ...             0.0             0.0   \n",
      "\n",
      "      100 to 104  Years_perc  105 to 109  Years_perc  \\\n",
      "0                        0.0                     0.0   \n",
      "1                        0.0                     0.0   \n",
      "2                        0.0                     0.0   \n",
      "3                        0.0                     0.0   \n",
      "4                        0.0                     0.0   \n",
      "...                      ...                     ...   \n",
      "3216                     0.0                     0.0   \n",
      "3217                     0.0                     0.0   \n",
      "3218                     0.0                     0.0   \n",
      "3219                     0.0                     0.0   \n",
      "3220                     0.0                     0.0   \n",
      "\n",
      "      110  Years and Over_perc  Total                     Location  State  \\\n",
      "0                          0.0    188     Bullitt County, Kentucky     21   \n",
      "1                          0.0      8      Butler County, Kentucky     21   \n",
      "2                          0.0     24    Caldwell County, Kentucky     21   \n",
      "3                          0.0    205    Calloway County, Kentucky     21   \n",
      "4                          0.0      3    Magoffin County, Kentucky     21   \n",
      "...                        ...    ...                          ...    ...   \n",
      "3216                       0.0     10    Haywood County, Tennessee     47   \n",
      "3217                       0.0     34  Henderson County, Tennessee     47   \n",
      "3218                       0.0    223         Howard County, Texas     48   \n",
      "3219                       0.0      5       Hudspeth County, Texas     48   \n",
      "3220                       0.0    422           Hunt County, Texas     48   \n",
      "\n",
      "      County   FIPS  \n",
      "0        029  21029  \n",
      "1        031  21031  \n",
      "2        033  21033  \n",
      "3        035  21035  \n",
      "4        153  21153  \n",
      "...      ...    ...  \n",
      "3216     075  47075  \n",
      "3217     077  47077  \n",
      "3218     227  48227  \n",
      "3219     229  48229  \n",
      "3220     231  48231  \n",
      "\n",
      "[3221 rows x 212 columns]\n",
      "\n",
      "DataFrame 'DF_total_female_aa' after modification:\n",
      "      0  1   2   3  4   5  6  7  8   9  ...  98  Years_perc  99  Years_perc  \\\n",
      "0     0  1   3   1  0   2  2  6  3  15  ...             0.0             0.0   \n",
      "1     0  0   4   0  0   0  0  0  0   0  ...             0.0             0.0   \n",
      "2     1  0   0   0  0   0  0  0  1   0  ...             0.0             0.0   \n",
      "3     0  1   0   3  3   5  3  1  9   1  ...             0.0             0.0   \n",
      "4     0  0   0   0  0   0  0  0  0   0  ...             0.0             0.0   \n",
      "...  .. ..  ..  .. ..  .. .. .. ..  ..  ...             ...             ...   \n",
      "3216  0  0   0   0  0   0  0  0  0   0  ...             0.0             0.0   \n",
      "3217  1  0   0   0  0   0  2  0  2   0  ...             0.0             0.0   \n",
      "3218  0  8   0   1  5   3  0  0  3   4  ...             0.0             0.0   \n",
      "3219  0  0   0   0  0   0  0  0  0   0  ...             0.0             0.0   \n",
      "3220  0  3  10  11  5  13  7  0  0   6  ...             0.0             0.0   \n",
      "\n",
      "      100 to 104  Years_perc  105 to 109  Years_perc  \\\n",
      "0                        0.0                     0.0   \n",
      "1                        0.0                     0.0   \n",
      "2                        0.0                     0.0   \n",
      "3                        0.0                     0.0   \n",
      "4                        0.0                     0.0   \n",
      "...                      ...                     ...   \n",
      "3216                     0.0                     0.0   \n",
      "3217                     0.0                     0.0   \n",
      "3218                     0.0                     0.0   \n",
      "3219                     0.0                     0.0   \n",
      "3220                     0.0                     0.0   \n",
      "\n",
      "      110  Years and Over_perc  Total                     Location  State  \\\n",
      "0                          0.0    263     Bullitt County, Kentucky     21   \n",
      "1                          0.0     15      Butler County, Kentucky     21   \n",
      "2                          0.0     32    Caldwell County, Kentucky     21   \n",
      "3                          0.0    230    Calloway County, Kentucky     21   \n",
      "4                          0.0      2    Magoffin County, Kentucky     21   \n",
      "...                        ...    ...                          ...    ...   \n",
      "3216                       0.0     16    Haywood County, Tennessee     47   \n",
      "3217                       0.0     59  Henderson County, Tennessee     47   \n",
      "3218                       0.0    184         Howard County, Texas     48   \n",
      "3219                       0.0      5       Hudspeth County, Texas     48   \n",
      "3220                       0.0    594           Hunt County, Texas     48   \n",
      "\n",
      "      County   FIPS  \n",
      "0        029  21029  \n",
      "1        031  21031  \n",
      "2        033  21033  \n",
      "3        035  21035  \n",
      "4        153  21153  \n",
      "...      ...    ...  \n",
      "3216     075  47075  \n",
      "3217     077  47077  \n",
      "3218     227  48227  \n",
      "3219     229  48229  \n",
      "3220     231  48231  \n",
      "\n",
      "[3221 rows x 212 columns]\n",
      "\n",
      "DataFrame 'DF_total_male_nhop' after modification:\n",
      "      0  1  2  3  4  5  6  7  8  9  ...  98  Years_perc  99  Years_perc  \\\n",
      "0     0  0  1  0  1  0  0  0  0  0  ...             0.0             0.0   \n",
      "1     0  0  0  0  0  0  0  0  0  0  ...             0.0             0.0   \n",
      "2     0  0  0  0  0  0  0  0  0  0  ...             0.0             0.0   \n",
      "3     0  0  0  0  0  0  0  0  0  0  ...             0.0             0.0   \n",
      "4     0  0  0  0  0  0  0  0  0  0  ...             0.0             0.0   \n",
      "...  .. .. .. .. .. .. .. .. .. ..  ...             ...             ...   \n",
      "3216  0  0  0  0  0  0  0  0  0  0  ...             0.0             0.0   \n",
      "3217  0  0  0  0  0  0  0  0  0  0  ...             0.0             0.0   \n",
      "3218  0  0  0  0  0  0  0  0  0  0  ...             0.0             0.0   \n",
      "3219  0  0  0  0  0  0  0  0  0  0  ...             0.0             0.0   \n",
      "3220  5  5  1  0  0  0  2  5  0  1  ...             0.0             0.0   \n",
      "\n",
      "      100 to 104  Years_perc  105 to 109  Years_perc  \\\n",
      "0                        0.0                     0.0   \n",
      "1                        0.0                     0.0   \n",
      "2                        0.0                     0.0   \n",
      "3                        0.0                     0.0   \n",
      "4                        0.0                     0.0   \n",
      "...                      ...                     ...   \n",
      "3216                     0.0                     0.0   \n",
      "3217                     0.0                     0.0   \n",
      "3218                     0.0                     0.0   \n",
      "3219                     0.0                     0.0   \n",
      "3220                     0.0                     0.0   \n",
      "\n",
      "      110  Years and Over_perc  Total                     Location  State  \\\n",
      "0                          0.0      8     Bullitt County, Kentucky     21   \n",
      "1                          0.0      0      Butler County, Kentucky     21   \n",
      "2                          0.0      1    Caldwell County, Kentucky     21   \n",
      "3                          0.0      6    Calloway County, Kentucky     21   \n",
      "4                          0.0      1    Magoffin County, Kentucky     21   \n",
      "...                        ...    ...                          ...    ...   \n",
      "3216                       0.0      6    Haywood County, Tennessee     47   \n",
      "3217                       0.0      0  Henderson County, Tennessee     47   \n",
      "3218                       0.0      9         Howard County, Texas     48   \n",
      "3219                       0.0      0       Hudspeth County, Texas     48   \n",
      "3220                       0.0     88           Hunt County, Texas     48   \n",
      "\n",
      "      County   FIPS  \n",
      "0        029  21029  \n",
      "1        031  21031  \n",
      "2        033  21033  \n",
      "3        035  21035  \n",
      "4        153  21153  \n",
      "...      ...    ...  \n",
      "3216     075  47075  \n",
      "3217     077  47077  \n",
      "3218     227  48227  \n",
      "3219     229  48229  \n",
      "3220     231  48231  \n",
      "\n",
      "[3221 rows x 212 columns]\n",
      "\n",
      "DataFrame 'DF_total_female_nhop' after modification:\n",
      "      0  1  2  3  4  5  6  7  8  9  ...  98  Years_perc  99  Years_perc  \\\n",
      "0     0  0  0  1  0  0  0  0  0  0  ...             0.0             0.0   \n",
      "1     0  0  0  0  0  0  0  0  0  0  ...             0.0             0.0   \n",
      "2     0  0  0  0  0  0  0  0  0  0  ...             0.0             0.0   \n",
      "3     0  0  0  0  1  0  0  0  0  1  ...             0.0             0.0   \n",
      "4     0  0  0  0  1  0  0  0  0  0  ...             0.0             0.0   \n",
      "...  .. .. .. .. .. .. .. .. .. ..  ...             ...             ...   \n",
      "3216  0  0  0  0  0  0  0  0  0  0  ...             0.0             0.0   \n",
      "3217  0  0  0  0  0  0  0  0  0  0  ...             0.0             0.0   \n",
      "3218  0  0  0  0  0  0  0  0  0  0  ...             0.0             0.0   \n",
      "3219  0  0  0  0  0  0  0  0  0  0  ...             0.0             0.0   \n",
      "3220  0  0  0  0  6  0  2  0  0  1  ...             0.0             0.0   \n",
      "\n",
      "      100 to 104  Years_perc  105 to 109  Years_perc  \\\n",
      "0                        0.0                     0.0   \n",
      "1                        0.0                     0.0   \n",
      "2                        0.0                     0.0   \n",
      "3                        0.0                     0.0   \n",
      "4                        0.0                     0.0   \n",
      "...                      ...                     ...   \n",
      "3216                     0.0                     0.0   \n",
      "3217                     0.0                     0.0   \n",
      "3218                     0.0                     0.0   \n",
      "3219                     0.0                     0.0   \n",
      "3220                     0.0                     0.0   \n",
      "\n",
      "      110  Years and Over_perc  Total                     Location  State  \\\n",
      "0                          0.0     17     Bullitt County, Kentucky     21   \n",
      "1                          0.0      3      Butler County, Kentucky     21   \n",
      "2                          0.0      1    Caldwell County, Kentucky     21   \n",
      "3                          0.0      5    Calloway County, Kentucky     21   \n",
      "4                          0.0      5    Magoffin County, Kentucky     21   \n",
      "...                        ...    ...                          ...    ...   \n",
      "3216                       0.0      3    Haywood County, Tennessee     47   \n",
      "3217                       0.0      2  Henderson County, Tennessee     47   \n",
      "3218                       0.0     15         Howard County, Texas     48   \n",
      "3219                       0.0      0       Hudspeth County, Texas     48   \n",
      "3220                       0.0     69           Hunt County, Texas     48   \n",
      "\n",
      "      County   FIPS  \n",
      "0        029  21029  \n",
      "1        031  21031  \n",
      "2        033  21033  \n",
      "3        035  21035  \n",
      "4        153  21153  \n",
      "...      ...    ...  \n",
      "3216     075  47075  \n",
      "3217     077  47077  \n",
      "3218     227  48227  \n",
      "3219     229  48229  \n",
      "3220     231  48231  \n",
      "\n",
      "[3221 rows x 212 columns]\n",
      "\n",
      "DataFrame 'DF_total_male_sor' after modification:\n",
      "       0   1   2   3   4   5   6   7   8   9  ...  98  Years_perc  \\\n",
      "0      2   6   7   2   1  16  16   7   4   0  ...             0.0   \n",
      "1      2   5  12  10  15   6  12   2   2   0  ...             0.0   \n",
      "2      0   0   0   3   1   0   0   0   0   2  ...             0.0   \n",
      "3      5   7   2  10   0   0   8   8   6   3  ...             0.0   \n",
      "4      0   0   0   0   0   0   0   0   0   0  ...             0.0   \n",
      "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...             ...   \n",
      "3216   5   5   2   2   2  10   6   3  10   6  ...             0.0   \n",
      "3217   0   6   4   1  10   6   2   1  10   2  ...             0.0   \n",
      "3218  31  29  21  28  49  30  26  27  34  32  ...             0.0   \n",
      "3219   6   0   2   4   0   1   2   1   3   0  ...             0.0   \n",
      "3220  62  70  59  53  67  87  54  78  73  70  ...             0.0   \n",
      "\n",
      "      99  Years_perc  100 to 104  Years_perc  105 to 109  Years_perc  \\\n",
      "0                0.0                     0.0                     0.0   \n",
      "1                0.0                     0.0                     0.0   \n",
      "2                0.0                     0.0                     0.0   \n",
      "3                0.0                     0.0                     0.0   \n",
      "4                0.0                     0.0                     0.0   \n",
      "...              ...                     ...                     ...   \n",
      "3216             0.0                     0.0                     0.0   \n",
      "3217             0.0                     0.0                     0.0   \n",
      "3218             0.0                     0.0                     0.0   \n",
      "3219             0.0                     0.0                     0.0   \n",
      "3220             0.0                     0.0                     0.0   \n",
      "\n",
      "      110  Years and Over_perc  Total                     Location  State  \\\n",
      "0                          0.0    403     Bullitt County, Kentucky     21   \n",
      "1                          0.0    241      Butler County, Kentucky     21   \n",
      "2                          0.0     36    Caldwell County, Kentucky     21   \n",
      "3                          0.0    326    Calloway County, Kentucky     21   \n",
      "4                          0.0     17    Magoffin County, Kentucky     21   \n",
      "...                        ...    ...                          ...    ...   \n",
      "3216                       0.0    267    Haywood County, Tennessee     47   \n",
      "3217                       0.0    194  Henderson County, Tennessee     47   \n",
      "3218                       0.0   1926         Howard County, Texas     48   \n",
      "3219                       0.0    308       Hudspeth County, Texas     48   \n",
      "3220                       0.0   3853           Hunt County, Texas     48   \n",
      "\n",
      "      County   FIPS  \n",
      "0        029  21029  \n",
      "1        031  21031  \n",
      "2        033  21033  \n",
      "3        035  21035  \n",
      "4        153  21153  \n",
      "...      ...    ...  \n",
      "3216     075  47075  \n",
      "3217     077  47077  \n",
      "3218     227  48227  \n",
      "3219     229  48229  \n",
      "3220     231  48231  \n",
      "\n",
      "[3221 rows x 212 columns]\n",
      "\n",
      "DataFrame 'DF_total_female_sor' after modification:\n",
      "       0   1   2   3   4   5   6   7   8   9  ...  98  Years_perc  \\\n",
      "0     10   4  15  13   1   7   1   4   7  13  ...             0.0   \n",
      "1     11  10   2   9   9   8   6   0   7   5  ...             0.0   \n",
      "2      0   0   0   0   0   1   0   1   0   3  ...             0.0   \n",
      "3      0   5   9   3   1   5   4   1   2   2  ...             0.0   \n",
      "4      0   0   1   0   0   0   0   3   0   2  ...             0.0   \n",
      "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...             ...   \n",
      "3216   1   7   0   1   1  15   7   4   9  14  ...             0.0   \n",
      "3217   2   3   0   5   0   0   3   9   2   1  ...             0.0   \n",
      "3218  27  26  35  28  35  21  29  27  41  33  ...             0.0   \n",
      "3219   1   4   2   0  15   8   0   8   4   0  ...             0.0   \n",
      "3220  48  45  73  74  51  60  53  68  80  83  ...             0.0   \n",
      "\n",
      "      99  Years_perc  100 to 104  Years_perc  105 to 109  Years_perc  \\\n",
      "0                0.0                     0.0                     0.0   \n",
      "1                0.0                     0.0                     0.0   \n",
      "2                0.0                     0.0                     0.0   \n",
      "3                0.0                     0.0                     0.0   \n",
      "4                0.0                     0.0                     0.0   \n",
      "...              ...                     ...                     ...   \n",
      "3216             0.0                     0.0                     0.0   \n",
      "3217             0.0                     0.0                     0.0   \n",
      "3218             0.0                     0.0                     0.0   \n",
      "3219             0.0                     0.0                     0.0   \n",
      "3220             0.0                     0.0                     0.0   \n",
      "\n",
      "      110  Years and Over_perc  Total                     Location  State  \\\n",
      "0                     0.000000    335     Bullitt County, Kentucky     21   \n",
      "1                     0.000000    166      Butler County, Kentucky     21   \n",
      "2                     0.000000     34    Caldwell County, Kentucky     21   \n",
      "3                     0.000000    221    Calloway County, Kentucky     21   \n",
      "4                     0.000000     15    Magoffin County, Kentucky     21   \n",
      "...                        ...    ...                          ...    ...   \n",
      "3216                  0.000000    257    Haywood County, Tennessee     47   \n",
      "3217                  0.000000    160  Henderson County, Tennessee     47   \n",
      "3218                  0.000000   1844         Howard County, Texas     48   \n",
      "3219                  0.000000    314       Hudspeth County, Texas     48   \n",
      "3220                  0.000282   3545           Hunt County, Texas     48   \n",
      "\n",
      "      County   FIPS  \n",
      "0        029  21029  \n",
      "1        031  21031  \n",
      "2        033  21033  \n",
      "3        035  21035  \n",
      "4        153  21153  \n",
      "...      ...    ...  \n",
      "3216     075  47075  \n",
      "3217     077  47077  \n",
      "3218     227  48227  \n",
      "3219     229  48229  \n",
      "3220     231  48231  \n",
      "\n",
      "[3221 rows x 212 columns]\n",
      "\n",
      "DataFrame 'DF_total_male_tom' after modification:\n",
      "        0   1    2    3    4    5    6   7    8    9  ...  98  Years_perc  \\\n",
      "0      28  52   50   51   52   54   46  37   37   53  ...        0.000000   \n",
      "1       2   2    3    0    0    2   10   9    7    1  ...        0.000000   \n",
      "2       6  12    5   10    7    5    7  11   14    3  ...        0.000000   \n",
      "3      16  35   17   18   21   17   12  21   13   10  ...        0.000000   \n",
      "4       0   1    0    2    3    0    1   0    0    0  ...        0.000000   \n",
      "...   ...  ..  ...  ...  ...  ...  ...  ..  ...  ...  ...             ...   \n",
      "3216    9   6    4    1    7   10    1   1    1    2  ...        0.000000   \n",
      "3217   14  12   20   29   14   13   20  12    9   18  ...        0.000000   \n",
      "3218   24  46   45   34   57   54   53  38   46   30  ...        0.001582   \n",
      "3219    4   1    2    1    1    1    2  10    2    5  ...        0.000000   \n",
      "3220  133  95  118  109  135  113  111  91  121  104  ...        0.000000   \n",
      "\n",
      "      99  Years_perc  100 to 104  Years_perc  105 to 109  Years_perc  \\\n",
      "0                0.0                0.000000                     0.0   \n",
      "1                0.0                0.000000                     0.0   \n",
      "2                0.0                0.000000                     0.0   \n",
      "3                0.0                0.000000                     0.0   \n",
      "4                0.0                0.000000                     0.0   \n",
      "...              ...                     ...                     ...   \n",
      "3216             0.0                0.000000                     0.0   \n",
      "3217             0.0                0.000000                     0.0   \n",
      "3218             0.0                0.000000                     0.0   \n",
      "3219             0.0                0.000000                     0.0   \n",
      "3220             0.0                0.000178                     0.0   \n",
      "\n",
      "      110  Years and Over_perc  Total                     Location  State  \\\n",
      "0                     0.000000   2114     Bullitt County, Kentucky     21   \n",
      "1                     0.000000    214      Butler County, Kentucky     21   \n",
      "2                     0.000000    315    Caldwell County, Kentucky     21   \n",
      "3                     0.000000   1014    Calloway County, Kentucky     21   \n",
      "4                     0.000000     97    Magoffin County, Kentucky     21   \n",
      "...                        ...    ...                          ...    ...   \n",
      "3216                  0.003846    260    Haywood County, Tennessee     47   \n",
      "3217                  0.000000    672  Henderson County, Tennessee     47   \n",
      "3218                  0.000000   2529         Howard County, Texas     48   \n",
      "3219                  0.000000    314       Hudspeth County, Texas     48   \n",
      "3220                  0.000000   5610           Hunt County, Texas     48   \n",
      "\n",
      "      County   FIPS  \n",
      "0        029  21029  \n",
      "1        031  21031  \n",
      "2        033  21033  \n",
      "3        035  21035  \n",
      "4        153  21153  \n",
      "...      ...    ...  \n",
      "3216     075  47075  \n",
      "3217     077  47077  \n",
      "3218     227  48227  \n",
      "3219     229  48229  \n",
      "3220     231  48231  \n",
      "\n",
      "[3221 rows x 212 columns]\n",
      "\n",
      "DataFrame 'DF_total_female_tom' after modification:\n",
      "       0   1    2    3   4    5    6    7    8    9  ...  98  Years_perc  \\\n",
      "0     36  28   42   37  62   22   51   51   35   48  ...        0.000000   \n",
      "1      6   1    1    8   3    2    1    3    3    5  ...        0.000000   \n",
      "2      4   6    0    6   2    5    7    6    0   10  ...        0.000000   \n",
      "3     18  19   36   20  41   26   11   24   18   10  ...        0.000000   \n",
      "4      2   0    0    4   4    5    4    1    0    0  ...        0.000000   \n",
      "...   ..  ..  ...  ...  ..  ...  ...  ...  ...  ...  ...             ...   \n",
      "3216   6   6    7    7  10   12    5    6    4    1  ...        0.000000   \n",
      "3217  14  20   10    6  15    7   14   16    7   10  ...        0.000000   \n",
      "3218  43  39   48   42  39   51   42   42   45   29  ...        0.000427   \n",
      "3219   1   4    1    4  10   10    8    3    2   10  ...        0.000000   \n",
      "3220  93  87  119  107  89  125  114  123  120  117  ...        0.000000   \n",
      "\n",
      "      99  Years_perc  100 to 104  Years_perc  105 to 109  Years_perc  \\\n",
      "0           0.000000                0.000000                0.000000   \n",
      "1           0.000000                0.000000                0.000000   \n",
      "2           0.000000                0.000000                0.000000   \n",
      "3           0.000000                0.000000                0.000000   \n",
      "4           0.000000                0.000000                0.000000   \n",
      "...              ...                     ...                     ...   \n",
      "3216        0.000000                0.000000                0.000000   \n",
      "3217        0.000000                0.000000                0.000000   \n",
      "3218        0.000000                0.000000                0.000000   \n",
      "3219        0.000000                0.003058                0.000000   \n",
      "3220        0.000507                0.000000                0.000338   \n",
      "\n",
      "      110  Years and Over_perc  Total                     Location  State  \\\n",
      "0                     0.000000   2215     Bullitt County, Kentucky     21   \n",
      "1                     0.000000    213      Butler County, Kentucky     21   \n",
      "2                     0.000000    263    Caldwell County, Kentucky     21   \n",
      "3                     0.000000   1093    Calloway County, Kentucky     21   \n",
      "4                     0.000000    109    Magoffin County, Kentucky     21   \n",
      "...                        ...    ...                          ...    ...   \n",
      "3216                  0.000000    259    Haywood County, Tennessee     47   \n",
      "3217                  0.000000    622  Henderson County, Tennessee     47   \n",
      "3218                  0.000000   2341         Howard County, Texas     48   \n",
      "3219                  0.000000    327       Hudspeth County, Texas     48   \n",
      "3220                  0.000169   5922           Hunt County, Texas     48   \n",
      "\n",
      "      County   FIPS  \n",
      "0        029  21029  \n",
      "1        031  21031  \n",
      "2        033  21033  \n",
      "3        035  21035  \n",
      "4        153  21153  \n",
      "...      ...    ...  \n",
      "3216     075  47075  \n",
      "3217     077  47077  \n",
      "3218     227  48227  \n",
      "3219     229  48229  \n",
      "3220     231  48231  \n",
      "\n",
      "[3221 rows x 212 columns]\n",
      "\n",
      "DataFrame 'DF_total_male_hol' after modification:\n",
      "        0    1    2    3    4    5    6    7    8    9  ...  98  Years_perc  \\\n",
      "0      12   26   30   17   22   12   36   17   25   14  ...        0.000000   \n",
      "1       7    5   15   10   18    8   17    3    5    0  ...        0.000000   \n",
      "2       2    1    4    1    3    1    0    1    2    4  ...        0.000000   \n",
      "3      11   17   15   15   12    7   11   14   11    9  ...        0.000000   \n",
      "4       0    3    0    0    1    0    1    0    0    0  ...        0.000000   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...             ...   \n",
      "3216   12    5    5    6    7   16    7    2   15    6  ...        0.000000   \n",
      "3217    8   10   12   11   15   18    1    3   13   12  ...        0.000000   \n",
      "3218  103  109  111  110  145  120  108  111  129   88  ...        0.000399   \n",
      "3219   20   10    4   12    2    3   15   14   14   11  ...        0.000000   \n",
      "3220  204  175  182  176  224  236  188  189  199  174  ...        0.000000   \n",
      "\n",
      "      99  Years_perc  100 to 104  Years_perc  105 to 109  Years_perc  \\\n",
      "0                0.0                0.000000                     0.0   \n",
      "1                0.0                0.000000                     0.0   \n",
      "2                0.0                0.000000                     0.0   \n",
      "3                0.0                0.000000                     0.0   \n",
      "4                0.0                0.000000                     0.0   \n",
      "...              ...                     ...                     ...   \n",
      "3216             0.0                0.000000                     0.0   \n",
      "3217             0.0                0.000000                     0.0   \n",
      "3218             0.0                0.000000                     0.0   \n",
      "3219             0.0                0.000000                     0.0   \n",
      "3220             0.0                0.000099                     0.0   \n",
      "\n",
      "      110  Years and Over_perc  Total                     Location  State  \\\n",
      "0                          0.0   1100     Bullitt County, Kentucky     21   \n",
      "1                          0.0    326      Butler County, Kentucky     21   \n",
      "2                          0.0    115    Caldwell County, Kentucky     21   \n",
      "3                          0.0    722    Calloway County, Kentucky     21   \n",
      "4                          0.0     35    Magoffin County, Kentucky     21   \n",
      "...                        ...    ...                          ...    ...   \n",
      "3216                       0.0    427    Haywood County, Tennessee     47   \n",
      "3217                       0.0    408  Henderson County, Tennessee     47   \n",
      "3218                       0.0  10021         Howard County, Texas     48   \n",
      "3219                       0.0   1011       Hudspeth County, Texas     48   \n",
      "3220                       0.0  10086           Hunt County, Texas     48   \n",
      "\n",
      "      County   FIPS  \n",
      "0        029  21029  \n",
      "1        031  21031  \n",
      "2        033  21033  \n",
      "3        035  21035  \n",
      "4        153  21153  \n",
      "...      ...    ...  \n",
      "3216     075  47075  \n",
      "3217     077  47077  \n",
      "3218     227  48227  \n",
      "3219     229  48229  \n",
      "3220     231  48231  \n",
      "\n",
      "[3221 rows x 212 columns]\n",
      "\n",
      "DataFrame 'DF_total_female_hol' after modification:\n",
      "        0    1    2    3    4    5    6    7    8    9  ...  98  Years_perc  \\\n",
      "0      19   18   27   23   29   17   14   22   18   27  ...        0.000000   \n",
      "1      14   10    5   13   11    3    9    3   10    7  ...        0.000000   \n",
      "2       0    4    0    2    1    2    0    1    0    2  ...        0.000000   \n",
      "3      18   20   25    6   19   10   13   10    1   17  ...        0.000000   \n",
      "4       0    0    0    0    6    0    0    4    0    0  ...        0.000000   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...             ...   \n",
      "3216    9    7    2    8    6   18    9    3   15   14  ...        0.000000   \n",
      "3217    4   12    3    6    7    4    4   13    4    6  ...        0.000000   \n",
      "3218  106   99  119  107  112   79  115  113  134  100  ...        0.000488   \n",
      "3219   10   17    3    8   25   21    9   20    8   10  ...        0.000000   \n",
      "3220  141  157  220  181  163  205  173  200  198  207  ...        0.000000   \n",
      "\n",
      "      99  Years_perc  100 to 104  Years_perc  105 to 109  Years_perc  \\\n",
      "0           0.000000                0.000000                     0.0   \n",
      "1           0.000000                0.000000                     0.0   \n",
      "2           0.000000                0.000000                     0.0   \n",
      "3           0.000000                0.000000                     0.0   \n",
      "4           0.000000                0.000000                     0.0   \n",
      "...              ...                     ...                     ...   \n",
      "3216        0.000000                0.000000                     0.0   \n",
      "3217        0.000000                0.000000                     0.0   \n",
      "3218        0.000000                0.000000                     0.0   \n",
      "3219        0.000000                0.000976                     0.0   \n",
      "3220        0.000417                0.000000                     0.0   \n",
      "\n",
      "      110  Years and Over_perc  Total                     Location  State  \\\n",
      "0                     0.000000   1017     Bullitt County, Kentucky     21   \n",
      "1                     0.000000    266      Butler County, Kentucky     21   \n",
      "2                     0.000000     83    Caldwell County, Kentucky     21   \n",
      "3                     0.000000    631    Calloway County, Kentucky     21   \n",
      "4                     0.000000     31    Magoffin County, Kentucky     21   \n",
      "...                        ...    ...                          ...    ...   \n",
      "3216                  0.000000    411    Haywood County, Tennessee     47   \n",
      "3217                  0.000000    311  Henderson County, Tennessee     47   \n",
      "3218                  0.000000   6153         Howard County, Texas     48   \n",
      "3219                  0.000000   1025       Hudspeth County, Texas     48   \n",
      "3220                  0.000209   9587           Hunt County, Texas     48   \n",
      "\n",
      "      County   FIPS  \n",
      "0        029  21029  \n",
      "1        031  21031  \n",
      "2        033  21033  \n",
      "3        035  21035  \n",
      "4        153  21153  \n",
      "...      ...    ...  \n",
      "3216     075  47075  \n",
      "3217     077  47077  \n",
      "3218     227  48227  \n",
      "3219     229  48229  \n",
      "3220     231  48231  \n",
      "\n",
      "[3221 rows x 212 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, df in dfs.items():\n",
    "    print(f\"DataFrame '{key}' after modification:\")\n",
    "    print(df)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Error Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Total                     Location State County   FIPS male_all  \\\n",
      "0     82217     Bullitt County, Kentucky    21    029  21029    40783   \n",
      "1     12371      Butler County, Kentucky    21    031  21031     6205   \n",
      "2     12649    Caldwell County, Kentucky    21    033  21033     6136   \n",
      "3     37103    Calloway County, Kentucky    21    035  21035    17906   \n",
      "4     11637    Magoffin County, Kentucky    21    153  21153     5722   \n",
      "...     ...                          ...   ...    ...    ...      ...   \n",
      "3216  17864    Haywood County, Tennessee    47    075  47075     8345   \n",
      "3217  27842  Henderson County, Tennessee    47    077  47077    13569   \n",
      "3218  34860         Howard County, Texas    48    227  48227    19687   \n",
      "3219   3202       Hudspeth County, Texas    48    229  48229     1684   \n",
      "3220  99956           Hunt County, Texas    48    231  48231    49310   \n",
      "\n",
      "0    female_all total_whi total_baa total_aian  ...  96  97  98  99 102  107  \\\n",
      "0         41434     75417      1045        212  ...  14   7   1   8   7    1   \n",
      "1          6166     11464        15         32  ...   0   1   1   0   0    0   \n",
      "2          6513     11244       674         25  ...   9  10   2   0   2    6   \n",
      "3         19197     32626      1313         64  ...  14   7   6   8   3    0   \n",
      "4          5915     11360        14         14  ...   3   1   0   0   3    1   \n",
      "...         ...       ...       ...        ...  ...  ..  ..  ..  ..  ..  ...   \n",
      "3216       9519      7695      9032         59  ...  11   3   4   1   9    0   \n",
      "3217      14273     24079      1950         70  ...  12   2   9   1   3    2   \n",
      "3218      15173     23664      1721        404  ...  12  16   8   3   9    0   \n",
      "3219       1518      1874        16         39  ...   0   0   0   0   2    0   \n",
      "3220      50646     70576      8014       1263  ...  22  16  13  12   8    4   \n",
      "\n",
      "0     110  Expected Total  Absolute Error  Error Rate  \n",
      "0       0           84334            2117    2.510257  \n",
      "1       0           12963             592    4.566844  \n",
      "2       0           12847             198    1.541216  \n",
      "3       1           38456            1353    3.518307  \n",
      "4       0           11703              66    0.563958  \n",
      "...   ...             ...             ...         ...  \n",
      "3216    1           18702             838    4.480804  \n",
      "3217    0           28561             719    2.517419  \n",
      "3218    0           51034           16174   31.692597  \n",
      "3219    0            5238            2036   38.869798  \n",
      "3220    2          119629           19673   16.445009  \n",
      "\n",
      "[3221 rows x 121 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\134927289.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs['DF_total_all']['Expected Total'] = expected_total\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\134927289.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs['DF_total_all']['Absolute Error'] = absolute_error\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_20620\\134927289.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfs['DF_total_all']['Error Rate'] = error_rate\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already loaded the 'DF_total_all' DataFrame\n",
    "\n",
    "# Step 1: Calculate the expected total by summing the individual racial category columns\n",
    "expected_total = dfs['DF_total_all'][['total_whi', 'total_baa', 'total_aian', 'total_aa', 'total_nhop', 'total_sor', 'total_tom', 'total_hol']].sum(axis=1)\n",
    "\n",
    "# Step 2: Find the absolute error by subtracting the 'Total' column from the expected total\n",
    "absolute_error = expected_total - dfs['DF_total_all']['Total']\n",
    "\n",
    "# Step 3: Calculate the error rate as the absolute error divided by the expected total, multiplied by 100\n",
    "error_rate = (absolute_error / expected_total) * 100\n",
    "\n",
    "# Add the 'expected_total', 'absolute_error', and 'error_rate' columns to the DataFrame\n",
    "dfs['DF_total_all']['Expected Total'] = expected_total\n",
    "dfs['DF_total_all']['Absolute Error'] = absolute_error\n",
    "dfs['DF_total_all']['Error Rate'] = error_rate\n",
    "\n",
    "# Display the DataFrame with the added columns\n",
    "print(dfs['DF_total_all'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Total                     Location State County   FIPS male_all  \\\n",
      "0     82217     Bullitt County, Kentucky    21    029  21029    40783   \n",
      "1     12371      Butler County, Kentucky    21    031  21031     6205   \n",
      "2     12649    Caldwell County, Kentucky    21    033  21033     6136   \n",
      "3     37103    Calloway County, Kentucky    21    035  21035    17906   \n",
      "4     11637    Magoffin County, Kentucky    21    153  21153     5722   \n",
      "...     ...                          ...   ...    ...    ...      ...   \n",
      "3216  17864    Haywood County, Tennessee    47    075  47075     8345   \n",
      "3217  27842  Henderson County, Tennessee    47    077  47077    13569   \n",
      "3218  34860         Howard County, Texas    48    227  48227    19687   \n",
      "3219   3202       Hudspeth County, Texas    48    229  48229     1684   \n",
      "3220  99956           Hunt County, Texas    48    231  48231    49310   \n",
      "\n",
      "0    female_all total_whi total_baa total_aian  ...  96  97  98  99 102  107  \\\n",
      "0         41434     75417      1045        212  ...  14   7   1   8   7    1   \n",
      "1          6166     11464        15         32  ...   0   1   1   0   0    0   \n",
      "2          6513     11244       674         25  ...   9  10   2   0   2    6   \n",
      "3         19197     32626      1313         64  ...  14   7   6   8   3    0   \n",
      "4          5915     11360        14         14  ...   3   1   0   0   3    1   \n",
      "...         ...       ...       ...        ...  ...  ..  ..  ..  ..  ..  ...   \n",
      "3216       9519      7695      9032         59  ...  11   3   4   1   9    0   \n",
      "3217      14273     24079      1950         70  ...  12   2   9   1   3    2   \n",
      "3218      15173     23664      1721        404  ...  12  16   8   3   9    0   \n",
      "3219       1518      1874        16         39  ...   0   0   0   0   2    0   \n",
      "3220      50646     70576      8014       1263  ...  22  16  13  12   8    4   \n",
      "\n",
      "0     110  Expected Total  Absolute Error  Error Rate  \n",
      "0       0           84334            2117    2.510257  \n",
      "1       0           12963             592    4.566844  \n",
      "2       0           12847             198    1.541216  \n",
      "3       1           38456            1353    3.518307  \n",
      "4       0           11703              66    0.563958  \n",
      "...   ...             ...             ...         ...  \n",
      "3216    1           18702             838    4.480804  \n",
      "3217    0           28561             719    2.517419  \n",
      "3218    0           51034           16174   31.692597  \n",
      "3219    0            5238            2036   38.869798  \n",
      "3220    2          119629           19673   16.445009  \n",
      "\n",
      "[3221 rows x 121 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the DataFrame with the added columns\n",
    "print(dfs['DF_total_all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_names = ['DF_total_all','DF_male_all','DF_female_all',,'DF_total_whi',\n",
    "#             'DF_total_male_whi','DF_total_female_whi','DF_total_baa',\n",
    "#             'DF_total_male_baa','DF_total_female_baa','DF_total_aian',\n",
    "#             'DF_total_male_aian','DF_total_female_aian','DF_total_aa',\n",
    "#             'DF_total_male_aa','DF_total_female_aa','DF_total_nhop',\n",
    "#             'DF_total_male_nhop','DF_total_female_nhop','DF_total_sor',\n",
    "#             'DF_total_male_sor','DF_total_female_sor','DF_total_tom',\n",
    "#             'DF_total_male_tom','DF_total_female_tom','DF_total_hol',\n",
    "#             'DF_total_male_hol','DF_total_female_hol'\n",
    "#             ]\n",
    "\n",
    "# perc_df_2 = ['DF_total_all','DF_total_whi','DF_total_baa','DF_total_aian',\n",
    "#              'DF_total_aa','DF_total_nhop','DF_total_sor','DF_total_tom',\n",
    "#              'DF_total_hol'\n",
    "#              ]\n",
    "\n",
    "# perc_df = ['DF_male_all','DF_female_all','DF_total_male_whi',\n",
    "#              'DF_total_female_whi','DF_total_male_baa','DF_total_female_baa',\n",
    "#              'DF_total_male_aian','DF_total_female_aian','DF_total_male_aa',\n",
    "#              'DF_total_female_aa','DF_total_male_nhop','DF_total_female_nhop',\n",
    "#              'DF_total_male_sor','DF_total_female_sor','DF_total_male_tom',\n",
    "#              'DF_total_female_tom','DF_total_male_hol','DF_total_female_hol'\n",
    "#              ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the names, shapes, and dtypes of the dataframes in 'perc_df_2'\n",
    "# print(\"Data Frames in 'perc_df_2':\")\n",
    "# for name in perc_df_2:\n",
    "#     if name in dfs:\n",
    "#         df = dfs[name]\n",
    "#         print(name)\n",
    "#         print(\"Shape:\", df.shape)\n",
    "#         print(\"Dtypes:\")\n",
    "#         for column, dtype in df.dtypes.items():\n",
    "#             print(f\"{column}: {dtype}\")\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create workbook and export wanted dataframes to excel as individual sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the file name\n",
    "# file_name = '2020_agesex_statistics.xlsx'\n",
    "\n",
    "# # Get the file path in the current working directory\n",
    "# file_path = os.path.join(os.getcwd(), file_name)\n",
    "\n",
    "# # Check if the file exists\n",
    "# if os.path.exists(file_path):\n",
    "#     # Load the existing Excel file\n",
    "#     excel_file = pd.read_excel(file_path, engine='openpyxl')\n",
    "\n",
    "#     # Create a new ExcelWriter object using the existing file\n",
    "#     writer = pd.ExcelWriter(file_path, engine='openpyxl', if_sheet_exists='replace', mode='a')\n",
    "\n",
    "#     # Iterate through the dataframes in dfs\n",
    "#     for df_name, df in dfs.items():  # Use 'dfs.items()' to get the name (key) and dataframe (value)\n",
    "#         # Get the name of the dataframe\n",
    "#         name = df_name\n",
    "\n",
    "#         # Write each dataframe to a separate sheet in the Excel file\n",
    "#         df.to_excel(writer, sheet_name=name, index=False)\n",
    "\n",
    "#     # Close the writer\n",
    "#     writer.close()\n",
    "\n",
    "# else:\n",
    "#     # Create a new workbook\n",
    "#     writer = pd.ExcelWriter(file_path, engine='openpyxl')\n",
    "\n",
    "#     # Iterate through the dataframes in dfs\n",
    "#     for df_name, df in dfs.items():  # Use 'dfs.items()' to get the name (key) and dataframe (value)\n",
    "#         # Get the name of the dataframe\n",
    "#         name = df_name\n",
    "\n",
    "#         # Write each dataframe to a separate sheet in the Excel file\n",
    "#         df.to_excel(writer, sheet_name=name, index=False)\n",
    "\n",
    "#     # Close the writer\n",
    "#     writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
