{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import textwrap\n",
    "from time import sleep\n",
    "import json\n",
    "import xlsxwriter\n",
    "import os\n",
    "from openpyxl import workbook, load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = '593ff23df30236471e2bd1165031f208ce43d9f4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables for API Calls\n",
    "\n",
    "Assigning all the variables for each call to a python variable to be inserterted in the \n",
    "API call as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_households = ('NAME,DP03_0051E')\n",
    "\t\n",
    "th_range = ('NAME,DP03_0052E,DP03_0052PE,DP03_0053E,DP03_0053PE,DP03_0054E,'\n",
    "            'DP03_0054PE,DP03_0055E,DP03_0055PE,DP03_0056E,DP03_0056PE,'\n",
    "            'DP03_0057E,DP03_0057PE,DP03_0058E,DP03_0058PE,DP03_0059E,'\n",
    "            'DP03_0059PE,DP03_0060E,DP03_0060PE,DP03_0061E,DP03_0061PE'\n",
    "            )\n",
    "\t\n",
    "th_w_earn = ('NAME,DP03_0064E')\n",
    "\t\n",
    "th_w_ss = ('NAME,DP03_0066E,DP03_0066PE')\n",
    "\t\n",
    "th_w_ri = ('NAME,DP03_0068E,DP03_0068PE')\n",
    "\t\n",
    "th_w_ssi = ('NAME,DP03_0070E,DP03_0070PE')\n",
    "\t\n",
    "th_w_cpa = ('NAME,DP03_0072E,DP03_0072PE')\n",
    "\t\n",
    "th_w_snap = ('NAME,DP03_0074E,DP03_0074PE')\n",
    "\t\n",
    "families = ('NAME,DP03_0075E')\n",
    "\t\n",
    "fm_range = ('NAME,DP03_0076E,DP03_0076PE,DP03_0077E,DP03_0077PE,DP03_0078E,'\n",
    "            'DP03_0078PE,DP03_0079E,DP03_0079PE,DP03_0080E,DP03_0080PE,'\n",
    "            'DP03_0081E,DP03_0081PE,DP03_0082E,DP03_0082PE,DP03_0083E,'\n",
    "            'DP03_0083PE,DP03_0084E,DP03_0084PE,DP03_0085E,DP03_0085PE'\n",
    "            )\n",
    "\t\n",
    "per_capita = ('NAME,DP03_0088E')\n",
    "\t\n",
    "non_family = ('NAME,DP03_0089E')\n",
    "\t\n",
    "worker_earn = ('NAME,DP03_0092E')\n",
    "\t\n",
    "worker_ft_earn_male = ('NAME,DP03_0093E')\n",
    "\t\n",
    "worker_ft_earn_female = ('NAME,DP03_0094E')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vars = [total_households,th_range,th_w_earn,th_w_ss,th_w_ri,th_w_ssi,\n",
    "            th_w_cpa,th_w_snap,families,fm_range,per_capita,non_family,\n",
    "            worker_earn,worker_ft_earn_male,worker_ft_earn_female\n",
    "            ]\n",
    "\n",
    "df_vars = ['DF_total_households','DF_th_range','DF_th_w_earn','DF_th_w_ss',\n",
    "           'DF_th_w_ri','DF_th_w_ssi','DF_th_w_cpa','DF_th_w_snap',\n",
    "           'DF_families','DF_fm_range','DF_per_capita','DF_non_family',\n",
    "           'DF_worker_earn','DF_worker_ft_earn_male','DF_worker_ft_earn_female'\n",
    "           ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Calls\n",
    "\n",
    "completing 15 calls to the API and dumping each into a named dataframe in a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API call parameters\n",
    "url = 'https://api.census.gov/data/2020/acs/acs5/profile'\n",
    "how = 'state:*'\n",
    "where = 'county:*'\n",
    "\n",
    "# Create an empty dictionary to store the data frames\n",
    "dfs = {}\n",
    "\n",
    "# Iterate through get_vars and df_vars simultaneously\n",
    "for var, name in zip(get_vars, df_vars):\n",
    "    r = requests.request('GET', url, params={\"get\": var, \"for\": where, \"in\": how, \"key\": key})\n",
    "\n",
    "    # Check if the API call was successful\n",
    "    if r.status_code == 200:\n",
    "        data = r.json()\n",
    "\n",
    "        # Create the data frame using the returned JSON data\n",
    "        df_data = data[1:]  # Skip the first row which contains the column names\n",
    "        dfs[name] = pd.DataFrame(df_data, columns=data[0])\n",
    "\n",
    "        # Join 'state' and 'county' columns into a new column 'FIPS'\n",
    "        dfs[name]['FIPS'] = dfs[name]['state'] + dfs[name]['county']\n",
    "\n",
    "        # Convert specific columns to desired data types\n",
    "        columns_to_convert = ['NAME', 'state', 'county', 'FIPS']\n",
    "        columns_to_convert = [col for col in columns_to_convert if col in dfs[name].columns]\n",
    "        columns_to_convert_int = dfs[name].columns.difference(columns_to_convert)\n",
    "        columns_to_convert_float = []\n",
    "\n",
    "        # Handle integer and float conversion separately\n",
    "        for col in columns_to_convert_int:\n",
    "            try:\n",
    "                dfs[name][col] = dfs[name][col].astype(int)\n",
    "            except ValueError:\n",
    "                # If it cannot be converted to int, add it to the float conversion list\n",
    "                columns_to_convert_float.append(col)\n",
    "\n",
    "        for col in columns_to_convert_float:\n",
    "            dfs[name][col] = dfs[name][col].astype(float)\n",
    "\n",
    "        # Display the created data frame\n",
    "        print(f\"Data frame '{name}':\")\n",
    "        print(dfs[name])\n",
    "    else:\n",
    "        # API call failed\n",
    "        print(f\"API call for '{var}' failed. Status code:\", r.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Pulls from API\n",
    "\n",
    "I should have 15 Dataframes total.\n",
    "\n",
    "- There should be 8 dataframes of:\n",
    "    - Shape: 3221 rows, 5 columns\n",
    "- There should be 5 dataframes of:\n",
    "    - Shape: 3221 rows, 6 columns\n",
    "- There should be 2 dataframes of:\n",
    "    - Shape: 3221 rows, 24 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of data frame names stored in dfs dictionary\n",
    "print(f\"Number of data frames: {len(dfs)}\")\n",
    "\n",
    "print(\"Data Frames in dfs:\")\n",
    "for name, df in dfs.items():\n",
    "    # Get the shape of the data frame\n",
    "    rows, cols = df.shape\n",
    "\n",
    "    # Print the data frame name and shape\n",
    "    print(f\"Data frame '{name}':\")\n",
    "    print(f\"Shape: {rows} rows, {cols} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for data errors\n",
    "\n",
    "I should find no missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name, df in dfs.items():\n",
    "    # Find the rows with missing data\n",
    "    rows_with_missing_data = df[df.isnull().any(axis=1)]\n",
    "\n",
    "    # Find the columns with missing data\n",
    "    columns_with_missing_data = df.columns[df.isnull().any()]\n",
    "\n",
    "    # Check if there is missing data in the dataframe\n",
    "    if not rows_with_missing_data.empty or len(columns_with_missing_data) > 0:\n",
    "        print(f\"Missing data found in DataFrame '{df_name}'\")\n",
    "\n",
    "        # Replace NaN values with string 'NaN'\n",
    "        df = df.replace({np.nan: 'NaN'})\n",
    "\n",
    "        # Print the rows with missing data\n",
    "        print(\"Rows with missing data:\")\n",
    "        print(rows_with_missing_data)\n",
    "\n",
    "        # Print the columns with missing data\n",
    "        print(\"Columns with missing data:\")\n",
    "        print(columns_with_missing_data)\n",
    "        print()\n",
    "\n",
    "        # Search for 'NaN' string in the dataframe\n",
    "        rows_with_nan_string = df[df.eq('NaN').any(axis=1)]\n",
    "        columns_with_nan_string = df.columns[df.eq('NaN').any()]\n",
    "\n",
    "        # Print the rows with 'NaN' string\n",
    "        print(\"Rows with 'NaN' string:\")\n",
    "        print(rows_with_nan_string)\n",
    "\n",
    "        # Print the columns with 'NaN' string\n",
    "        print(\"Columns with 'NaN' string:\")\n",
    "        print(columns_with_nan_string)\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"No missing data found in DataFrame '{df_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Column Names\n",
    "\n",
    "Changing names of dataframe columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_range_col_names = ['Estimate Less than $10,000','Percent Less than $10,000',\n",
    "                      'Estimate$10,000 to $14,999','Percent$10,000 to $14,999',\n",
    "                      'Estimate$15,000 to $24,999','Percent$15,000 to $24,999',\n",
    "                      'Estimate$25,000 to $34,999','Percent$25,000 to $34,999',\n",
    "                      'Estimate$35,000 to $49,999','Percent$35,000 to $49,999',\n",
    "                      'Estimate$50,000 to $74,999','Percent$50,000 to $74,999',\n",
    "                      'Estimate$75,000 to $99,999','Percent$75,000 to $99,999',\n",
    "                      'Estimate$100,000 to $149,999',\n",
    "                      'Percent$100,000 to $149,999',\n",
    "                      'Estimate$150,000 to $199,999',\n",
    "                      'Percent$150,000 to $199,999','Estimate$200,000 or more',\n",
    "                      'Percent$200,000 or more'\n",
    "                      ]\n",
    "\n",
    "# Iterate over the items in the 'merged_dfs' dictionary\n",
    "for item, df in merged_dfs.items():\n",
    "    df.columns = col_names  # Assign the new column names to the data frame in place\n",
    "    merged_dfs[item] = df  # Update the data frame in the 'merged_dfs' dictionary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
