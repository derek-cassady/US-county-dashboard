{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age & Sex Data Pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "# import textwrap\n",
    "# from time import sleep\n",
    "import json\n",
    "# import xlsxwriter\n",
    "import os\n",
    "from openpyxl import workbook, load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import numpy as np\n",
    "# import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting 'Key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'PLEASE INSERT YOUR KEY HERE'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables for API Calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning all the variables for each call to a python variable to be inserterted in the \n",
    "API call as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_all = ('NAME,PCT12_001N')\n",
    "\n",
    "male_all_0 = ('NAME,PCT12_002N,PCT12_003N,PCT12_004N,PCT12_005N,PCT12_006N,'\n",
    "              'PCT12_007N,PCT12_008N,PCT12_009N,PCT12_010N,PCT12_011N,'\n",
    "              'PCT12_012N,PCT12_013N,PCT12_014N,PCT12_015N,PCT12_016N,'\n",
    "              'PCT12_017N,PCT12_018N,PCT12_019N,PCT12_020N,PCT12_021N,'\n",
    "              'PCT12_022N,PCT12_023N,PCT12_024N,PCT12_025N,PCT12_026N,'\n",
    "              'PCT12_027N,PCT12_028N,PCT12_029N,PCT12_030N,PCT12_031N,'\n",
    "              'PCT12_032N,PCT12_033N,PCT12_034N,PCT12_035N,PCT12_036N,'\n",
    "              'PCT12_037N,PCT12_038N,PCT12_039N,PCT12_040N,PCT12_041N,'\n",
    "              'PCT12_042N,PCT12_043N,PCT12_044N,PCT12_045N,PCT12_046N,'\n",
    "              'PCT12_047N,PCT12_048N,PCT12_049N,PCT12_050N')\n",
    "\n",
    "male_all_1 = ('NAME,PCT12_051N,PCT12_052N,PCT12_053N,PCT12_054N,PCT12_055N,'\n",
    "              'PCT12_056N,PCT12_057N,PCT12_058N,PCT12_059N,PCT12_060N,'\n",
    "              'PCT12_061N,PCT12_062N,PCT12_063N,PCT12_064N,PCT12_065N,'\n",
    "              'PCT12_066N,PCT12_067N,PCT12_068N,PCT12_069N,PCT12_070N,'\n",
    "              'PCT12_071N,PCT12_072N,PCT12_073N,PCT12_074N,PCT12_075N,'\n",
    "              'PCT12_076N,PCT12_077N,PCT12_078N,PCT12_079N,PCT12_080N,'\n",
    "              'PCT12_081N,PCT12_082N,PCT12_083N,PCT12_084N,PCT12_085N,'\n",
    "              'PCT12_086N,PCT12_087N,PCT12_088N,PCT12_089N,PCT12_090N,'\n",
    "              'PCT12_091N,PCT12_092N,PCT12_093N,PCT12_094N,PCT12_095N,'\n",
    "              'PCT12_096N,PCT12_097N,PCT12_098N,PCT12_099N')\n",
    "\n",
    "male_all_2 = ('NAME,PCT12_100N,PCT12_101N,PCT12_102N,PCT12_103N,PCT12_104N,'\n",
    "              'PCT12_105N')\n",
    "\n",
    "female_all_0 = ('NAME,PCT12_106N,PCT12_107N,PCT12_108N,PCT12_109N,PCT12_110N,'\n",
    "                'PCT12_111N,PCT12_112N,PCT12_113N,PCT12_114N,PCT12_115N,'\n",
    "                'PCT12_116N,PCT12_117N,PCT12_118N,PCT12_119N,PCT12_120N,'\n",
    "                'PCT12_121N,PCT12_122N,PCT12_123N,PCT12_124N,PCT12_125N,'\n",
    "                'PCT12_126N,PCT12_127N,PCT12_128N,PCT12_129N,PCT12_130N,'\n",
    "                'PCT12_131N,PCT12_132N,PCT12_133N,PCT12_134N,PCT12_135N,'\n",
    "                'PCT12_136N,PCT12_137N,PCT12_138N,PCT12_139N,PCT12_140N,'\n",
    "                'PCT12_141N,PCT12_142N,PCT12_143N,PCT12_144N,PCT12_145N,'\n",
    "                'PCT12_146N,PCT12_147N,PCT12_148N,PCT12_149N,PCT12_150N,'\n",
    "                'PCT12_151N,PCT12_152N,PCT12_153N,PCT12_154N')\n",
    "\n",
    "female_all_1 = ('NAME,PCT12_155N,PCT12_156N,PCT12_157N,PCT12_158N,PCT12_159N,'\n",
    "                'PCT12_160N,PCT12_161N,PCT12_162N,PCT12_163N,PCT12_164N,'\n",
    "                'PCT12_165N,PCT12_166N,PCT12_167N,PCT12_168N,PCT12_169N,'\n",
    "                'PCT12_170N,PCT12_171N,PCT12_172N,PCT12_173N,PCT12_174N,'\n",
    "                'PCT12_175N,PCT12_176N,PCT12_177N,PCT12_178N,PCT12_179N,'\n",
    "                'PCT12_180N,PCT12_181N,PCT12_182N,PCT12_183N,PCT12_184N,'\n",
    "                'PCT12_185N,PCT12_186N,PCT12_187N,PCT12_188N,PCT12_189N,'\n",
    "                'PCT12_190N,PCT12_191N,PCT12_192N,PCT12_193N,PCT12_194N,'\n",
    "                'PCT12_195N,PCT12_196N,PCT12_197N,PCT12_198N,PCT12_199N,'\n",
    "                'PCT12_200N,PCT12_201N,PCT12_202N,PCT12_203N')\n",
    "\n",
    "female_all_2 = ('NAME,PCT12_204N,PCT12_205N,PCT12_206N,PCT12_207N,PCT12_208N,'\n",
    "                'PCT12_209N')\n",
    "\n",
    "total_whi = ('NAME,PCT12A_001N')\n",
    "\n",
    "total_male_whi_0 = ('NAME,PCT12A_002N,PCT12A_003N,PCT12A_004N,PCT12A_005N,'\n",
    "                    'PCT12A_006N,PCT12A_007N,PCT12A_008N,PCT12A_009N,'\n",
    "                    'PCT12A_010N,PCT12A_011N,PCT12A_012N,PCT12A_013N,'\n",
    "                    'PCT12A_014N,PCT12A_015N,PCT12A_016N,PCT12A_017N,'\n",
    "                    'PCT12A_018N,PCT12A_019N,PCT12A_020N,PCT12A_021N,'\n",
    "                    'PCT12A_022N,PCT12A_023N,PCT12A_024N,PCT12A_025N,'\n",
    "                    'PCT12A_026N,PCT12A_027N,PCT12A_028N,PCT12A_029N,'\n",
    "                    'PCT12A_030N,PCT12A_031N,PCT12A_032N,PCT12A_033N,'\n",
    "                    'PCT12A_034N,PCT12A_035N,PCT12A_036N,PCT12A_037N,'\n",
    "                    'PCT12A_038N,PCT12A_039N,PCT12A_040N,PCT12A_041N,'\n",
    "                    'PCT12A_042N,PCT12A_043N,PCT12A_044N,PCT12A_045N,'\n",
    "                    'PCT12A_046N,PCT12A_047N,PCT12A_048N,PCT12A_049N,'\n",
    "                    'PCT12A_050N')\n",
    "\n",
    "total_male_whi_1 = ('NAME,PCT12A_051N,PCT12A_052N,PCT12A_053N,PCT12A_054N,'\n",
    "                    'PCT12A_055N,PCT12A_056N,PCT12A_057N,PCT12A_058N,'\n",
    "                    'PCT12A_059N,PCT12A_060N,PCT12A_061N,PCT12A_062N,'\n",
    "                    'PCT12A_063N,PCT12A_064N,PCT12A_065N,PCT12A_066N,'\n",
    "                    'PCT12A_067N,PCT12A_068N,PCT12A_069N,PCT12A_070N,'\n",
    "                    'PCT12A_071N,PCT12A_072N,PCT12A_073N,PCT12A_074N,'\n",
    "                    'PCT12A_075N,PCT12A_076N,PCT12A_077N,PCT12A_078N,'\n",
    "                    'PCT12A_079N,PCT12A_080N,PCT12A_081N,PCT12A_082N,'\n",
    "                    'PCT12A_083N,PCT12A_084N,PCT12A_085N,PCT12A_086N,'\n",
    "                    'PCT12A_087N,PCT12A_088N,PCT12A_089N,PCT12A_090N,'\n",
    "                    'PCT12A_091N,PCT12A_092N,PCT12A_093N,PCT12A_094N,'\n",
    "                    'PCT12A_095N,PCT12A_096N,PCT12A_097N,PCT12A_098N,'\n",
    "                    'PCT12A_099N')\n",
    "\n",
    "total_male_whi_2 = ('NAME,PCT12A_100N,PCT12A_101N,PCT12A_102N,PCT12A_103N,'\n",
    "                    'PCT12A_104N,PCT12A_105N')\n",
    "\n",
    "total_female_whi_0 = ('NAME,PCT12A_106N,PCT12A_107N,PCT12A_108N,PCT12A_109N,'\n",
    "                      'PCT12A_110N,PCT12A_111N,PCT12A_112N,PCT12A_113N,'\n",
    "                      'PCT12A_114N,PCT12A_115N,PCT12A_116N,PCT12A_117N,'\n",
    "                      'PCT12A_118N,PCT12A_119N,PCT12A_120N,PCT12A_121N,'\n",
    "                      'PCT12A_122N,PCT12A_123N,PCT12A_124N,PCT12A_125N,'\n",
    "                      'PCT12A_126N,PCT12A_127N,PCT12A_128N,PCT12A_129N,'\n",
    "                      'PCT12A_130N,PCT12A_131N,PCT12A_132N,PCT12A_133N,'\n",
    "                      'PCT12A_134N,PCT12A_135N,PCT12A_136N,PCT12A_137N,'\n",
    "                      'PCT12A_138N,PCT12A_139N,PCT12A_140N,PCT12A_141N,'\n",
    "                      'PCT12A_142N,PCT12A_143N,PCT12A_144N,PCT12A_145N,'\n",
    "                      'PCT12A_146N,PCT12A_147N,PCT12A_148N,PCT12A_149N,'\n",
    "                      'PCT12A_150N,PCT12A_151N,PCT12A_152N,PCT12A_153N,'\n",
    "                      'PCT12A_154N')\n",
    "\n",
    "total_female_whi_1 = ('NAME,PCT12A_155N,PCT12A_156N,PCT12A_157N,PCT12A_158N,'\n",
    "                      'PCT12A_159N,PCT12A_160N,PCT12A_161N,PCT12A_162N,'\n",
    "                      'PCT12A_163N,PCT12A_164N,PCT12A_165N,PCT12A_166N,'\n",
    "                      'PCT12A_167N,PCT12A_168N,PCT12A_169N,PCT12A_170N,'\n",
    "                      'PCT12A_171N,PCT12A_172N,PCT12A_173N,PCT12A_174N,'\n",
    "                      'PCT12A_175N,PCT12A_176N,PCT12A_177N,PCT12A_178N,'\n",
    "                      'PCT12A_179N,PCT12A_180N,PCT12A_181N,PCT12A_182N,'\n",
    "                      'PCT12A_183N,PCT12A_184N,PCT12A_185N,PCT12A_186N,'\n",
    "                      'PCT12A_187N,PCT12A_188N,PCT12A_189N,PCT12A_190N,'\n",
    "                      'PCT12A_191N,PCT12A_192N,PCT12A_193N,PCT12A_194N,'\n",
    "                      'PCT12A_195N,PCT12A_196N,PCT12A_197N,PCT12A_198N,'\n",
    "                      'PCT12A_199N,PCT12A_200N,PCT12A_201N,PCT12A_202N,'\n",
    "                      'PCT12A_203N')\n",
    "\n",
    "total_female_whi_2 = ('NAME,PCT12A_204N,PCT12A_205N,PCT12A_206N,PCT12A_207N,'\n",
    "                      'PCT12A_208N,PCT12A_209N')\n",
    "\n",
    "total_baa = ('NAME,PCT12B_001N')\n",
    "\n",
    "total_male_baa_0 = ('NAME,PCT12B_002N,PCT12B_003N,PCT12B_004N,PCT12B_005N,'\n",
    "                    'PCT12B_006N,PCT12B_007N,PCT12B_008N,PCT12B_009N,'\n",
    "                    'PCT12B_010N,PCT12B_011N,PCT12B_012N,PCT12B_013N,'\n",
    "                    'PCT12B_014N,PCT12B_015N,PCT12B_016N,PCT12B_017N,'\n",
    "                    'PCT12B_018N,PCT12B_019N,PCT12B_020N,PCT12B_021N,'\n",
    "                    'PCT12B_022N,PCT12B_023N,PCT12B_024N,PCT12B_025N,'\n",
    "                    'PCT12B_026N,PCT12B_027N,PCT12B_028N,PCT12B_029N,'\n",
    "                    'PCT12B_030N,PCT12B_031N,PCT12B_032N,PCT12B_033N,'\n",
    "                    'PCT12B_034N,PCT12B_035N,PCT12B_036N,PCT12B_037N,'\n",
    "                    'PCT12B_038N,PCT12B_039N,PCT12B_040N,PCT12B_041N,'\n",
    "                    'PCT12B_042N,PCT12B_043N,PCT12B_044N,PCT12B_045N,'\n",
    "                    'PCT12B_046N,PCT12B_047N,PCT12B_048N,PCT12B_049N,'\n",
    "                    'PCT12B_050N')\n",
    "\n",
    "total_male_baa_1 = ('NAME,PCT12B_051N,PCT12B_052N,PCT12B_053N,PCT12B_054N,'\n",
    "                    'PCT12B_055N,PCT12B_056N,PCT12B_057N,PCT12B_058N,'\n",
    "                    'PCT12B_059N,PCT12B_060N,PCT12B_061N,PCT12B_062N,'\n",
    "                    'PCT12B_063N,PCT12B_064N,PCT12B_065N,PCT12B_066N,'\n",
    "                    'PCT12B_067N,PCT12B_068N,PCT12B_069N,PCT12B_070N,'\n",
    "                    'PCT12B_071N,PCT12B_072N,PCT12B_073N,PCT12B_074N,'\n",
    "                    'PCT12B_075N,PCT12B_076N,PCT12B_077N,PCT12B_078N,'\n",
    "                    'PCT12B_079N,PCT12B_080N,PCT12B_081N,PCT12B_082N,'\n",
    "                    'PCT12B_083N,PCT12B_084N,PCT12B_085N,PCT12B_086N,'\n",
    "                    'PCT12B_087N,PCT12B_088N,PCT12B_089N,PCT12B_090N,'\n",
    "                    'PCT12B_091N,PCT12B_092N,PCT12B_093N,PCT12B_094N,'\n",
    "                    'PCT12B_095N,PCT12B_096N,PCT12B_097N,PCT12B_098N,'\n",
    "                    'PCT12B_099N')\n",
    "\n",
    "total_male_baa_2 = ('NAME,PCT12B_100N,PCT12B_101N,PCT12B_102N,PCT12B_103N,'\n",
    "                    'PCT12B_104N,PCT12B_105N')\n",
    "\n",
    "total_female_baa_0 = ('NAME,PCT12B_106N,PCT12B_107N,PCT12B_108N,PCT12B_109N,'\n",
    "                      'PCT12B_110N,PCT12B_111N,PCT12B_112N,PCT12B_113N,'\n",
    "                      'PCT12B_114N,PCT12B_115N,PCT12B_116N,PCT12B_117N,'\n",
    "                      'PCT12B_118N,PCT12B_119N,PCT12B_120N,PCT12B_121N,'\n",
    "                      'PCT12B_122N,PCT12B_123N,PCT12B_124N,PCT12B_125N,'\n",
    "                      'PCT12B_126N,PCT12B_127N,PCT12B_128N,PCT12B_129N,'\n",
    "                      'PCT12B_130N,PCT12B_131N,PCT12B_132N,PCT12B_133N,'\n",
    "                      'PCT12B_134N,PCT12B_135N,PCT12B_136N,PCT12B_137N,'\n",
    "                      'PCT12B_138N,PCT12B_139N,PCT12B_140N,PCT12B_141N,'\n",
    "                      'PCT12B_142N,PCT12B_143N,PCT12B_144N,PCT12B_145N,'\n",
    "                      'PCT12B_146N,PCT12B_147N,PCT12B_148N,PCT12B_149N,'\n",
    "                      'PCT12B_150N,PCT12B_151N,PCT12B_152N,PCT12B_153N,'\n",
    "                      'PCT12B_154N')\n",
    "\n",
    "total_female_baa_1 = ('NAME,PCT12B_155N,PCT12B_156N,PCT12B_157N,PCT12B_158N,'\n",
    "                      'PCT12B_159N,PCT12B_160N,PCT12B_161N,PCT12B_162N,'\n",
    "                      'PCT12B_163N,PCT12B_164N,PCT12B_165N,PCT12B_166N,'\n",
    "                      'PCT12B_167N,PCT12B_168N,PCT12B_169N,PCT12B_170N,'\n",
    "                      'PCT12B_171N,PCT12B_172N,PCT12B_173N,PCT12B_174N,'\n",
    "                      'PCT12B_175N,PCT12B_176N,PCT12B_177N,PCT12B_178N,'\n",
    "                      'PCT12B_179N,PCT12B_180N,PCT12B_181N,PCT12B_182N,'\n",
    "                      'PCT12B_183N,PCT12B_184N,PCT12B_185N,PCT12B_186N,'\n",
    "                      'PCT12B_187N,PCT12B_188N,PCT12B_189N,PCT12B_190N,'\n",
    "                      'PCT12B_191N,PCT12B_192N,PCT12B_193N,PCT12B_194N,'\n",
    "                      'PCT12B_195N,PCT12B_196N,PCT12B_197N,PCT12B_198N,'\n",
    "                      'PCT12B_199N,PCT12B_200N,PCT12B_201N,PCT12B_202N,'\n",
    "                      'PCT12B_203N')\n",
    "\n",
    "total_female_baa_2 = ('NAME,PCT12B_204N,PCT12B_205N,PCT12B_206N,PCT12B_207N,'\n",
    "                      'PCT12B_208N,PCT12B_209N')\n",
    "\n",
    "total_aian = ('NAME,PCT12C_001N')\n",
    "\n",
    "total_male_aian_0 = ('NAME,PCT12C_002N,PCT12C_003N,PCT12C_004N,PCT12C_005N,'\n",
    "                     'PCT12C_006N,PCT12C_007N,PCT12C_008N,PCT12C_009N,'\n",
    "                     'PCT12C_010N,PCT12C_011N,PCT12C_012N,PCT12C_013N,'\n",
    "                     'PCT12C_014N,PCT12C_015N,PCT12C_016N,PCT12C_017N,'\n",
    "                     'PCT12C_018N,PCT12C_019N,PCT12C_020N,PCT12C_021N,'\n",
    "                     'PCT12C_022N,PCT12C_023N,PCT12C_024N,PCT12C_025N,'\n",
    "                     'PCT12C_026N,PCT12C_027N,PCT12C_028N,PCT12C_029N,'\n",
    "                     'PCT12C_030N,PCT12C_031N,PCT12C_032N,PCT12C_033N,'\n",
    "                     'PCT12C_034N,PCT12C_035N,PCT12C_036N,PCT12C_037N,'\n",
    "                     'PCT12C_038N,PCT12C_039N,PCT12C_040N,PCT12C_041N,'\n",
    "                     'PCT12C_042N,PCT12C_043N,PCT12C_044N,PCT12C_045N,'\n",
    "                     'PCT12C_046N,PCT12C_047N,PCT12C_048N,PCT12C_049N,'\n",
    "                     'PCT12C_050N')\n",
    "\n",
    "total_male_aian_1 = ('NAME,PCT12C_051N,PCT12C_052N,PCT12C_053N,PCT12C_054N,'\n",
    "                     'PCT12C_055N,PCT12C_056N,PCT12C_057N,PCT12C_058N,'\n",
    "                     'PCT12C_059N,PCT12C_060N,PCT12C_061N,PCT12C_062N,'\n",
    "                     'PCT12C_063N,PCT12C_064N,PCT12C_065N,PCT12C_066N,'\n",
    "                     'PCT12C_067N,PCT12C_068N,PCT12C_069N,PCT12C_070N,'\n",
    "                     'PCT12C_071N,PCT12C_072N,PCT12C_073N,PCT12C_074N,'\n",
    "                     'PCT12C_075N,PCT12C_076N,PCT12C_077N,PCT12C_078N,'\n",
    "                     'PCT12C_079N,PCT12C_080N,PCT12C_081N,PCT12C_082N,'\n",
    "                     'PCT12C_083N,PCT12C_084N,PCT12C_085N,PCT12C_086N,'\n",
    "                     'PCT12C_087N,PCT12C_088N,PCT12C_089N,PCT12C_090N,'\n",
    "                     'PCT12C_091N,PCT12C_092N,PCT12C_093N,PCT12C_094N,'\n",
    "                     'PCT12C_095N,PCT12C_096N,PCT12C_097N,PCT12C_098N,'\n",
    "                     'PCT12C_099N')\n",
    "\n",
    "total_male_aian_2 = ('NAME,PCT12C_100N,PCT12C_101N,PCT12C_102N,PCT12C_103N,'\n",
    "                     'PCT12C_104N,PCT12C_105N')\n",
    "\n",
    "total_female_aian_0 = ('NAME,PCT12C_106N,PCT12C_107N,PCT12C_108N,PCT12C_109N,'\n",
    "                       'PCT12C_110N,PCT12C_111N,PCT12C_112N,PCT12C_113N,'\n",
    "                       'PCT12C_114N,PCT12C_115N,PCT12C_116N,PCT12C_117N,'\n",
    "                       'PCT12C_118N,PCT12C_119N,PCT12C_120N,PCT12C_121N,'\n",
    "                       'PCT12C_122N,PCT12C_123N,PCT12C_124N,PCT12C_125N,'\n",
    "                       'PCT12C_126N,PCT12C_127N,PCT12C_128N,PCT12C_129N,'\n",
    "                       'PCT12C_130N,PCT12C_131N,PCT12C_132N,PCT12C_133N,'\n",
    "                       'PCT12C_134N,PCT12C_135N,PCT12C_136N,PCT12C_137N,'\n",
    "                       'PCT12C_138N,PCT12C_139N,PCT12C_140N,PCT12C_141N,'\n",
    "                       'PCT12C_142N,PCT12C_143N,PCT12C_144N,PCT12C_145N,'\n",
    "                       'PCT12C_146N,PCT12C_147N,PCT12C_148N,PCT12C_149N,'\n",
    "                       'PCT12C_150N,PCT12C_151N,PCT12C_152N,PCT12C_153N,'\n",
    "                       'PCT12C_154N')\n",
    "\n",
    "total_female_aian_1 = ('NAME,PCT12C_155N,PCT12C_156N,PCT12C_157N,PCT12C_158N,'\n",
    "                       'PCT12C_159N,PCT12C_160N,PCT12C_161N,PCT12C_162N,'\n",
    "                       'PCT12C_163N,PCT12C_164N,PCT12C_165N,PCT12C_166N,'\n",
    "                       'PCT12C_167N,PCT12C_168N,PCT12C_169N,PCT12C_170N,'\n",
    "                       'PCT12C_171N,PCT12C_172N,PCT12C_173N,PCT12C_174N,'\n",
    "                       'PCT12C_175N,PCT12C_176N,PCT12C_177N,PCT12C_178N,'\n",
    "                       'PCT12C_179N,PCT12C_180N,PCT12C_181N,PCT12C_182N,'\n",
    "                       'PCT12C_183N,PCT12C_184N,PCT12C_185N,PCT12C_186N,'\n",
    "                       'PCT12C_187N,PCT12C_188N,PCT12C_189N,PCT12C_190N,'\n",
    "                       'PCT12C_191N,PCT12C_192N,PCT12C_193N,PCT12C_194N,'\n",
    "                       'PCT12C_195N,PCT12C_196N,PCT12C_197N,PCT12C_198N,'\n",
    "                       'PCT12C_199N,PCT12C_200N,PCT12C_201N,PCT12C_202N,'\n",
    "                       'PCT12C_203N')\n",
    "\n",
    "total_female_aian_2 = ('NAME,PCT12C_204N,PCT12C_205N,PCT12C_206N,PCT12C_207N,'\n",
    "                       'PCT12C_208N,PCT12C_209N')\n",
    "\n",
    "total_aa = ('NAME,PCT12D_001N')\n",
    "\n",
    "total_male_aa_0 = ('NAME,PCT12D_002N,PCT12D_003N,PCT12D_004N,PCT12D_005N,'\n",
    "                   'PCT12D_006N,PCT12D_007N,PCT12D_008N,PCT12D_009N,'\n",
    "                   'PCT12D_010N,PCT12D_011N,PCT12D_012N,PCT12D_013N,'\n",
    "                   'PCT12D_014N,PCT12D_015N,PCT12D_016N,PCT12D_017N,'\n",
    "                   'PCT12D_018N,PCT12D_019N,PCT12D_020N,PCT12D_021N,'\n",
    "                   'PCT12D_022N,PCT12D_023N,PCT12D_024N,PCT12D_025N,'\n",
    "                   'PCT12D_026N,PCT12D_027N,PCT12D_028N,PCT12D_029N,'\n",
    "                   'PCT12D_030N,PCT12D_031N,PCT12D_032N,PCT12D_033N,'\n",
    "                   'PCT12D_034N,PCT12D_035N,PCT12D_036N,PCT12D_037N,'\n",
    "                   'PCT12D_038N,PCT12D_039N,PCT12D_040N,PCT12D_041N,'\n",
    "                   'PCT12D_042N,PCT12D_043N,PCT12D_044N,PCT12D_045N,'\n",
    "                   'PCT12D_046N,PCT12D_047N,PCT12D_048N,PCT12D_049N,'\n",
    "                   'PCT12D_050N')\n",
    "\n",
    "total_male_aa_1 = ('NAME,PCT12D_051N,PCT12D_052N,PCT12D_053N,PCT12D_054N,'\n",
    "                   'PCT12D_055N,PCT12D_056N,PCT12D_057N,PCT12D_058N,'\n",
    "                   'PCT12D_059N,PCT12D_060N,PCT12D_061N,PCT12D_062N,'\n",
    "                   'PCT12D_063N,PCT12D_064N,PCT12D_065N,PCT12D_066N,'\n",
    "                   'PCT12D_067N,PCT12D_068N,PCT12D_069N,PCT12D_070N,'\n",
    "                   'PCT12D_071N,PCT12D_072N,PCT12D_073N,PCT12D_074N,'\n",
    "                   'PCT12D_075N,PCT12D_076N,PCT12D_077N,PCT12D_078N,'\n",
    "                   'PCT12D_079N,PCT12D_080N,PCT12D_081N,PCT12D_082N,'\n",
    "                   'PCT12D_083N,PCT12D_084N,PCT12D_085N,PCT12D_086N,'\n",
    "                   'PCT12D_087N,PCT12D_088N,PCT12D_089N,PCT12D_090N,'\n",
    "                   'PCT12D_091N,PCT12D_092N,PCT12D_093N,PCT12D_094N,'\n",
    "                   'PCT12D_095N,PCT12D_096N,PCT12D_097N,PCT12D_098N,'\n",
    "                   'PCT12D_099N')\n",
    "\n",
    "total_male_aa_2 = ('NAME,PCT12D_100N,PCT12D_101N,PCT12D_102N,PCT12D_103N,'\n",
    "                   'PCT12D_104N,PCT12D_105N')\n",
    "\n",
    "total_female_aa_0 = ('NAME,PCT12D_106N,PCT12D_107N,PCT12D_108N,PCT12D_109N,'\n",
    "                     'PCT12D_110N,PCT12D_111N,PCT12D_112N,PCT12D_113N,'\n",
    "                     'PCT12D_114N,PCT12D_115N,PCT12D_116N,PCT12D_117N,'\n",
    "                     'PCT12D_118N,PCT12D_119N,PCT12D_120N,PCT12D_121N,'\n",
    "                     'PCT12D_122N,PCT12D_123N,PCT12D_124N,PCT12D_125N,'\n",
    "                     'PCT12D_126N,PCT12D_127N,PCT12D_128N,PCT12D_129N,'\n",
    "                     'PCT12D_130N,PCT12D_131N,PCT12D_132N,PCT12D_133N,'\n",
    "                     'PCT12D_134N,PCT12D_135N,PCT12D_136N,PCT12D_137N,'\n",
    "                     'PCT12D_138N,PCT12D_139N,PCT12D_140N,PCT12D_141N,'\n",
    "                     'PCT12D_142N,PCT12D_143N,PCT12D_144N,PCT12D_145N,'\n",
    "                     'PCT12D_146N,PCT12D_147N,PCT12D_148N,PCT12D_149N,'\n",
    "                     'PCT12D_150N,PCT12D_151N,PCT12D_152N,PCT12D_153N,'\n",
    "                     'PCT12D_154N')\n",
    "\n",
    "total_female_aa_1 = ('NAME,PCT12D_155N,PCT12D_156N,PCT12D_157N,PCT12D_158N,'\n",
    "                     'PCT12D_159N,PCT12D_160N,PCT12D_161N,PCT12D_162N,'\n",
    "                     'PCT12D_163N,PCT12D_164N,PCT12D_165N,PCT12D_166N,'\n",
    "                     'PCT12D_167N,PCT12D_168N,PCT12D_169N,PCT12D_170N,'\n",
    "                     'PCT12D_171N,PCT12D_172N,PCT12D_173N,PCT12D_174N,'\n",
    "                     'PCT12D_175N,PCT12D_176N,PCT12D_177N,PCT12D_178N,'\n",
    "                     'PCT12D_179N,PCT12D_180N,PCT12D_181N,PCT12D_182N,'\n",
    "                     'PCT12D_183N,PCT12D_184N,PCT12D_185N,PCT12D_186N,'\n",
    "                     'PCT12D_187N,PCT12D_188N,PCT12D_189N,PCT12D_190N,'\n",
    "                     'PCT12D_191N,PCT12D_192N,PCT12D_193N,PCT12D_194N,'\n",
    "                     'PCT12D_195N,PCT12D_196N,PCT12D_197N,PCT12D_198N,'\n",
    "                     'PCT12D_199N,PCT12D_200N,PCT12D_201N,PCT12D_202N,'\n",
    "                     'PCT12D_203N')\n",
    "\n",
    "total_female_aa_2 = ('NAME,PCT12D_204N,PCT12D_205N,PCT12D_206N,PCT12D_207N,'\n",
    "                     'PCT12D_208N,PCT12D_209N')\n",
    "\n",
    "total_nhop = ('NAME,PCT12E_001N')\n",
    "\n",
    "total_male_nhop_0 = ('NAME,PCT12E_002N,PCT12E_003N,PCT12E_004N,PCT12E_005N,'\n",
    "                     'PCT12E_006N,PCT12E_007N,PCT12E_008N,PCT12E_009N,'\n",
    "                     'PCT12E_010N,PCT12E_011N,PCT12E_012N,PCT12E_013N,'\n",
    "                     'PCT12E_014N,PCT12E_015N,PCT12E_016N,PCT12E_017N,'\n",
    "                     'PCT12E_018N,PCT12E_019N,PCT12E_020N,PCT12E_021N,'\n",
    "                     'PCT12E_022N,PCT12E_023N,PCT12E_024N,PCT12E_025N,'\n",
    "                     'PCT12E_026N,PCT12E_027N,PCT12E_028N,PCT12E_029N,'\n",
    "                     'PCT12E_030N,PCT12E_031N,PCT12E_032N,PCT12E_033N,'\n",
    "                     'PCT12E_034N,PCT12E_035N,PCT12E_036N,PCT12E_037N,'\n",
    "                     'PCT12E_038N,PCT12E_039N,PCT12E_040N,PCT12E_041N,'\n",
    "                     'PCT12E_042N,PCT12E_043N,PCT12E_044N,PCT12E_045N,'\n",
    "                     'PCT12E_046N,PCT12E_047N,PCT12E_048N,PCT12E_049N,'\n",
    "                     'PCT12E_050N')\n",
    "\n",
    "total_male_nhop_1 = ('NAME,PCT12E_051N,PCT12E_052N,PCT12E_053N,PCT12E_054N,'\n",
    "                     'PCT12E_055N,PCT12E_056N,PCT12E_057N,PCT12E_058N,'\n",
    "                     'PCT12E_059N,PCT12E_060N,PCT12E_061N,PCT12E_062N,'\n",
    "                     'PCT12E_063N,PCT12E_064N,PCT12E_065N,PCT12E_066N,'\n",
    "                     'PCT12E_067N,PCT12E_068N,PCT12E_069N,PCT12E_070N,'\n",
    "                     'PCT12E_071N,PCT12E_072N,PCT12E_073N,PCT12E_074N,'\n",
    "                     'PCT12E_075N,PCT12E_076N,PCT12E_077N,PCT12E_078N,'\n",
    "                     'PCT12E_079N,PCT12E_080N,PCT12E_081N,PCT12E_082N,'\n",
    "                     'PCT12E_083N,PCT12E_084N,PCT12E_085N,PCT12E_086N,'\n",
    "                     'PCT12E_087N,PCT12E_088N,PCT12E_089N,PCT12E_090N,'\n",
    "                     'PCT12E_091N,PCT12E_092N,PCT12E_093N,PCT12E_094N,'\n",
    "                     'PCT12E_095N,PCT12E_096N,PCT12E_097N,PCT12E_098N,'\n",
    "                     'PCT12E_099N')\n",
    "\n",
    "total_male_nhop_2 = ('NAME,PCT12E_100N,PCT12E_101N,PCT12E_102N,PCT12E_103N,'\n",
    "                     'PCT12E_104N,PCT12E_105N')\n",
    "\n",
    "total_female_nhop_0 = ('NAME,PCT12E_106N,PCT12E_107N,PCT12E_108N,PCT12E_109N,'\n",
    "                       'PCT12E_110N,PCT12E_111N,PCT12E_112N,PCT12E_113N,'\n",
    "                       'PCT12E_114N,PCT12E_115N,PCT12E_116N,PCT12E_117N,'\n",
    "                       'PCT12E_118N,PCT12E_119N,PCT12E_120N,PCT12E_121N,'\n",
    "                       'PCT12E_122N,PCT12E_123N,PCT12E_124N,PCT12E_125N,'\n",
    "                       'PCT12E_126N,PCT12E_127N,PCT12E_128N,PCT12E_129N,'\n",
    "                       'PCT12E_130N,PCT12E_131N,PCT12E_132N,PCT12E_133N,'\n",
    "                       'PCT12E_134N,PCT12E_135N,PCT12E_136N,PCT12E_137N,'\n",
    "                       'PCT12E_138N,PCT12E_139N,PCT12E_140N,PCT12E_141N,'\n",
    "                       'PCT12E_142N,PCT12E_143N,PCT12E_144N,PCT12E_145N,'\n",
    "                       'PCT12E_146N,PCT12E_147N,PCT12E_148N,PCT12E_149N,'\n",
    "                       'PCT12E_150N,PCT12E_151N,PCT12E_152N,PCT12E_153N,'\n",
    "                       'PCT12E_154N')\n",
    "\n",
    "total_female_nhop_1 = ('NAME,PCT12E_155N,PCT12E_156N,PCT12E_157N,PCT12E_158N,'\n",
    "                       'PCT12E_159N,PCT12E_160N,PCT12E_161N,PCT12E_162N,'\n",
    "                       'PCT12E_163N,PCT12E_164N,PCT12E_165N,PCT12E_166N,'\n",
    "                       'PCT12E_167N,PCT12E_168N,PCT12E_169N,PCT12E_170N,'\n",
    "                       'PCT12E_171N,PCT12E_172N,PCT12E_173N,PCT12E_174N,'\n",
    "                       'PCT12E_175N,PCT12E_176N,PCT12E_177N,PCT12E_178N,'\n",
    "                       'PCT12E_179N,PCT12E_180N,PCT12E_181N,PCT12E_182N,'\n",
    "                       'PCT12E_183N,PCT12E_184N,PCT12E_185N,PCT12E_186N,'\n",
    "                       'PCT12E_187N,PCT12E_188N,PCT12E_189N,PCT12E_190N,'\n",
    "                       'PCT12E_191N,PCT12E_192N,PCT12E_193N,PCT12E_194N,'\n",
    "                       'PCT12E_195N,PCT12E_196N,PCT12E_197N,PCT12E_198N,'\n",
    "                       'PCT12E_199N,PCT12E_200N,PCT12E_201N,PCT12E_202N,'\n",
    "                       'PCT12E_203N')\n",
    "\n",
    "total_female_nhop_2 = ('NAME,PCT12E_204N,PCT12E_205N,PCT12E_206N,PCT12E_207N,'\n",
    "                       'PCT12E_208N,PCT12E_209N')\n",
    "\n",
    "total_sor = ('NAME,PCT12F_001N')\n",
    "\n",
    "total_male_sor_0 = ('NAME,PCT12F_002N,PCT12F_003N,PCT12F_004N,PCT12F_005N,'\n",
    "                    'PCT12F_006N,PCT12F_007N,PCT12F_008N,PCT12F_009N,'\n",
    "                    'PCT12F_010N,PCT12F_011N,PCT12F_012N,PCT12F_013N,'\n",
    "                    'PCT12F_014N,PCT12F_015N,PCT12F_016N,PCT12F_017N,'\n",
    "                    'PCT12F_018N,PCT12F_019N,PCT12F_020N,PCT12F_021N,'\n",
    "                    'PCT12F_022N,PCT12F_023N,PCT12F_024N,PCT12F_025N,'\n",
    "                    'PCT12F_026N,PCT12F_027N,PCT12F_028N,PCT12F_029N,'\n",
    "                    'PCT12F_030N,PCT12F_031N,PCT12F_032N,PCT12F_033N,'\n",
    "                    'PCT12F_034N,PCT12F_035N,PCT12F_036N,PCT12F_037N,'\n",
    "                    'PCT12F_038N,PCT12F_039N,PCT12F_040N,PCT12F_041N,'\n",
    "                    'PCT12F_042N,PCT12F_043N,PCT12F_044N,PCT12F_045N,'\n",
    "                    'PCT12F_046N,PCT12F_047N,PCT12F_048N,PCT12F_049N,'\n",
    "                    'PCT12F_050N')\n",
    "\n",
    "total_male_sor_1 = ('NAME,PCT12F_051N,PCT12F_052N,PCT12F_053N,PCT12F_054N,'\n",
    "                    'PCT12F_055N,PCT12F_056N,PCT12F_057N,PCT12F_058N,'\n",
    "                    'PCT12F_059N,PCT12F_060N,PCT12F_061N,PCT12F_062N,'\n",
    "                    'PCT12F_063N,PCT12F_064N,PCT12F_065N,PCT12F_066N,'\n",
    "                    'PCT12F_067N,PCT12F_068N,PCT12F_069N,PCT12F_070N,'\n",
    "                    'PCT12F_071N,PCT12F_072N,PCT12F_073N,PCT12F_074N,'\n",
    "                    'PCT12F_075N,PCT12F_076N,PCT12F_077N,PCT12F_078N,'\n",
    "                    'PCT12F_079N,PCT12F_080N,PCT12F_081N,PCT12F_082N,'\n",
    "                    'PCT12F_083N,PCT12F_084N,PCT12F_085N,PCT12F_086N,'\n",
    "                    'PCT12F_087N,PCT12F_088N,PCT12F_089N,PCT12F_090N,'\n",
    "                    'PCT12F_091N,PCT12F_092N,PCT12F_093N,PCT12F_094N,'\n",
    "                    'PCT12F_095N,PCT12F_096N,PCT12F_097N,PCT12F_098N,'\n",
    "                    'PCT12F_099N')\n",
    "\n",
    "total_male_sor_2 = ('NAME,PCT12F_100N,PCT12F_101N,PCT12F_102N,PCT12F_103N,'\n",
    "                    'PCT12F_104N,PCT12F_105N')\n",
    "\n",
    "total_female_sor_0 = ('NAME,PCT12F_106N,PCT12F_107N,PCT12F_108N,PCT12F_109N,'\n",
    "                      'PCT12F_110N,PCT12F_111N,PCT12F_112N,PCT12F_113N,'\n",
    "                      'PCT12F_114N,PCT12F_115N,PCT12F_116N,PCT12F_117N,'\n",
    "                      'PCT12F_118N,PCT12F_119N,PCT12F_120N,PCT12F_121N,'\n",
    "                      'PCT12F_122N,PCT12F_123N,PCT12F_124N,PCT12F_125N,'\n",
    "                      'PCT12F_126N,PCT12F_127N,PCT12F_128N,PCT12F_129N,'\n",
    "                      'PCT12F_130N,PCT12F_131N,PCT12F_132N,PCT12F_133N,'\n",
    "                      'PCT12F_134N,PCT12F_135N,PCT12F_136N,PCT12F_137N,'\n",
    "                      'PCT12F_138N,PCT12F_139N,PCT12F_140N,PCT12F_141N,'\n",
    "                      'PCT12F_142N,PCT12F_143N,PCT12F_144N,PCT12F_145N,'\n",
    "                      'PCT12F_146N,PCT12F_147N,PCT12F_148N,PCT12F_149N,'\n",
    "                      'PCT12F_150N,PCT12F_151N,PCT12F_152N,PCT12F_153N,'\n",
    "                      'PCT12F_154N')\n",
    "\n",
    "total_female_sor_1 = ('NAME,PCT12F_155N,PCT12F_156N,PCT12F_157N,PCT12F_158N,'\n",
    "                      'PCT12F_159N,PCT12F_160N,PCT12F_161N,PCT12F_162N,'\n",
    "                      'PCT12F_163N,PCT12F_164N,PCT12F_165N,PCT12F_166N,'\n",
    "                      'PCT12F_167N,PCT12F_168N,PCT12F_169N,PCT12F_170N,'\n",
    "                      'PCT12F_171N,PCT12F_172N,PCT12F_173N,PCT12F_174N,'\n",
    "                      'PCT12F_175N,PCT12F_176N,PCT12F_177N,PCT12F_178N,'\n",
    "                      'PCT12F_179N,PCT12F_180N,PCT12F_181N,PCT12F_182N,'\n",
    "                      'PCT12F_183N,PCT12F_184N,PCT12F_185N,PCT12F_186N,'\n",
    "                      'PCT12F_187N,PCT12F_188N,PCT12F_189N,PCT12F_190N,'\n",
    "                      'PCT12F_191N,PCT12F_192N,PCT12F_193N,PCT12F_194N,'\n",
    "                      'PCT12F_195N,PCT12F_196N,PCT12F_197N,PCT12F_198N,'\n",
    "                      'PCT12F_199N,PCT12F_200N,PCT12F_201N,PCT12F_202N,'\n",
    "                      'PCT12F_203N')\n",
    "\n",
    "total_female_sor_2 = ('NAME,PCT12F_204N,PCT12F_205N,PCT12F_206N,PCT12F_207N,'\n",
    "                      'PCT12F_208N,PCT12F_209N')\n",
    "\n",
    "total_tom = ('NAME,PCT12G_001N')\n",
    "\n",
    "total_male_tom_0 = ('NAME,PCT12G_002N,PCT12G_003N,PCT12G_004N,PCT12G_005N,'\n",
    "                    'PCT12G_006N,PCT12G_007N,PCT12G_008N,PCT12G_009N,'\n",
    "                    'PCT12G_010N,PCT12G_011N,PCT12G_012N,PCT12G_013N,'\n",
    "                    'PCT12G_014N,PCT12G_015N,PCT12G_016N,PCT12G_017N,'\n",
    "                    'PCT12G_018N,PCT12G_019N,PCT12G_020N,PCT12G_021N,'\n",
    "                    'PCT12G_022N,PCT12G_023N,PCT12G_024N,PCT12G_025N,'\n",
    "                    'PCT12G_026N,PCT12G_027N,PCT12G_028N,PCT12G_029N,'\n",
    "                    'PCT12G_030N,PCT12G_031N,PCT12G_032N,PCT12G_033N,'\n",
    "                    'PCT12G_034N,PCT12G_035N,PCT12G_036N,PCT12G_037N,'\n",
    "                    'PCT12G_038N,PCT12G_039N,PCT12G_040N,PCT12G_041N,'\n",
    "                    'PCT12G_042N,PCT12G_043N,PCT12G_044N,PCT12G_045N,'\n",
    "                    'PCT12G_046N,PCT12G_047N,PCT12G_048N,PCT12G_049N,'\n",
    "                    'PCT12G_050N')\n",
    "\n",
    "total_male_tom_1 = ('NAME,PCT12G_051N,PCT12G_052N,PCT12G_053N,PCT12G_054N,'\n",
    "                    'PCT12G_055N,PCT12G_056N,PCT12G_057N,PCT12G_058N,'\n",
    "                    'PCT12G_059N,PCT12G_060N,PCT12G_061N,PCT12G_062N,'\n",
    "                    'PCT12G_063N,PCT12G_064N,PCT12G_065N,PCT12G_066N,'\n",
    "                    'PCT12G_067N,PCT12G_068N,PCT12G_069N,PCT12G_070N,'\n",
    "                    'PCT12G_071N,PCT12G_072N,PCT12G_073N,PCT12G_074N,'\n",
    "                    'PCT12G_075N,PCT12G_076N,PCT12G_077N,PCT12G_078N,'\n",
    "                    'PCT12G_079N,PCT12G_080N,PCT12G_081N,PCT12G_082N,'\n",
    "                    'PCT12G_083N,PCT12G_084N,PCT12G_085N,PCT12G_086N,'\n",
    "                    'PCT12G_087N,PCT12G_088N,PCT12G_089N,PCT12G_090N,'\n",
    "                    'PCT12G_091N,PCT12G_092N,PCT12G_093N,PCT12G_094N,'\n",
    "                    'PCT12G_095N,PCT12G_096N,PCT12G_097N,PCT12G_098N,'\n",
    "                    'PCT12G_099N')\n",
    "\n",
    "total_male_tom_2 = ('NAME,PCT12G_100N,PCT12G_101N,PCT12G_102N,PCT12G_103N,'\n",
    "                    'PCT12G_104N,PCT12G_105N')\n",
    "\n",
    "total_female_tom_0 = ('NAME,PCT12G_106N,PCT12G_107N,PCT12G_108N,PCT12G_109N,'\n",
    "                      'PCT12G_110N,PCT12G_111N,PCT12G_112N,PCT12G_113N,'\n",
    "                      'PCT12G_114N,PCT12G_115N,PCT12G_116N,PCT12G_117N,'\n",
    "                      'PCT12G_118N,PCT12G_119N,PCT12G_120N,PCT12G_121N,'\n",
    "                      'PCT12G_122N,PCT12G_123N,PCT12G_124N,PCT12G_125N,'\n",
    "                      'PCT12G_126N,PCT12G_127N,PCT12G_128N,PCT12G_129N,'\n",
    "                      'PCT12G_130N,PCT12G_131N,PCT12G_132N,PCT12G_133N,'\n",
    "                      'PCT12G_134N,PCT12G_135N,PCT12G_136N,PCT12G_137N,'\n",
    "                      'PCT12G_138N,PCT12G_139N,PCT12G_140N,PCT12G_141N,'\n",
    "                      'PCT12G_142N,PCT12G_143N,PCT12G_144N,PCT12G_145N,'\n",
    "                      'PCT12G_146N,PCT12G_147N,PCT12G_148N,PCT12G_149N,'\n",
    "                      'PCT12G_150N,PCT12G_151N,PCT12G_152N,PCT12G_153N,'\n",
    "                      'PCT12G_154N')\n",
    "\n",
    "total_female_tom_1 = ('NAME,PCT12G_155N,PCT12G_156N,PCT12G_157N,PCT12G_158N,'\n",
    "                      'PCT12G_159N,PCT12G_160N,PCT12G_161N,PCT12G_162N,'\n",
    "                      'PCT12G_163N,PCT12G_164N,PCT12G_165N,PCT12G_166N,'\n",
    "                      'PCT12G_167N,PCT12G_168N,PCT12G_169N,PCT12G_170N,'\n",
    "                      'PCT12G_171N,PCT12G_172N,PCT12G_173N,PCT12G_174N,'\n",
    "                      'PCT12G_175N,PCT12G_176N,PCT12G_177N,PCT12G_178N,'\n",
    "                      'PCT12G_179N,PCT12G_180N,PCT12G_181N,PCT12G_182N,'\n",
    "                      'PCT12G_183N,PCT12G_184N,PCT12G_185N,PCT12G_186N,'\n",
    "                      'PCT12G_187N,PCT12G_188N,PCT12G_189N,PCT12G_190N,'\n",
    "                      'PCT12G_191N,PCT12G_192N,PCT12G_193N,PCT12G_194N,'\n",
    "                      'PCT12G_195N,PCT12G_196N,PCT12G_197N,PCT12G_198N,'\n",
    "                      'PCT12G_199N,PCT12G_200N,PCT12G_201N,PCT12G_202N,'\n",
    "                      'PCT12G_203N')\n",
    "\n",
    "total_female_tom_2 = ('NAME,PCT12G_204N,PCT12G_205N,PCT12G_206N,PCT12G_207N,'\n",
    "                      'PCT12G_208N,PCT12G_209N')\n",
    "\n",
    "total_hol = ('NAME,PCT12H_001N')\n",
    "\n",
    "total_male_hol_0 = ('NAME,PCT12H_002N,PCT12H_003N,PCT12H_004N,PCT12H_005N,'\n",
    "                    'PCT12H_006N,PCT12H_007N,PCT12H_008N,PCT12H_009N,'\n",
    "                    'PCT12H_010N,PCT12H_011N,PCT12H_012N,PCT12H_013N,'\n",
    "                    'PCT12H_014N,PCT12H_015N,PCT12H_016N,PCT12H_017N,'\n",
    "                    'PCT12H_018N,PCT12H_019N,PCT12H_020N,PCT12H_021N,'\n",
    "                    'PCT12H_022N,PCT12H_023N,PCT12H_024N,PCT12H_025N,'\n",
    "                    'PCT12H_026N,PCT12H_027N,PCT12H_028N,PCT12H_029N,'\n",
    "                    'PCT12H_030N,PCT12H_031N,PCT12H_032N,PCT12H_033N,'\n",
    "                    'PCT12H_034N,PCT12H_035N,PCT12H_036N,PCT12H_037N,'\n",
    "                    'PCT12H_038N,PCT12H_039N,PCT12H_040N,PCT12H_041N,'\n",
    "                    'PCT12H_042N,PCT12H_043N,PCT12H_044N,PCT12H_045N,'\n",
    "                    'PCT12H_046N,PCT12H_047N,PCT12H_048N,PCT12H_049N,'\n",
    "                    'PCT12H_050N')\n",
    "\n",
    "total_male_hol_1 = ('NAME,PCT12H_051N,PCT12H_052N,PCT12H_053N,PCT12H_054N,'\n",
    "                    'PCT12H_055N,PCT12H_056N,PCT12H_057N,PCT12H_058N,'\n",
    "                    'PCT12H_059N,PCT12H_060N,PCT12H_061N,PCT12H_062N,'\n",
    "                    'PCT12H_063N,PCT12H_064N,PCT12H_065N,PCT12H_066N,'\n",
    "                    'PCT12H_067N,PCT12H_068N,PCT12H_069N,PCT12H_070N,'\n",
    "                    'PCT12H_071N,PCT12H_072N,PCT12H_073N,PCT12H_074N,'\n",
    "                    'PCT12H_075N,PCT12H_076N,PCT12H_077N,PCT12H_078N,'\n",
    "                    'PCT12H_079N,PCT12H_080N,PCT12H_081N,PCT12H_082N,'\n",
    "                    'PCT12H_083N,PCT12H_084N,PCT12H_085N,PCT12H_086N,'\n",
    "                    'PCT12H_087N,PCT12H_088N,PCT12H_089N,PCT12H_090N,'\n",
    "                    'PCT12H_091N,PCT12H_092N,PCT12H_093N,PCT12H_094N,'\n",
    "                    'PCT12H_095N,PCT12H_096N,PCT12H_097N,PCT12H_098N,'\n",
    "                    'PCT12H_099N')\n",
    "\n",
    "total_male_hol_2 = ('NAME,PCT12H_100N,PCT12H_101N,PCT12H_102N,PCT12H_103N,'\n",
    "                    'PCT12H_104N,PCT12H_105N')\n",
    "\n",
    "total_female_hol_0 = ('NAME,PCT12H_106N,PCT12H_107N,PCT12H_108N,PCT12H_109N,'\n",
    "                      'PCT12H_110N,PCT12H_111N,PCT12H_112N,PCT12H_113N,'\n",
    "                      'PCT12H_114N,PCT12H_115N,PCT12H_116N,PCT12H_117N,'\n",
    "                      'PCT12H_118N,PCT12H_119N,PCT12H_120N,PCT12H_121N,'\n",
    "                      'PCT12H_122N,PCT12H_123N,PCT12H_124N,PCT12H_125N,'\n",
    "                      'PCT12H_126N,PCT12H_127N,PCT12H_128N,PCT12H_129N,'\n",
    "                      'PCT12H_130N,PCT12H_131N,PCT12H_132N,PCT12H_133N,'\n",
    "                      'PCT12H_134N,PCT12H_135N,PCT12H_136N,PCT12H_137N,'\n",
    "                      'PCT12H_138N,PCT12H_139N,PCT12H_140N,PCT12H_141N,'\n",
    "                      'PCT12H_142N,PCT12H_143N,PCT12H_144N,PCT12H_145N,'\n",
    "                      'PCT12H_146N,PCT12H_147N,PCT12H_148N,PCT12H_149N,'\n",
    "                      'PCT12H_150N,PCT12H_151N,PCT12H_152N,PCT12H_153N,'\n",
    "                      'PCT12H_154N')\n",
    "\n",
    "total_female_hol_1 = ('NAME,PCT12H_155N,PCT12H_156N,PCT12H_157N,PCT12H_158N,'\n",
    "                      'PCT12H_159N,PCT12H_160N,PCT12H_161N,PCT12H_162N,'\n",
    "                      'PCT12H_163N,PCT12H_164N,PCT12H_165N,PCT12H_166N,'\n",
    "                      'PCT12H_167N,PCT12H_168N,PCT12H_169N,PCT12H_170N,'\n",
    "                      'PCT12H_171N,PCT12H_172N,PCT12H_173N,PCT12H_174N,'\n",
    "                      'PCT12H_175N,PCT12H_176N,PCT12H_177N,PCT12H_178N,'\n",
    "                      'PCT12H_179N,PCT12H_180N,PCT12H_181N,PCT12H_182N,'\n",
    "                      'PCT12H_183N,PCT12H_184N,PCT12H_185N,PCT12H_186N,'\n",
    "                      'PCT12H_187N,PCT12H_188N,PCT12H_189N,PCT12H_190N,'\n",
    "                      'PCT12H_191N,PCT12H_192N,PCT12H_193N,PCT12H_194N,'\n",
    "                      'PCT12H_195N,PCT12H_196N,PCT12H_197N,PCT12H_198N,'\n",
    "                      'PCT12H_199N,PCT12H_200N,PCT12H_201N,PCT12H_202N,'\n",
    "                      'PCT12H_203N')\n",
    "\n",
    "total_female_hol_2 = ('NAME,PCT12H_204N,PCT12H_205N,PCT12H_206N,PCT12H_207N,'\n",
    "                      'PCT12H_208N,PCT12H_209N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vars = [male_all_0,male_all_1,male_all_2,female_all_0,\n",
    "            female_all_1,female_all_2,total_male_whi_0,\n",
    "            total_male_whi_1,total_male_whi_2,total_female_whi_0,\n",
    "            total_female_whi_1,total_female_whi_2,total_male_baa_0,\n",
    "            total_male_baa_1,total_male_baa_2,total_female_baa_0,\n",
    "            total_female_baa_1,total_female_baa_2,total_male_aian_0,\n",
    "            total_male_aian_1,total_male_aian_2,total_female_aian_0,\n",
    "            total_female_aian_1,total_female_aian_2,total_male_aa_0,\n",
    "            total_male_aa_1,total_male_aa_2,total_female_aa_0,\n",
    "            total_female_aa_1,total_female_aa_2,total_male_nhop_0,\n",
    "            total_male_nhop_1,total_male_nhop_2,total_female_nhop_0,\n",
    "            total_female_nhop_1,total_female_nhop_2,total_male_sor_0,\n",
    "            total_male_sor_1,total_male_sor_2,total_female_sor_0,\n",
    "            total_female_sor_1,total_female_sor_2,total_male_tom_0,\n",
    "            total_male_tom_1,total_male_tom_2,total_female_tom_0,\n",
    "            total_female_tom_1,total_female_tom_2,total_male_hol_0,\n",
    "            total_male_hol_1,total_male_hol_2,total_female_hol_0,\n",
    "            total_female_hol_1,total_female_hol_2\n",
    "            ]\n",
    "\n",
    "get_vars_A = [total_all,total_whi,total_baa,total_aian,total_aa,total_nhop,\n",
    "              total_sor,total_tom,total_hol\n",
    "              ]\n",
    "\n",
    "df_vars = ['DF_male_all_0','DF_male_all_1','DF_male_all_2',\n",
    "           'DF_female_all_0','DF_female_all_1','DF_female_all_2',\n",
    "           'DF_total_male_whi_0','DF_total_male_whi_1',\n",
    "           'DF_total_male_whi_2','DF_total_female_whi_0',\n",
    "           'DF_total_female_whi_1','DF_total_female_whi_2',\n",
    "           'DF_total_male_baa_0','DF_total_male_baa_1','DF_total_male_baa_2',\n",
    "           'DF_total_female_baa_0','DF_total_female_baa_1',\n",
    "           'DF_total_female_baa_2','DF_total_male_aian_0',\n",
    "           'DF_total_male_aian_1','DF_total_male_aian_2',\n",
    "           'DF_total_female_aian_0','DF_total_female_aian_1',\n",
    "           'DF_total_female_aian_2','DF_total_male_aa_0',\n",
    "           'DF_total_male_aa_1','DF_total_male_aa_2','DF_total_female_aa_0',\n",
    "           'DF_total_female_aa_1','DF_total_female_aa_2',\n",
    "           'DF_total_male_nhop_0','DF_total_male_nhop_1',\n",
    "           'DF_total_male_nhop_2','DF_total_female_nhop_0',\n",
    "           'DF_total_female_nhop_1','DF_total_female_nhop_2',\n",
    "           'DF_total_male_sor_0','DF_total_male_sor_1','DF_total_male_sor_2',\n",
    "           'DF_total_female_sor_0','DF_total_female_sor_1',\n",
    "           'DF_total_female_sor_2','DF_total_male_tom_0',\n",
    "           'DF_total_male_tom_1','DF_total_male_tom_2','DF_total_female_tom_0',\n",
    "           'DF_total_female_tom_1','DF_total_female_tom_2',\n",
    "           'DF_total_male_hol_0','DF_total_male_hol_1','DF_total_male_hol_2',\n",
    "           'DF_total_female_hol_0','DF_total_female_hol_1',\n",
    "           'DF_total_female_hol_2'\n",
    "           ]\n",
    "\n",
    "df_vars_A = ['DF_total_all','DF_total_whi','DF_total_baa','DF_total_aian',\n",
    "             'DF_total_aa','DF_total_nhop','DF_total_sor','DF_total_tom',\n",
    "             'DF_total_hol']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Calls (For Merge)\n",
    "\n",
    "Due to the high volumn of API calls and dataframes being created I am \n",
    "splitting the calls into the API in two:\n",
    "\n",
    "Dataframes to be merged (get_vars,df_vars)<br>\n",
    "Dataframes to NOT merge (get_vars_A,df_vars_A)<br>\n",
    "\n",
    "This will ease management since the dataframes of each type have many disimilar\n",
    "features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API call parameters\n",
    "url = 'https://api.census.gov/data/2020/dec/dhc'\n",
    "how = 'state:*'\n",
    "where = 'county:*'\n",
    "\n",
    "# Create an empty dictionary to store the data frames\n",
    "dfs = {}\n",
    "\n",
    "# Iterate through get_vars and df_vars simultaneously\n",
    "for var, name in zip(get_vars, df_vars):\n",
    "    r = requests.request('GET', url, params={\"get\": var, \"for\": where, \"in\": how, \"key\": key})\n",
    "\n",
    "    # Check if the API call was successful\n",
    "    if r.status_code == 200:\n",
    "        data = r.json()\n",
    "\n",
    "        # Create the data frame using the returned JSON data\n",
    "        df_data = data[1:]  # Skip the first row which contains the column names\n",
    "        dfs[name] = pd.DataFrame(df_data, columns=data[0])\n",
    "\n",
    "        # Join 'state' and 'county' columns into a new column 'FIPS'\n",
    "        dfs[name]['FIPS'] = dfs[name]['state'] + dfs[name]['county']\n",
    "\n",
    "        # Convert specific columns to desired data types\n",
    "        columns_to_convert = ['NAME', 'state', 'county', 'FIPS']\n",
    "        columns_to_convert = [col for col in columns_to_convert if col in dfs[name].columns]\n",
    "        dfs[name][columns_to_convert] = dfs[name][columns_to_convert].astype(str)\n",
    "        dfs[name][dfs[name].columns.difference(columns_to_convert)] = dfs[name][dfs[name].columns.difference(columns_to_convert)].astype(int)\n",
    "\n",
    "        # Display the created data frame\n",
    "        # print(f\"Data frame '{name}':\")\n",
    "        # print(dfs[name])\n",
    "    else:\n",
    "        # API call failed\n",
    "        print(f\"API call for '{var}' failed. Status code:\", r.status_code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Pulls from API\n",
    "\n",
    "I should have 54 Dataframes total.\n",
    "\n",
    "- Dataframes ending in _0 should have:\n",
    "    - Shape: 3221 rows, 53 columns\n",
    "- Dataframes ending in _1 should have:\n",
    "    - Shape: 3221 rows, 53 columns\n",
    "- Dataframes ending in _2 should have:\n",
    "    - Shape: 3221 rows, 10 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the number of data frame names stored in dfs dictionary\n",
    "# print(f\"Number of data frames: {len(dfs)}\")\n",
    "\n",
    "# print(\"Data Frames in dfs:\")\n",
    "# for name, df in dfs.items():\n",
    "#     # Get the shape of the data frame\n",
    "#     rows, cols = df.shape\n",
    "\n",
    "#     # Print the data frame name and shape\n",
    "#     print(f\"Data frame '{name}':\")\n",
    "#     print(f\"Shape: {rows} rows, {cols} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for data errors\n",
    "\n",
    "I should find no missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df_name, df in dfs.items():\n",
    "#     # Find the rows with missing data\n",
    "#     rows_with_missing_data = df[df.isnull().any(axis=1)]\n",
    "\n",
    "#     # Find the columns with missing data\n",
    "#     columns_with_missing_data = df.columns[df.isnull().any()]\n",
    "\n",
    "#     # Check if there is missing data in the dataframe\n",
    "#     if not rows_with_missing_data.empty or len(columns_with_missing_data) > 0:\n",
    "#         print(f\"Missing data found in DataFrame '{df_name}'\")\n",
    "\n",
    "#         # Replace NaN values with string 'NaN'\n",
    "#         df = df.replace({np.nan: 'NaN'})\n",
    "\n",
    "#         # Print the rows with missing data\n",
    "#         print(\"Rows with missing data:\")\n",
    "#         print(rows_with_missing_data)\n",
    "\n",
    "#         # Print the columns with missing data\n",
    "#         print(\"Columns with missing data:\")\n",
    "#         print(columns_with_missing_data)\n",
    "#         print()\n",
    "\n",
    "#         # Search for 'NaN' string in the dataframe\n",
    "#         rows_with_nan_string = df[df.eq('NaN').any(axis=1)]\n",
    "#         columns_with_nan_string = df.columns[df.eq('NaN').any()]\n",
    "\n",
    "#         # Print the rows with 'NaN' string\n",
    "#         print(\"Rows with 'NaN' string:\")\n",
    "#         print(rows_with_nan_string)\n",
    "\n",
    "#         # Print the columns with 'NaN' string\n",
    "#         print(\"Columns with 'NaN' string:\")\n",
    "#         print(columns_with_nan_string)\n",
    "#         print()\n",
    "#     else:\n",
    "#         print(f\"No missing data found in DataFrame '{df_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Dataframes\n",
    "\n",
    "Merging dataframes based on their name:\n",
    "\n",
    ">Example: 'DF_male_all' = 'DF_male_all_0'+'DF_male_all_1'+'DF_male_all_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of dataframe names to use for merging\n",
    "df_mrg = ['DF_male_all','DF_female_all','DF_total_male_whi',\n",
    "          'DF_total_female_whi','DF_total_male_baa','DF_total_female_baa',\n",
    "          'DF_total_male_aian','DF_total_female_aian','DF_total_male_aa',\n",
    "          'DF_total_female_aa','DF_total_male_nhop','DF_total_female_nhop',\n",
    "          'DF_total_male_sor','DF_total_female_sor','DF_total_male_tom',\n",
    "          'DF_total_female_tom','DF_total_male_hol','DF_total_female_hol'\n",
    "          ]\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
      "C:\\Users\\Derek\\AppData\\Local\\Temp\\ipykernel_10864\\180942237.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df[common_cols] = dfs[item + '_0'][common_cols]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store the merged data frames\n",
    "merged_dfs = {}\n",
    "\n",
    "# Iterate over the items in the 'df_mrg' list\n",
    "for item in df_mrg:\n",
    "\n",
    "    # Create an empty list to store modified dataframes\n",
    "        # Drop 4 common columns from each dataframe in 'dfs'dictionary\n",
    "            # Create 'df_name' to represent the dataframe name from 'df_mrg'\n",
    "            # 'df_name' is the loop variable for the key/value pairs in 'dfs'\n",
    "                #looking for the name from 'df_mrg', beginning of name string\n",
    "    dfs_to_merge = [df.drop(['NAME', 'state', 'county', 'FIPS'], axis=1) \n",
    "                    for df_name, df in dfs.items() if df_name.startswith(item)]\n",
    "    \n",
    "    # Merge the data frames by joining all columns at once\n",
    "    # Merged columns will be in order since 'df_mrg' was in introduced\n",
    "    #   and has the proper order for the itteration above\n",
    "    merged_df = pd.concat(dfs_to_merge, axis=1, ignore_index=True)\n",
    "\n",
    "    # # Reset the index after concatenation\n",
    "    # merged_df = merged_df.reset_index(drop=True)\n",
    "    \n",
    "    # Add the common columns back to the merged data frame\n",
    "    # Since the columns and their data still exist, they can be added back\n",
    "    common_cols = ['NAME', 'state', 'county', 'FIPS']\n",
    "    merged_df[common_cols] = dfs[item + '_0'][common_cols]\n",
    "    \n",
    "    # Add the merged data frame to the dictionary created before\n",
    "    merged_dfs[item] = merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Merge\n",
    "\n",
    "I should have 18 Dataframes total.\n",
    "\n",
    "Dataframes should match the names of 'df_mrg' and be the following shape:<br>\n",
    ">Shape: (3221, 108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the number of dataframes in merged_dfs\n",
    "# print(\"Number of Dataframes in merged_dfs:\", len(merged_dfs))\n",
    "\n",
    "# # Iterate over the dataframes in merged_dfs and print their names and shapes\n",
    "# for name, df in merged_dfs.items():\n",
    "#     print(\"Dataframe:\", name)\n",
    "#     print(\"Shape:\", df.shape)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Content\n",
    "\n",
    "selected dataframe from 'merged_dfs' should have the following columns:<br>\n",
    ">104 variable columns with 4 constant columns at the end:<br>\n",
    ">['NAME','state','county','FIPS']<br>\n",
    "\n",
    "Columns should be in order according to associated sheet in planning doc:<br>\n",
    ">'2020_agesex.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = merged_dfs['DF_male_all']\n",
    "# # Print the columns\n",
    "# print(\"Columns of DF_male_all:\")\n",
    "# for column in df.columns:\n",
    "#     print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Column Names\n",
    "\n",
    "Column order of dataframes has been verified, changing column names to the <br>\n",
    "merged dataframes in 'merged_dfs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['Total','Under 1 Year','1 Year','2 Years','3 Years','4 Years',\n",
    "             '5 Years','6 Years','7 Years','8 Years','9 Years','10 Years',\n",
    "             '11 Years','12 Years','13 Years','14 Years','15 Years','16 Years',\n",
    "             '17 Years','18 Years','19 Years','20 Years','21 Years','22 Years',\n",
    "             '23 Years','24 Years','25 Years','26 Years','27 Years','28 Years',\n",
    "             '29 Years','30 Years','31 Years','32 Years','33 Years','34 Years',\n",
    "             '35 Years','36 Years','37 Years','38 Years','39 Years','40 Years',\n",
    "             '41 Years','42 Years','43 Years','44 Years','45 Years','46 Years',\n",
    "             '47 Years','48 Years','49 Years','50 Years','51 Years','52 Years',\n",
    "             '53 Years','54 Years','55 Years','56 Years','57 Years','58 Years',\n",
    "             '59 Years','60 Years','61 Years','62 Years','63 Years','64 Years',\n",
    "             '65 Years','66 Years','67 Years','68 Years','69 Years','70 Years',\n",
    "             '71 Years','72 Years','73 Years','74 Years','75 Years','76 Years',\n",
    "             '77 Years','78 Years','79 Years','80 Years','81 Years','82 Years',\n",
    "             '83 Years','84 Years','85 Years','86 Years','87 Years','88 Years',\n",
    "             '89 Years','90 Years','91 Years','92 Years','93 Years','94 Years',\n",
    "             '95 Years','96 Years','97  Years','98  Years','99  Years',\n",
    "             '100 to 104  Years','105 to 109  Years','110  Years and Over',\n",
    "             'Location','State','County','FIPS'\n",
    "             ]\n",
    "\n",
    "# Iterate over the items in the 'merged_dfs' dictionary\n",
    "for item, df in merged_dfs.items():\n",
    "    df.columns = col_names  # Assign the new column names to the data frame in place\n",
    "    merged_dfs[item] = df  # Update the data frame in the 'merged_dfs' dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Column Names\n",
    "\n",
    "selected dataframe from 'merged_dfs' should have the correct columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = merged_dfs['DF_male_all']\n",
    "# # Print the columns\n",
    "# print(\"Columns of DF_male_all:\")\n",
    "# for column in df.columns:\n",
    "#     print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Calls (For Non-Merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API call parameters\n",
    "url = 'https://api.census.gov/data/2020/dec/dhc'\n",
    "how = 'state:*'\n",
    "where = 'county:*'\n",
    "\n",
    "# Create an empty dictionary to store the data frames\n",
    "dfs_A = {}\n",
    "\n",
    "# Iterate through get_vars and df_vars simultaneously\n",
    "for var, name in zip(get_vars_A, df_vars_A):\n",
    "    r = requests.request('GET', url, params={\"get\": var, \"for\": where, \"in\": how, \"key\": key})\n",
    "\n",
    "    # Check if the API call was successful\n",
    "    if r.status_code == 200:\n",
    "        data = r.json()\n",
    "\n",
    "        # Create the data frame using the returned JSON data\n",
    "        df_data = data[1:]  # Skip the first row which contains the column names\n",
    "        dfs_A[name] = pd.DataFrame(df_data, columns=data[0])\n",
    "\n",
    "        # Join 'state' and 'county' columns into a new column 'FIPS'\n",
    "        dfs_A[name]['FIPS'] = dfs_A[name]['state'] + dfs_A[name]['county']\n",
    "\n",
    "                # Convert specific columns to desired data types\n",
    "        columns_to_convert = ['NAME', 'state', 'county', 'FIPS']\n",
    "        columns_to_convert = [col for col in columns_to_convert if col in dfs_A[name].columns]\n",
    "        dfs_A[name][columns_to_convert] = dfs_A[name][columns_to_convert].astype(str)\n",
    "        dfs_A[name][dfs_A[name].columns.difference(columns_to_convert)] = dfs_A[name][dfs_A[name].columns.difference(columns_to_convert)].astype(int)\n",
    "\n",
    "        # Display the created data frame\n",
    "        # print(f\"Data frame '{name}':\")\n",
    "        # print(dfs_A[name])\n",
    "    else:\n",
    "        # API call failed\n",
    "        print(f\"API call for '{var}' failed. Status code:\", r.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Pulls from API\n",
    "\n",
    "I should have 9 Dataframes total.\n",
    "\n",
    "- Dataframes should have:\n",
    "    - Shape: 3221 rows, 5 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the number of data frame names stored in dfs_A dictionary\n",
    "# print(f\"Number of data frames: {len(dfs_A)}\")\n",
    "\n",
    "# print(\"Data Frames in dfs_A:\")\n",
    "# for name, df in dfs_A.items():\n",
    "#     # Get the shape of the data frame\n",
    "#     rows, cols = df.shape\n",
    "\n",
    "#     # Print the data frame name and shape\n",
    "#     print(f\"Data frame '{name}':\")\n",
    "#     print(f\"Shape: {rows} rows, {cols} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for data errors\n",
    "\n",
    "I should find no missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df_name, df in dfs_A.items():\n",
    "#     # Find the rows with missing data\n",
    "#     rows_with_missing_data = df[df.isnull().any(axis=1)]\n",
    "\n",
    "#     # Find the columns with missing data\n",
    "#     columns_with_missing_data = df.columns[df.isnull().any()]\n",
    "\n",
    "#     # Check if there is missing data in the dataframe\n",
    "#     if not rows_with_missing_data.empty or len(columns_with_missing_data) > 0:\n",
    "#         print(f\"Missing data found in DataFrame '{df_name}'\")\n",
    "\n",
    "#         # Replace NaN values with string 'NaN'\n",
    "#         df = df.replace({np.nan: 'NaN'})\n",
    "\n",
    "#         # Print the rows with missing data\n",
    "#         print(\"Rows with missing data:\")\n",
    "#         print(rows_with_missing_data)\n",
    "\n",
    "#         # Print the columns with missing data\n",
    "#         print(\"Columns with missing data:\")\n",
    "#         print(columns_with_missing_data)\n",
    "#         print()\n",
    "\n",
    "#         # Search for 'NaN' string in the dataframe\n",
    "#         rows_with_nan_string = df[df.eq('NaN').any(axis=1)]\n",
    "#         columns_with_nan_string = df.columns[df.eq('NaN').any()]\n",
    "\n",
    "#         # Print the rows with 'NaN' string\n",
    "#         print(\"Rows with 'NaN' string:\")\n",
    "#         print(rows_with_nan_string)\n",
    "\n",
    "#         # Print the columns with 'NaN' string\n",
    "#         print(\"Columns with 'NaN' string:\")\n",
    "#         print(columns_with_nan_string)\n",
    "#         print()\n",
    "#     else:\n",
    "#         print(f\"No missing data found in DataFrame '{df_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify Content\n",
    "\n",
    "selected dataframe from 'dfs_A' should have the following columns:<br>\n",
    ">1 variable column with 4 constant columns:<br>\n",
    ">['NAME','state','county','FIPS']<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = dfs_A['DF_total_all']\n",
    "# # Print the columns\n",
    "# print(\"Columns of DF_total_all:\")\n",
    "# for column in df.columns:\n",
    "#     print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify Column Locations\n",
    "\n",
    "Reindex columsn to share column structure with merged dataframes:<br>\n",
    ">['NAME','state','county','FIPS']<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in dfs_A.items():\n",
    "    columns = df.columns.tolist()\n",
    "    columns[0], columns[1] = columns[1], columns[0]\n",
    "    df = df.reindex(columns=columns)\n",
    "    dfs_A[name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = dfs_A['DF_total_all']\n",
    "# # Print the columns\n",
    "# print(\"Columns of DF_total_all:\")\n",
    "# for column in df.columns:\n",
    "#     print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Column Names\n",
    "\n",
    "Column order of dataframes has been verified, changing column names to the <br>\n",
    "dataframes in 'dfs_A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['Total','Location','State','County','FIPS']\n",
    "\n",
    "# Iterate over the items in the 'dfs_A' dictionary\n",
    "for item, df in dfs_A.items():\n",
    "    df.columns = col_names  # Assign the new column names to the data frame in place\n",
    "    dfs_A[item] = df  # Update the data frame in the 'dfs_A' dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of DF_total_all:\n",
      "Total\n",
      "Location\n",
      "State\n",
      "County\n",
      "FIPS\n"
     ]
    }
   ],
   "source": [
    "df = dfs_A['DF_total_all']\n",
    "# Print the columns\n",
    "print(\"Columns of DF_total_all:\")\n",
    "for column in df.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepparing for Export\n",
    "\n",
    "Gathering dataframes in 'merged_dfs' and 'dfs_A' into one variable for export to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_export_prep =['DF_total_all','DF_male_all','DF_female_all','DF_total_whi',\n",
    "            'DF_total_male_whi','DF_total_female_whi','DF_total_baa',\n",
    "            'DF_total_male_baa','DF_total_female_baa','DF_total_aian',\n",
    "            'DF_total_male_aian','DF_total_female_aian','DF_total_aa',\n",
    "            'DF_total_male_aa','DF_total_female_aa','DF_total_nhop',\n",
    "            'DF_total_male_nhop','DF_total_female_nhop','DF_total_sor',\n",
    "            'DF_total_male_sor','DF_total_female_sor','DF_total_tom',\n",
    "            'DF_total_male_tom','DF_total_female_tom','DF_total_hol',\n",
    "            'DF_total_male_hol','DF_total_female_hol'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying location of dataframes\n",
    "\n",
    "checking 'merged_dfs' and 'dfs_A' to verify dataframe location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the names of the dataframes in 'merged_dfs'\n",
    "# print(\"Data Frames in 'merged_dfs':\")\n",
    "# for name in merged_dfs.keys():\n",
    "#     print(name)\n",
    "\n",
    "# # Print the names of the dataframes in 'dfs_A'\n",
    "# print(\"\\nData Frames in 'dfs_A':\")\n",
    "# for name in dfs_A.keys():\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging dictionaries to list\n",
    "\n",
    "Merging 'merged_dfs' and 'dfs_A' using common keys from 'df_export_prep'.<br>\n",
    "Naming dataframes to match names in ''df_export_prep' to ease sheet naming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the dataframes\n",
    "df_export = []\n",
    "\n",
    "# Iterate through the keys in df_export_prep\n",
    "for key in df_export_prep:\n",
    "    # Check if the key exists in merged_dfs or dfs_A\n",
    "    if key in merged_dfs:\n",
    "        # Assign the dataframe to df\n",
    "        df = merged_dfs[key]\n",
    "    elif key in dfs_A:\n",
    "        # Assign the dataframe to df\n",
    "        df = dfs_A[key]\n",
    "    else:\n",
    "        # Key not found in any dictionary\n",
    "        print(f\"Dataframe with key '{key}' not found in merged_dfs or dfs_A\")\n",
    "        continue\n",
    "\n",
    "    # Set the dataframe name as the key\n",
    "    df.name = key\n",
    "\n",
    "    # Append the dataframe to df_export\n",
    "    df_export.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final verification before export\n",
    "\n",
    "verifying count, name, and shape before export.<br>\n",
    "Should match planning doc:<br>\n",
    "'2020_agesex.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataframes in df_export: 27\n",
      "Dataframes in df_export:\n",
      "Name: 'DF_total_all', Shape: (3221, 5)\n",
      "Name: 'DF_male_all', Shape: (3221, 108)\n",
      "Name: 'DF_female_all', Shape: (3221, 108)\n",
      "Name: 'DF_total_whi', Shape: (3221, 5)\n",
      "Name: 'DF_total_male_whi', Shape: (3221, 108)\n",
      "Name: 'DF_total_female_whi', Shape: (3221, 108)\n",
      "Name: 'DF_total_baa', Shape: (3221, 5)\n",
      "Name: 'DF_total_male_baa', Shape: (3221, 108)\n",
      "Name: 'DF_total_female_baa', Shape: (3221, 108)\n",
      "Name: 'DF_total_aian', Shape: (3221, 5)\n",
      "Name: 'DF_total_male_aian', Shape: (3221, 108)\n",
      "Name: 'DF_total_female_aian', Shape: (3221, 108)\n",
      "Name: 'DF_total_aa', Shape: (3221, 5)\n",
      "Name: 'DF_total_male_aa', Shape: (3221, 108)\n",
      "Name: 'DF_total_female_aa', Shape: (3221, 108)\n",
      "Name: 'DF_total_nhop', Shape: (3221, 5)\n",
      "Name: 'DF_total_male_nhop', Shape: (3221, 108)\n",
      "Name: 'DF_total_female_nhop', Shape: (3221, 108)\n",
      "Name: 'DF_total_sor', Shape: (3221, 5)\n",
      "Name: 'DF_total_male_sor', Shape: (3221, 108)\n",
      "Name: 'DF_total_female_sor', Shape: (3221, 108)\n",
      "Name: 'DF_total_tom', Shape: (3221, 5)\n",
      "Name: 'DF_total_male_tom', Shape: (3221, 108)\n",
      "Name: 'DF_total_female_tom', Shape: (3221, 108)\n",
      "Name: 'DF_total_hol', Shape: (3221, 5)\n",
      "Name: 'DF_total_male_hol', Shape: (3221, 108)\n",
      "Name: 'DF_total_female_hol', Shape: (3221, 108)\n"
     ]
    }
   ],
   "source": [
    "# List the name, shape, and count of dataframes in df_export\n",
    "print(f\"Total dataframes in df_export: {len(df_export)}\")\n",
    "print(\"Dataframes in df_export:\")\n",
    "for df in df_export:\n",
    "    name = df.name if hasattr(df, 'name') else 'Unnamed'\n",
    "    print(f\"Name: '{name}', Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create workbook and export wanted dataframes to excel as individual sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file name\n",
    "file_name = '2020_agesex_data.xlsx'\n",
    "\n",
    "# Get the file path in the current working directory\n",
    "file_path = os.path.join(os.getcwd(), file_name)\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "   # Load the existing Excel file\n",
    "    excel_file = pd.read_excel(file_path, engine='openpyxl')\n",
    "\n",
    "    # Create a new ExcelWriter object using the existing file\n",
    "    writer = pd.ExcelWriter(file_path, engine='openpyxl', if_sheet_exists = 'replace', mode= 'a')\n",
    "    \n",
    "    # Iterate through the dataframes in df_export\n",
    "    for df in df_export:\n",
    "        # Get the name of the dataframe\n",
    "        name = df.name if hasattr(df, 'name') else 'Unnamed'\n",
    "    \n",
    "        # Write each dataframe to a separate sheet in the Excel file\n",
    "        df.to_excel(writer, sheet_name=name, index=False)\n",
    "    \n",
    "    # Save the Excel file\n",
    "    writer.close()\n",
    "\n",
    "else:\n",
    "    # Create a new workbook\n",
    "    writer = pd.ExcelWriter(file_path, engine='openpyxl')\n",
    "    \n",
    "    # Iterate through the dataframes in df_export\n",
    "    for df in df_export:\n",
    "        # Get the name of the dataframe\n",
    "        name = df.name if hasattr(df, 'name') else 'Unnamed'\n",
    "    \n",
    "        # Write each dataframe to a separate sheet in the Excel file\n",
    "        df.to_excel(writer, sheet_name=name, index=False)\n",
    "    \n",
    "    # Save the Excel file\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
